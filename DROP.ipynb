{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ref1-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Va99aleijfbdl6-Kr_ESfWHZ6jHI0qLP",
      "authorship_tag": "ABX9TyMkjSCt+hVpzeSqiWsyiDVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surensnyper/ys_project_001/blob/main/DROP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/eladsegal/tag-based-multi-span-extraction \\\\\n",
        "https://eladsegal.github.io/DROP-explorer/"
      ],
      "metadata": {
        "id": "cY8y6XG_Bkzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Load and Prerequisites Install"
      ],
      "metadata": {
        "id": "_w4LgfJ2Hl8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "BqmYW6oBGNPE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jk9QlPydC93u",
        "outputId": "1b94b988-2042-41d1-ce2b-bcb463055508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.31.5)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.3.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.3.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.56.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (21.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eladsegal/tag-based-multi-span-extraction.git\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import torch\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/EQA related/EQA_DA_Multispan_Classification/EQA_Multispan/DROP_TASE_IO.tar.gz\" \"DROP_TASE_IO.tar.gz\"\n",
        "\n",
        "# # bert folder construction in the Colab\n",
        "# if \"RoBERTa_TASE_IO+SSE\" not in os.listdir():\n",
        "#   os.makedirs(\"RoBERTa_TASE_IO+SSE\")\n",
        "# else:\n",
        "#   pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "0BsUtE61GTZF",
        "outputId": "eccb650d-d4f1-4c93-82db-68b2c39b7d30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tag-based-multi-span-extraction'...\n",
            "remote: Enumerating objects: 1472, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 1472 (delta 17), reused 0 (delta 0), pack-reused 1439\u001b[K\n",
            "Receiving objects: 100% (1472/1472), 30.25 MiB | 13.04 MiB/s, done.\n",
            "Resolving deltas: 100% (908/908), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install patool\n",
        "# import patoolib"
      ],
      "metadata": {
        "id": "19zq3_wCGsR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the Model .gz file in the RoBERTa_TASE_IO+SSE folder\n",
        "# roberta_gzip  = patoolib.extract_archive('/content/drive/MyDrive/Colab Notebooks/EQA related/EQA_DA_Multispan_Classification/EQA_Multispan/TASE_IO+SSE.gz', outdir='/content/RoBERTa_TASE_IO+SSE')\n",
        "# shutil.rmtree('/content/unpack')\n",
        "# roberta_gzip.extractall('RoBERTa_TASE_IO+SSE')\n",
        "\n",
        "# roberta_gzip.close()"
      ],
      "metadata": {
        "id": "sZXpag8eGtc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar xf /content/RoBERTa_TASE_IO+SSE/best_model.tar"
      ],
      "metadata": {
        "id": "VElZ4KSbGuv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install overrides\n",
        "!pip install allennlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tY64U9XBGwZf",
        "outputId": "70902451-d708-40b7-ab5f-e81de8a899c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting overrides\n",
            "  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting typing-utils>=0.0.3\n",
            "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: typing-utils, overrides\n",
            "Successfully installed overrides-6.1.0 typing-utils-0.1.0\n",
            "Collecting allennlp\n",
            "  Downloading allennlp-2.9.3-py3-none-any.whl (719 kB)\n",
            "\u001b[K     |████████████████████████████████| 719 kB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.64.0)\n",
            "Requirement already satisfied: spacy<3.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.4)\n",
            "Requirement already satisfied: torch<1.12.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.10.0+cu111)\n",
            "Collecting cached-path<1.2.0,>=1.0.2\n",
            "  Downloading cached_path-1.1.2-py3-none-any.whl (26 kB)\n",
            "Collecting fairscale==0.4.6\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 88.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.2)\n",
            "Collecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.12.0)\n",
            "Requirement already satisfied: filelock<3.7,>=3.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.0)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 109.9 MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n",
            "\u001b[K     |████████████████████████████████| 592 kB 86.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.11.1+cu111)\n",
            "Collecting transformers<4.19,>=4.1\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.23.0)\n",
            "Collecting typer>=0.4.1\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 86.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.21.6)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n",
            "Collecting boto3<2.0,>=1.0\n",
            "  Downloading boto3-1.21.46-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<3.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<1.2.0,>=1.0.2->allennlp) (1.18.1)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.46\n",
            "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 80.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.46->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 77.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (0.2.8)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.31.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (2022.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.56.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 82.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (0.9.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.16->allennlp) (3.8.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.13.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 97.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19,>=4.1->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.1->allennlp) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 69.0 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 90.7 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (21.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.19,>=4.1->allennlp) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp) (3.1.0)\n",
            "Building wheels for collected packages: fairscale, jsonnet, pathtools\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=5b8a29489ff77ede41a762ef2b712288c57f262256f9303f92546268ce5d6472\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994504 sha256=e0dacb430872ca88dbea7d21573f8eaf3056a2c6295f59f2294fe758cb23a25c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=83e0ba36024b436dd79720c412c62c47525e6eb45b6439ea088aa99a1df32300\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built fairscale jsonnet pathtools\n",
            "Installing collected packages: urllib3, jmespath, smmap, botocore, s3transfer, pyyaml, gitdb, tokenizers, shortuuid, setproctitle, sentry-sdk, sacremoses, pathtools, huggingface-hub, GitPython, docker-pycreds, boto3, wandb, typer, transformers, tensorboardX, sentencepiece, jsonnet, fairscale, cached-path, base58, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 allennlp-2.9.3 base58-2.1.1 boto3-1.21.46 botocore-1.24.46 cached-path-1.1.2 docker-pycreds-0.4.0 fairscale-0.4.6 gitdb-4.0.9 huggingface-hub-0.5.1 jmespath-1.0.0 jsonnet-0.18.0 pathtools-0.1.2 pyyaml-6.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 tensorboardX-2.5 tokenizers-0.12.1 transformers-4.18.0 typer-0.4.1 urllib3-1.25.11 wandb-0.12.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "4odPI7bpBfaA",
        "outputId": "141e4f78-b05d-444b-8e13-e9d5ba3ae7c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allennlp.models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bZqH6_UTBVAD",
        "outputId": "e0db8132-a8d0-4c03-dd1c-0c0d7ae73264"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp.models\n",
            "  Downloading allennlp_models-2.9.3-py3-none-any.whl (463 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 39.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 81 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 92 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 122 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 153 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 163 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 184 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 194 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 204 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 215 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 225 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 235 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 245 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 256 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 266 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 276 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 286 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 296 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 307 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 317 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 327 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 337 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 358 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 368 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 378 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 389 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 399 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 409 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 419 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 430 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 440 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 450 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 460 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 463 kB 17.9 MB/s \n",
            "\u001b[?25hCollecting conllu==4.4.1\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 105.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.12.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from allennlp.models) (1.10.0+cu111)\n",
            "Requirement already satisfied: allennlp<2.10,>=2.9.3 in /usr/local/lib/python3.7/dist-packages (from allennlp.models) (2.9.3)\n",
            "Collecting nltk>=3.6.5\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 78.8 MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (1.21.6)\n",
            "Requirement already satisfied: cached-path<1.2.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (1.1.2)\n",
            "Requirement already satisfied: transformers<4.19,>=4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (4.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.5.1)\n",
            "Requirement already satisfied: wandb<0.13.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.12.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (4.64.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (2.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.3.4)\n",
            "Requirement already satisfied: spacy<3.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (2.2.4)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.18.0)\n",
            "Requirement already satisfied: fairscale==0.4.6 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.4.6)\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.4.1)\n",
            "Requirement already satisfied: torchvision<0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.11.1+cu111)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (8.12.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (0.99)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (3.1.0)\n",
            "Requirement already satisfied: filelock<3.7,>=3.3 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (3.6.0)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (2.1.1)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (2.23.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (3.6.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp<2.10,>=2.9.3->allennlp.models) (1.0.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.18.1)\n",
            "Requirement already satisfied: boto3<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.21.46)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.46 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.24.46)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.46->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.46->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (2.8.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.0.3)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (4.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (4.2.4)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.31.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (2022.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (1.56.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp<2.10,>=2.9.3->allennlp.models) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp<2.10,>=2.9.3->allennlp.models) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp<2.10,>=2.9.3->allennlp.models) (4.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp.models) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp.models) (1.1.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp<2.10,>=2.9.3->allennlp.models) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp<2.10,>=2.9.3->allennlp.models) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp<2.10,>=2.9.3->allennlp.models) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp<2.10,>=2.9.3->allennlp.models) (3.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (0.9.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (3.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.16->allennlp<2.10,>=2.9.3->allennlp.models) (3.8.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.13.0,>=0.8.1->allennlp<2.10,>=2.9.3->allennlp.models) (7.1.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.19,>=4.1->allennlp<2.10,>=2.9.3->allennlp.models) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19,>=4.1->allennlp<2.10,>=2.9.3->allennlp.models) (0.12.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (0.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (2.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.5.10)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.2.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (3.1.27)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (1.0.8)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp<2.10,>=2.9.3->allennlp.models) (5.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp.models) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp.models) (6.0.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 80.3 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp.models) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp.models) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 91.7 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp.models) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 105.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp.models) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp<2.10,>=2.9.3->allennlp.models) (1.5.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp<2.10,>=2.9.3->allennlp.models) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp<2.10,>=2.9.3->allennlp.models) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp<2.10,>=2.9.3->allennlp.models) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp<2.10,>=2.9.3->allennlp.models) (3.1.0)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=b358206be32fc2469781ea33041fce283d1cdf7049a81db6ce354ecd0dc83cd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "Successfully built word2number\n",
            "Installing collected packages: multidict, frozenlist, yarl, regex, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, nltk, word2number, py-rouge, ftfy, datasets, conllu, allennlp.models\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 allennlp.models-2.9.3 async-timeout-4.0.2 asynctest-0.13.0 conllu-4.4.1 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 ftfy-6.1.1 multidict-6.0.2 nltk-3.7 py-rouge-1.1 regex-2022.3.15 responses-0.18.0 word2number-1.1 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/tag-based-multi-span-extraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLZer7R5nQPA",
        "outputId": "ceef40d7-67a1-44c2-94e4-30068c130fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tag-based-multi-span-extraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global url.\"https://\".insteadOf git://"
      ],
      "metadata": {
        "id": "LNgXsiYVuZ5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "75deb1af-8af2-4811-f44f-6af424ae370c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/tag-based-multi-span-extraction/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AN1-1JBWHQ8l",
        "outputId": "ca53ea33-2653-4d6a-c08e-11d6f269ea6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp\n",
            "  Cloning http://github.com/eladsegal/allennlp (to revision 2143c7c) to /tmp/pip-install-sd8ju6zz/allennlp_5cb6e4f071844c3099fc7a580c051831\n",
            "  Running command git clone -q http://github.com/eladsegal/allennlp /tmp/pip-install-sd8ju6zz/allennlp_5cb6e4f071844c3099fc7a580c051831\n",
            "\u001b[33m  WARNING: Did not find branch or tag '2143c7c', assuming revision or ref.\u001b[0m\n",
            "  Running command git checkout -q 2143c7c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers==2.3.0\n",
            "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
            "\u001b[K     |████████████████████████████████| 447 kB 37.7 MB/s \n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 97.6 MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.8.0\n",
            "  Downloading numpydoc-1.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 305 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (6.1.1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (4.64.0)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2022.1)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: torch!=1.3.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.6.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.21.46)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: gitpython>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.1.27)\n",
            "Collecting conllu==1.3.1\n",
            "  Downloading conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 93.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1)\n",
            "Collecting flaky\n",
            "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.2.2)\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting gevent>=1.3.6\n",
            "  Downloading gevent-21.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0\n",
            "  Downloading parsimonious-0.9.0.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.7)\n",
            "Collecting overrides==2.0\n",
            "  Downloading overrides-2.0.tar.gz (3.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r /content/tag-based-multi-span-extraction/requirements.txt (line 2)) (0.1.96)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r /content/tag-based-multi-span-extraction/requirements.txt (line 2)) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r /content/tag-based-multi-span-extraction/requirements.txt (line 2)) (2022.3.15)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.7->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.15.0)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 84.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (57.4.0)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=3.0.4->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=3.0.4->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.0.4->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.0.2->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: sphinx>=1.8 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.8.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.9.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.9.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.2.4)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.17.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.46 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.24.46)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.5.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (21.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.8->numpydoc>=0.8.0->allennlp->-r /content/tag-based-multi-span-extraction/requirements.txt (line 1)) (1.1.5)\n",
            "Building wheels for collected packages: allennlp, overrides, parsimonious\n",
            "  Building wheel for allennlp (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for allennlp: filename=allennlp-0.9.dev1-py3-none-any.whl size=5267203 sha256=7076613d8bba68be813ab1edb5797639a09bd50a4bbe23a7b196601e9cc50534\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yuwz9lb6/wheels/cd/69/fc/7d7a41005b3c7aa1b5c0b3463d7bc378d8eb3c760d6f1c936a\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.0-py3-none-any.whl size=4219 sha256=fe0da0e2440f2688ffdf6023750f0127f30989a2c4eefe4f51c1719bf7b00010\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/50/26/701019d83238c0815e9db8a2b607246f88a44d70fb078cf672\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.9.0-py3-none-any.whl size=44314 sha256=30759d098323c05c54fee793feec4f8f89910981cd4042adc1e0c115bf627fd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/54/88/c1ee7de0eabd1fb817cbf35824e4c2cba664d5816ddc64efb1\n",
            "Successfully built allennlp overrides parsimonious\n",
            "Installing collected packages: zope.interface, zope.event, unidecode, transformers, pytorch-pretrained-bert, parsimonious, overrides, numpydoc, jsonpickle, gevent, flask-cors, flaky, conllu, allennlp\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.18.0\n",
            "    Uninstalling transformers-4.18.0:\n",
            "      Successfully uninstalled transformers-4.18.0\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 6.1.0\n",
            "    Uninstalling overrides-6.1.0:\n",
            "      Successfully uninstalled overrides-6.1.0\n",
            "  Attempting uninstall: conllu\n",
            "    Found existing installation: conllu 4.4.1\n",
            "    Uninstalling conllu-4.4.1:\n",
            "      Successfully uninstalled conllu-4.4.1\n",
            "  Attempting uninstall: allennlp\n",
            "    Found existing installation: allennlp 2.9.3\n",
            "    Uninstalling allennlp-2.9.3:\n",
            "      Successfully uninstalled allennlp-2.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "allennlp-models 2.9.3 requires allennlp<2.10,>=2.9.3, but you have allennlp 0.9.dev1 which is incompatible.\n",
            "allennlp-models 2.9.3 requires conllu==4.4.1, but you have conllu 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed allennlp-0.9.dev1 conllu-1.3.1 flaky-3.7.0 flask-cors-3.0.10 gevent-21.12.0 jsonpickle-2.1.0 numpydoc-1.2.1 overrides-2.0 parsimonious-0.9.0 pytorch-pretrained-bert-0.6.2 transformers-2.3.0 unidecode-1.3.4 zope.event-4.5.0 zope.interface-5.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output predictions by a model:"
      ],
      "metadata": {
        "id": "3z0yYPK6Hhms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tag-based-multi-span-extraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "xcOKe5c4PGSd",
        "outputId": "b992b367-15dd-4d92-e8f3-8343980a690f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tag-based-multi-span-extraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning!\n",
        "# Model fine-tuning & Configuration (This tis just for fine-tuning!!!)\n",
        "''' After training, there will be a .tar.gz file in the training directory \n",
        "Epoch number is 35 in default by allenlp but, by probably memory issue\n",
        "it is interrupted by around 21 epoch when dataset has only one data\n",
        "https://github.com/eladsegal/tag-based-multi-span-extraction/issues/8 '''\n",
        "\n",
        "''' Dataset insertion (path speicification) for training\n",
        "Dataset are to be inserted in path tag-based-multi-span-extraction/drop_data/\n",
        "Train dataset and validation dataset should be placed here\n",
        "And the paths of train & validation dataset must be specified (modifying the default one)\n",
        "in drop_model.jsonnet (if it's drop format) and in quoref_model.jsonnet (if it's a quoref format)\n",
        "Drop Path : /content/tag-based-multi-span-extraction/configs/drop/abstract/drop_model.jsonnet\n",
        "Quoref Path : /content/tag-based-multi-span-extraction/configs/quoref/abstract/quoref_model.jsonnet\n",
        "'''\n",
        "\n",
        "''' Code \n",
        "In model config, can choose different models here by referring to Elad's mail\n",
        "For [config file] you can choose a config that is under configs (and not under abstract folders), \n",
        "for example configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet.\n",
        "'''\n",
        "\n",
        "!allennlp train configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet -s /content/Training --include-package src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvy6KmE1kfhH",
        "outputId": "35833cc0-cf99-46bf-e3a6-78bba1687b16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-23 02:39:54,266 - INFO - transformers.file_utils - PyTorch version 1.10.0+cu111 available.\n",
            "2022-04-23 02:39:55,994 - INFO - transformers.file_utils - TensorFlow version 2.8.0 available.\n",
            "2022-04-23 02:39:56,133 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2022-04-23 02:39:57,314 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2022-04-23 02:39:57,314 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2022-04-23 02:39:57,314 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2022-04-23 02:39:57,371 - INFO - allennlp.common.checks - Pytorch version: 1.10.0+cu111\n",
            "2022-04-23 02:39:57,372 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2022-04-23 02:39:57,372 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'answer_field_generators': {'arithmetic_answer': {'special_numbers': [100, 1], 'type': 'arithmetic_answer_generator'}, 'count_answer': {'type': 'count_answer_generator'}, 'passage_span_answer': {'text_type': 'passage', 'type': 'span_answer_generator'}, 'question_span_answer': {'text_type': 'question', 'type': 'span_answer_generator'}, 'tagged_answer': {'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'type': 'tagged_answer_generator'}}, 'answer_generator_names_per_type': {'date': ['arithmetic_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'multiple_span': ['tagged_answer'], 'number': ['arithmetic_answer', 'count_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'single_span': ['tagged_answer', 'passage_span_answer', 'question_span_answer']}, 'is_training': True, 'old_reader_behavior': True, 'pickle': {'action': 'load', 'file_name': 'all_heads_IO_roberta-large', 'path': '../pickle/drop'}, 'tokenizer': {'pretrained_model': 'roberta-large', 'type': 'huggingface_transformers'}, 'type': 'tbmse_drop'} and extras set()\n",
            "2022-04-23 02:39:57,372 - INFO - allennlp.common.params - dataset_reader.type = tbmse_drop\n",
            "2022-04-23 02:39:57,373 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.drop.drop_reader.DropReader'> from params {'answer_field_generators': {'arithmetic_answer': {'special_numbers': [100, 1], 'type': 'arithmetic_answer_generator'}, 'count_answer': {'type': 'count_answer_generator'}, 'passage_span_answer': {'text_type': 'passage', 'type': 'span_answer_generator'}, 'question_span_answer': {'text_type': 'question', 'type': 'span_answer_generator'}, 'tagged_answer': {'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'type': 'tagged_answer_generator'}}, 'answer_generator_names_per_type': {'date': ['arithmetic_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'multiple_span': ['tagged_answer'], 'number': ['arithmetic_answer', 'count_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'single_span': ['tagged_answer', 'passage_span_answer', 'question_span_answer']}, 'is_training': True, 'old_reader_behavior': True, 'pickle': {'action': 'load', 'file_name': 'all_heads_IO_roberta-large', 'path': '../pickle/drop'}, 'tokenizer': {'pretrained_model': 'roberta-large', 'type': 'huggingface_transformers'}} and extras set()\n",
            "2022-04-23 02:39:57,373 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'pretrained_model': 'roberta-large', 'type': 'huggingface_transformers'} and extras set()\n",
            "2022-04-23 02:39:57,373 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = huggingface_transformers\n",
            "2022-04-23 02:39:57,373 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.tokenizers.huggingface_transformers_tokenizer.HuggingfaceTransformersTokenizer'> from params {'pretrained_model': 'roberta-large'} and extras set()\n",
            "2022-04-23 02:39:57,373 - INFO - allennlp.common.params - dataset_reader.tokenizer.pretrained_model = roberta-large\n",
            "2022-04-23 02:39:58,271 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json not found in cache or force_download set to True, downloading to /tmp/tmpajn9xvux\n",
            "2022-04-23 02:40:00,482 - INFO - transformers.file_utils - copying /tmp/tmpajn9xvux to cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2022-04-23 02:40:00,483 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2022-04-23 02:40:00,484 - INFO - transformers.file_utils - removing temp file /tmp/tmpajn9xvux\n",
            "2022-04-23 02:40:01,390 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt not found in cache or force_download set to True, downloading to /tmp/tmpoz9ypfw_\n",
            "2022-04-23 02:40:03,428 - INFO - transformers.file_utils - copying /tmp/tmpoz9ypfw_ to cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2022-04-23 02:40:03,428 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2022-04-23 02:40:03,428 - INFO - transformers.file_utils - removing temp file /tmp/tmpoz9ypfw_\n",
            "2022-04-23 02:40:03,429 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2022-04-23 02:40:03,429 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2022-04-23 02:40:03,502 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'special_numbers': [100, 1], 'type': 'arithmetic_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:03,502 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.arithmetic_answer.type = arithmetic_answer_generator\n",
            "2022-04-23 02:40:03,502 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.arithmetic_answer_generator.ArithmeticAnswerGenerator'> from params {'special_numbers': [100, 1]} and extras set()\n",
            "2022-04-23 02:40:03,502 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.arithmetic_answer.max_numbers_expression = 2\n",
            "2022-04-23 02:40:03,502 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.arithmetic_answer.special_numbers = [100, 1]\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'type': 'count_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.count_answer.type = count_answer_generator\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.count_answer_generator.CountAnswerGenerator'> from params {} and extras set()\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.count_answer.max_count = 10\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'text_type': 'passage', 'type': 'span_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.passage_span_answer.type = span_answer_generator\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.span_answer_generator.SpanAnswerGenerator'> from params {'text_type': 'passage'} and extras set()\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.passage_span_answer.text_type = passage\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'text_type': 'question', 'type': 'span_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.question_span_answer.type = span_answer_generator\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.span_answer_generator.SpanAnswerGenerator'> from params {'text_type': 'question'} and extras set()\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.question_span_answer.text_type = question\n",
            "2022-04-23 02:40:03,503 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'type': 'tagged_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.tagged_answer.type = tagged_answer_generator\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.tagged_answer_generator.TaggedAnswerGenerator'> from params {'ignore_question': False, 'labels': {'I': 1, 'O': 0}} and extras set()\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.tagged_answer.ignore_question = False\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.tagged_answer.flexibility_threshold = 1000\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.answer_field_generators.tagged_answer.labels = {'I': 1, 'O': 0}\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.answer_generator_names_per_type = {'date': ['arithmetic_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'multiple_span': ['tagged_answer'], 'number': ['arithmetic_answer', 'count_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'single_span': ['tagged_answer', 'passage_span_answer', 'question_span_answer']}\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.old_reader_behavior = True\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.is_training = True\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.max_instances = -1\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.answer_types_filter = ['single_span', 'multiple_span', 'number', 'date']\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.max_pieces = 512\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.uncased = False\n",
            "2022-04-23 02:40:03,504 - INFO - allennlp.common.params - dataset_reader.standardize_texts = True\n",
            "2022-04-23 02:40:03,505 - INFO - allennlp.common.params - dataset_reader.pickle = {'action': 'load', 'file_name': 'all_heads_IO_roberta-large', 'path': '../pickle/drop'}\n",
            "2022-04-23 02:40:03,952 - INFO - allennlp.training.util - Using a separate dataset reader to load validation and test data.\n",
            "2022-04-23 02:40:03,952 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'answer_field_generators': {'arithmetic_answer': {'special_numbers': [100, 1], 'type': 'arithmetic_answer_generator'}, 'count_answer': {'type': 'count_answer_generator'}, 'passage_span_answer': {'text_type': 'passage', 'type': 'span_answer_generator'}, 'question_span_answer': {'text_type': 'question', 'type': 'span_answer_generator'}, 'tagged_answer': {'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'type': 'tagged_answer_generator'}}, 'answer_generator_names_per_type': {'date': ['arithmetic_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'multiple_span': ['tagged_answer'], 'number': ['arithmetic_answer', 'count_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'single_span': ['tagged_answer', 'passage_span_answer', 'question_span_answer']}, 'is_training': False, 'old_reader_behavior': True, 'pickle': {'action': 'load', 'file_name': 'all_heads_IO_roberta-large', 'path': '../pickle/drop'}, 'tokenizer': {'pretrained_model': 'roberta-large', 'type': 'huggingface_transformers'}, 'type': 'tbmse_drop'} and extras set()\n",
            "2022-04-23 02:40:03,952 - INFO - allennlp.common.params - validation_dataset_reader.type = tbmse_drop\n",
            "2022-04-23 02:40:03,952 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.drop.drop_reader.DropReader'> from params {'answer_field_generators': {'arithmetic_answer': {'special_numbers': [100, 1], 'type': 'arithmetic_answer_generator'}, 'count_answer': {'type': 'count_answer_generator'}, 'passage_span_answer': {'text_type': 'passage', 'type': 'span_answer_generator'}, 'question_span_answer': {'text_type': 'question', 'type': 'span_answer_generator'}, 'tagged_answer': {'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'type': 'tagged_answer_generator'}}, 'answer_generator_names_per_type': {'date': ['arithmetic_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'multiple_span': ['tagged_answer'], 'number': ['arithmetic_answer', 'count_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'single_span': ['tagged_answer', 'passage_span_answer', 'question_span_answer']}, 'is_training': False, 'old_reader_behavior': True, 'pickle': {'action': 'load', 'file_name': 'all_heads_IO_roberta-large', 'path': '../pickle/drop'}, 'tokenizer': {'pretrained_model': 'roberta-large', 'type': 'huggingface_transformers'}} and extras set()\n",
            "2022-04-23 02:40:03,953 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'pretrained_model': 'roberta-large', 'type': 'huggingface_transformers'} and extras set()\n",
            "2022-04-23 02:40:03,953 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.type = huggingface_transformers\n",
            "2022-04-23 02:40:03,953 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.tokenizers.huggingface_transformers_tokenizer.HuggingfaceTransformersTokenizer'> from params {'pretrained_model': 'roberta-large'} and extras set()\n",
            "2022-04-23 02:40:03,953 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer.pretrained_model = roberta-large\n",
            "2022-04-23 02:40:05,753 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /root/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "2022-04-23 02:40:05,753 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /root/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "2022-04-23 02:40:05,820 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'special_numbers': [100, 1], 'type': 'arithmetic_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:05,820 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.arithmetic_answer.type = arithmetic_answer_generator\n",
            "2022-04-23 02:40:05,820 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.arithmetic_answer_generator.ArithmeticAnswerGenerator'> from params {'special_numbers': [100, 1]} and extras set()\n",
            "2022-04-23 02:40:05,820 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.arithmetic_answer.max_numbers_expression = 2\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.arithmetic_answer.special_numbers = [100, 1]\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'type': 'count_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.count_answer.type = count_answer_generator\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.count_answer_generator.CountAnswerGenerator'> from params {} and extras set()\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.count_answer.max_count = 10\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'text_type': 'passage', 'type': 'span_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.passage_span_answer.type = span_answer_generator\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.span_answer_generator.SpanAnswerGenerator'> from params {'text_type': 'passage'} and extras set()\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.passage_span_answer.text_type = passage\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'text_type': 'question', 'type': 'span_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.question_span_answer.type = span_answer_generator\n",
            "2022-04-23 02:40:05,821 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.span_answer_generator.SpanAnswerGenerator'> from params {'text_type': 'question'} and extras set()\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.question_span_answer.text_type = question\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.answer_field_generator.AnswerFieldGenerator'> from params {'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'type': 'tagged_answer_generator'} and extras set()\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.tagged_answer.type = tagged_answer_generator\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.from_params - instantiating class <class 'src.data.dataset_readers.answer_field_generators.tagged_answer_generator.TaggedAnswerGenerator'> from params {'ignore_question': False, 'labels': {'I': 1, 'O': 0}} and extras set()\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.tagged_answer.ignore_question = False\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.tagged_answer.flexibility_threshold = 1000\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_field_generators.tagged_answer.labels = {'I': 1, 'O': 0}\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_generator_names_per_type = {'date': ['arithmetic_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'multiple_span': ['tagged_answer'], 'number': ['arithmetic_answer', 'count_answer', 'passage_span_answer', 'question_span_answer', 'tagged_answer'], 'single_span': ['tagged_answer', 'passage_span_answer', 'question_span_answer']}\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.old_reader_behavior = True\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.is_training = False\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = -1\n",
            "2022-04-23 02:40:05,822 - INFO - allennlp.common.params - validation_dataset_reader.answer_types_filter = ['single_span', 'multiple_span', 'number', 'date']\n",
            "2022-04-23 02:40:05,823 - INFO - allennlp.common.params - validation_dataset_reader.max_pieces = 512\n",
            "2022-04-23 02:40:05,823 - INFO - allennlp.common.params - validation_dataset_reader.uncased = False\n",
            "2022-04-23 02:40:05,823 - INFO - allennlp.common.params - validation_dataset_reader.standardize_texts = True\n",
            "2022-04-23 02:40:05,823 - INFO - allennlp.common.params - validation_dataset_reader.pickle = {'action': 'load', 'file_name': 'all_heads_IO_roberta-large', 'path': '../pickle/drop'}\n",
            "2022-04-23 02:40:05,823 - INFO - allennlp.common.params - train_data_path = drop_data/EMF_multispan_train.json\n",
            "2022-04-23 02:40:05,823 - INFO - allennlp.training.util - Reading training data from drop_data/EMF_multispan_train.json\n",
            "0it [00:00, ?it/s]\n",
            "1it [00:00,  3.48it/s]\n",
            "2it [00:00,  5.15it/s]\n",
            "3it [00:00,  4.96it/s]\n",
            "4it [00:00,  3.74it/s]\n",
            "5it [00:01,  3.99it/s]\n",
            "6it [00:01,  3.56it/s]\n",
            "7it [00:01,  4.17it/s]\n",
            "8it [00:01,  4.40it/s]\n",
            "9it [00:02,  4.74it/s]\n",
            "10it [00:02,  5.38it/s]\n",
            "11it [00:02,  5.08it/s]\n",
            "12it [00:02,  4.93it/s]\n",
            "13it [00:02,  5.20it/s]\n",
            "14it [00:02,  5.62it/s]\n",
            "15it [00:03,  5.89it/s]\n",
            "16it [00:03,  6.23it/s]\n",
            "17it [00:03,  6.53it/s]\n",
            "19it [00:03,  5.60it/s]\n",
            "20it [00:04,  5.05it/s]\n",
            "21it [00:04,  5.43it/s]\n",
            "22it [00:04,  6.16it/s]\n",
            "24it [00:04,  7.83it/s]\n",
            " 49%|####8     | 23/47 [00:04<00:03,  6.13it/s]\u001b[A\n",
            "25it [00:04,  5.87it/s]\n",
            "27it [00:04,  6.95it/s]\n",
            "28it [00:05,  7.19it/s]\n",
            "29it [00:05,  7.12it/s]\n",
            "31it [00:05,  8.92it/s]\n",
            "34it [00:05,  9.08it/s]\n",
            "35it [00:05,  7.73it/s]\n",
            "36it [00:06,  6.86it/s]\n",
            "37it [00:06,  7.25it/s]\n",
            "38it [00:06,  7.59it/s]\n",
            "39it [00:06,  7.81it/s]\n",
            "40it [00:06,  5.62it/s]\n",
            "42it [00:07,  6.30it/s]\n",
            "43it [00:07,  5.96it/s]\n",
            "44it [00:07,  5.38it/s]\n",
            "45it [00:07,  5.69it/s]\n",
            "47it [00:07,  7.42it/s]\n",
            "48it [00:08,  6.91it/s]\n",
            "100%|##########| 47/47 [00:07<00:00,  5.88it/s]\n",
            "48it [00:08,  5.94it/s]\n",
            "2022-04-23 02:40:13,902 - INFO - allennlp.common.params - validation_data_path = drop_data/EMF_multispan_test.json\n",
            "2022-04-23 02:40:13,903 - INFO - allennlp.training.util - Reading validation data from drop_data/EMF_multispan_test.json\n",
            "0it [00:00, ?it/s]\n",
            "1it [00:00,  6.49it/s]\n",
            "3it [00:00,  7.07it/s]\n",
            "4it [00:00,  6.33it/s]\n",
            "5it [00:00,  5.96it/s]\n",
            "6it [00:00,  6.23it/s]\n",
            "7it [00:01,  5.87it/s]\n",
            "8it [00:01,  6.34it/s]\n",
            "9it [00:01,  6.28it/s]\n",
            "10it [00:01,  5.92it/s]\n",
            "11it [00:01,  5.83it/s]\n",
            "13it [00:02,  6.91it/s]\n",
            "14it [00:02,  7.00it/s]\n",
            "15it [00:02,  6.85it/s]\n",
            "16it [00:02,  5.52it/s]\n",
            "17it [00:02,  5.81it/s]\n",
            "100%|##########| 18/18 [00:02<00:00,  6.38it/s]\n",
            "18it [00:02,  6.32it/s]\n",
            "2022-04-23 02:40:16,751 - INFO - allennlp.common.params - test_data_path = None\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.training.trainer_pieces - From dataset instances, train, validation will be considered for vocabulary creation.\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.type = None\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.extend = False\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.padding_token = @@PADDING@@\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.oov_token = @@UNKNOWN@@\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2022-04-23 02:40:16,762 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2022-04-23 02:40:16,763 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2022-04-23 02:40:16,763 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n",
            "2022-04-23 02:40:16,763 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n",
            "2022-04-23 02:40:16,763 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2022-04-23 02:40:16,763 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2022-04-23 02:40:16,763 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "66it [00:00, 28734.07it/s]\n",
            "2022-04-23 02:40:16,766 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'dataset_name': 'drop', 'head_predictor': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 5], 'input_dim': 2048, 'num_layers': 2}, 'heads': {'arithmetic': {'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 3], 'input_dim': 2048, 'num_layers': 2}, 'special_embedding_dim': 1024, 'special_numbers': [100, 1], 'training_style': 'soft_em', 'type': 'arithmetic_head'}, 'count': {'max_count': 10, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 11], 'input_dim': 1024, 'num_layers': 2}, 'type': 'count_head'}, 'multi_span': {'decoding_style': 'at_least_one', 'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 2], 'input_dim': 1024, 'num_layers': 2}, 'prediction_method': 'viterbi', 'training_style': 'soft_em', 'type': 'multi_span_head'}, 'passage_span': {'end_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'start_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'training_style': 'soft_em', 'type': 'passage_span_head'}, 'question_span': {'end_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'start_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'training_style': 'soft_em', 'type': 'question_span_head'}}, 'passage_summary_vector_module': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'pretrained_model': 'roberta-large', 'question_summary_vector_module': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'type': 'multi_head'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,766 - INFO - allennlp.common.params - model.type = multi_head\n",
            "2022-04-23 02:40:16,766 - INFO - allennlp.common.from_params - instantiating class <class 'src.models.multi_head_model.MultiHeadModel'> from params {'dataset_name': 'drop', 'head_predictor': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 5], 'input_dim': 2048, 'num_layers': 2}, 'heads': {'arithmetic': {'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 3], 'input_dim': 2048, 'num_layers': 2}, 'special_embedding_dim': 1024, 'special_numbers': [100, 1], 'training_style': 'soft_em', 'type': 'arithmetic_head'}, 'count': {'max_count': 10, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 11], 'input_dim': 1024, 'num_layers': 2}, 'type': 'count_head'}, 'multi_span': {'decoding_style': 'at_least_one', 'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 2], 'input_dim': 1024, 'num_layers': 2}, 'prediction_method': 'viterbi', 'training_style': 'soft_em', 'type': 'multi_span_head'}, 'passage_span': {'end_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'start_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'training_style': 'soft_em', 'type': 'passage_span_head'}, 'question_span': {'end_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'start_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'training_style': 'soft_em', 'type': 'question_span_head'}}, 'passage_summary_vector_module': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'pretrained_model': 'roberta-large', 'question_summary_vector_module': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,766 - INFO - allennlp.common.params - model.pretrained_model = roberta-large\n",
            "2022-04-23 02:40:16,767 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.head.Head'> from params {'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 3], 'input_dim': 2048, 'num_layers': 2}, 'special_embedding_dim': 1024, 'special_numbers': [100, 1], 'training_style': 'soft_em', 'type': 'arithmetic_head'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,767 - INFO - allennlp.common.params - model.heads.arithmetic.type = arithmetic_head\n",
            "2022-04-23 02:40:16,767 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.arithmetic_head.ArithmeticHead'> from params {'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 3], 'input_dim': 2048, 'num_layers': 2}, 'special_embedding_dim': 1024, 'special_numbers': [100, 1], 'training_style': 'soft_em'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,767 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 3], 'input_dim': 2048, 'num_layers': 2} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,767 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.input_dim = 2048\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.num_layers = 2\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.hidden_dims = [1024, 3]\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.hidden_dims = [1024, 3]\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu', 'linear'] and extras {'vocab'}\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - type = relu\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params linear and extras {'vocab'}\n",
            "2022-04-23 02:40:16,768 - INFO - allennlp.common.params - type = linear\n",
            "2022-04-23 02:40:16,769 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,769 - INFO - allennlp.common.params - model.heads.arithmetic.output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,818 - INFO - allennlp.common.params - model.heads.arithmetic.special_numbers = [100, 1]\n",
            "2022-04-23 02:40:16,818 - INFO - allennlp.common.params - model.heads.arithmetic.special_embedding_dim = 1024\n",
            "2022-04-23 02:40:16,818 - INFO - allennlp.common.params - model.heads.arithmetic.training_style = soft_em\n",
            "2022-04-23 02:40:16,818 - INFO - allennlp.common.params - model.heads.arithmetic.arithmetic_round_ndigits = 5\n",
            "2022-04-23 02:40:16,825 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.head.Head'> from params {'max_count': 10, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 11], 'input_dim': 1024, 'num_layers': 2}, 'type': 'count_head'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,825 - INFO - allennlp.common.params - model.heads.count.type = count_head\n",
            "2022-04-23 02:40:16,825 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.count_head.CountHead'> from params {'max_count': 10, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 11], 'input_dim': 1024, 'num_layers': 2}} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 11], 'input_dim': 1024, 'num_layers': 2} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - model.heads.count.output_layer.input_dim = 1024\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - model.heads.count.output_layer.num_layers = 2\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - model.heads.count.output_layer.hidden_dims = [1024, 11]\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - model.heads.count.output_layer.hidden_dims = [1024, 11]\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - model.heads.count.output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu', 'linear'] and extras {'vocab'}\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - model.heads.count.output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n",
            "2022-04-23 02:40:16,826 - INFO - allennlp.common.params - type = relu\n",
            "2022-04-23 02:40:16,827 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params linear and extras {'vocab'}\n",
            "2022-04-23 02:40:16,827 - INFO - allennlp.common.params - type = linear\n",
            "2022-04-23 02:40:16,827 - INFO - allennlp.common.params - model.heads.count.output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,827 - INFO - allennlp.common.params - model.heads.count.output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.params - model.heads.count.max_count = 10\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.head.Head'> from params {'decoding_style': 'at_least_one', 'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 2], 'input_dim': 1024, 'num_layers': 2}, 'prediction_method': 'viterbi', 'training_style': 'soft_em', 'type': 'multi_span_head'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.params - model.heads.multi_span.type = multi_span_head\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.multi_span_head.MultiSpanHead'> from params {'decoding_style': 'at_least_one', 'ignore_question': False, 'labels': {'I': 1, 'O': 0}, 'output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 2], 'input_dim': 1024, 'num_layers': 2}, 'prediction_method': 'viterbi', 'training_style': 'soft_em'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 2], 'input_dim': 1024, 'num_layers': 2} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.input_dim = 1024\n",
            "2022-04-23 02:40:16,834 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.num_layers = 2\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.hidden_dims = [1024, 2]\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.hidden_dims = [1024, 2]\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu', 'linear'] and extras {'vocab'}\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - type = relu\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params linear and extras {'vocab'}\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - type = linear\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,835 - INFO - allennlp.common.params - model.heads.multi_span.output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,842 - INFO - allennlp.common.params - model.heads.multi_span.ignore_question = False\n",
            "2022-04-23 02:40:16,842 - INFO - allennlp.common.params - model.heads.multi_span.prediction_method = viterbi\n",
            "2022-04-23 02:40:16,842 - INFO - allennlp.common.params - model.heads.multi_span.decoding_style = at_least_one\n",
            "2022-04-23 02:40:16,842 - INFO - allennlp.common.params - model.heads.multi_span.training_style = soft_em\n",
            "2022-04-23 02:40:16,842 - INFO - allennlp.common.params - model.heads.multi_span.labels = {'I': 1, 'O': 0}\n",
            "2022-04-23 02:40:16,843 - INFO - allennlp.common.params - model.heads.multi_span.generation_top_k = 0\n",
            "2022-04-23 02:40:16,843 - INFO - allennlp.common.params - model.heads.multi_span.unique_decoding = True\n",
            "2022-04-23 02:40:16,843 - INFO - allennlp.common.params - model.heads.multi_span.substring_unique_decoding = True\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.head.Head'> from params {'end_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'start_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'training_style': 'soft_em', 'type': 'passage_span_head'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.params - model.heads.passage_span.type = passage_span_head\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.passage_span_head.PassageSpanHead'> from params {'end_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'start_output_layer': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1}, 'training_style': 'soft_em'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.params - model.heads.passage_span.start_output_layer.input_dim = 1024\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.params - model.heads.passage_span.start_output_layer.num_layers = 1\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.params - model.heads.passage_span.start_output_layer.hidden_dims = 1\n",
            "2022-04-23 02:40:16,859 - INFO - allennlp.common.params - model.heads.passage_span.start_output_layer.activations = linear\n",
            "2022-04-23 02:40:16,862 - INFO - allennlp.common.params - model.heads.passage_span.start_output_layer.dropout = 0.0\n",
            "2022-04-23 02:40:16,863 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,863 - INFO - allennlp.common.params - model.heads.passage_span.end_output_layer.input_dim = 1024\n",
            "2022-04-23 02:40:16,863 - INFO - allennlp.common.params - model.heads.passage_span.end_output_layer.num_layers = 1\n",
            "2022-04-23 02:40:16,863 - INFO - allennlp.common.params - model.heads.passage_span.end_output_layer.hidden_dims = 1\n",
            "2022-04-23 02:40:16,863 - INFO - allennlp.common.params - model.heads.passage_span.end_output_layer.activations = linear\n",
            "2022-04-23 02:40:16,863 - INFO - allennlp.common.params - model.heads.passage_span.end_output_layer.dropout = 0.0\n",
            "2022-04-23 02:40:16,864 - INFO - allennlp.common.params - model.heads.passage_span.training_style = soft_em\n",
            "2022-04-23 02:40:16,864 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.head.Head'> from params {'end_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'start_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'training_style': 'soft_em', 'type': 'question_span_head'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,864 - INFO - allennlp.common.params - model.heads.question_span.type = question_span_head\n",
            "2022-04-23 02:40:16,864 - INFO - allennlp.common.from_params - instantiating class <class 'src.modules.heads.question_span_head.QuestionSpanHead'> from params {'end_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'start_output_layer': {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2}, 'training_style': 'soft_em'} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.input_dim = 2048\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.num_layers = 2\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.hidden_dims = [1024, 1]\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.hidden_dims = [1024, 1]\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu', 'linear'] and extras {'vocab'}\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.params - type = relu\n",
            "2022-04-23 02:40:16,865 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params linear and extras {'vocab'}\n",
            "2022-04-23 02:40:16,866 - INFO - allennlp.common.params - type = linear\n",
            "2022-04-23 02:40:16,866 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,866 - INFO - allennlp.common.params - model.heads.question_span.start_output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,883 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 1], 'input_dim': 2048, 'num_layers': 2} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,883 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.input_dim = 2048\n",
            "2022-04-23 02:40:16,883 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.num_layers = 2\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.hidden_dims = [1024, 1]\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.hidden_dims = [1024, 1]\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu', 'linear'] and extras {'vocab'}\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - type = relu\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params linear and extras {'vocab'}\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - type = linear\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,884 - INFO - allennlp.common.params - model.heads.question_span.end_output_layer.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.heads.question_span.training_style = soft_em\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.dataset_name = drop\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': ['relu', 'linear'], 'dropout': [0.1, 0], 'hidden_dims': [1024, 5], 'input_dim': 2048, 'num_layers': 2} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.head_predictor.input_dim = 2048\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.head_predictor.num_layers = 2\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.head_predictor.hidden_dims = [1024, 5]\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.head_predictor.hidden_dims = [1024, 5]\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.params - model.head_predictor.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,900 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params ['relu', 'linear'] and extras {'vocab'}\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.params - model.head_predictor.activations = ['relu', 'linear']\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params relu and extras {'vocab'}\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.params - type = relu\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.nn.activations.Activation'> from params linear and extras {'vocab'}\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.params - type = linear\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.params - model.head_predictor.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,901 - INFO - allennlp.common.params - model.head_predictor.dropout = [0.1, 0]\n",
            "2022-04-23 02:40:16,917 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,917 - INFO - allennlp.common.params - model.passage_summary_vector_module.input_dim = 1024\n",
            "2022-04-23 02:40:16,917 - INFO - allennlp.common.params - model.passage_summary_vector_module.num_layers = 1\n",
            "2022-04-23 02:40:16,917 - INFO - allennlp.common.params - model.passage_summary_vector_module.hidden_dims = 1\n",
            "2022-04-23 02:40:16,917 - INFO - allennlp.common.params - model.passage_summary_vector_module.activations = linear\n",
            "2022-04-23 02:40:16,917 - INFO - allennlp.common.params - model.passage_summary_vector_module.dropout = 0.0\n",
            "2022-04-23 02:40:16,918 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 1024, 'num_layers': 1} and extras {'vocab'}\n",
            "2022-04-23 02:40:16,918 - INFO - allennlp.common.params - model.question_summary_vector_module.input_dim = 1024\n",
            "2022-04-23 02:40:16,918 - INFO - allennlp.common.params - model.question_summary_vector_module.num_layers = 1\n",
            "2022-04-23 02:40:16,918 - INFO - allennlp.common.params - model.question_summary_vector_module.hidden_dims = 1\n",
            "2022-04-23 02:40:16,918 - INFO - allennlp.common.params - model.question_summary_vector_module.activations = linear\n",
            "2022-04-23 02:40:16,918 - INFO - allennlp.common.params - model.question_summary_vector_module.dropout = 0.0\n",
            "2022-04-23 02:40:16,919 - INFO - allennlp.common.params - model.training_evaluation = True\n",
            "2022-04-23 02:40:16,919 - INFO - allennlp.common.params - model.output_all_answers = False\n",
            "2022-04-23 02:40:17,812 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json not found in cache or force_download set to True, downloading to /tmp/tmpz8_gchi_\n",
            "2022-04-23 02:40:18,793 - INFO - transformers.file_utils - copying /tmp/tmpz8_gchi_ to cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n",
            "2022-04-23 02:40:18,793 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n",
            "2022-04-23 02:40:18,793 - INFO - transformers.file_utils - removing temp file /tmp/tmpz8_gchi_\n",
            "2022-04-23 02:40:18,794 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /root/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n",
            "2022-04-23 02:40:18,794 - INFO - transformers.configuration_utils - Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "2022-04-23 02:40:19,694 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpfpzqxup5\n",
            "2022-04-23 02:42:13,473 - INFO - transformers.file_utils - copying /tmp/tmpfpzqxup5 to cache at /root/.cache/torch/transformers/195c00f28dc68ef13a307c6db84d566f801f03b2b6bcf8b29524f10f767fac2a.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n",
            "2022-04-23 02:42:17,835 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/195c00f28dc68ef13a307c6db84d566f801f03b2b6bcf8b29524f10f767fac2a.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n",
            "2022-04-23 02:42:17,836 - INFO - transformers.file_utils - removing temp file /tmp/tmpfpzqxup5\n",
            "2022-04-23 02:42:17,996 - INFO - transformers.modeling_utils - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/195c00f28dc68ef13a307c6db84d566f801f03b2b6bcf8b29524f10f767fac2a.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n",
            "2022-04-23 02:42:26,587 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _head_predictor._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _head_predictor._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _head_predictor._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _head_predictor._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _heads.arithmetic._output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _heads.arithmetic._output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _heads.arithmetic._output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _heads.arithmetic._output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _heads.arithmetic._special_embeddings.weight\n",
            "2022-04-23 02:42:26,589 - INFO - allennlp.nn.initializers -    _heads.count._output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.count._output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.count._output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.count._output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.multi_span._output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.multi_span._output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.multi_span._output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.multi_span._output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.passage_span._end_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.passage_span._end_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.passage_span._start_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.passage_span._start_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.question_span._end_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.question_span._end_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.question_span._end_output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,590 - INFO - allennlp.nn.initializers -    _heads.question_span._end_output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _heads.question_span._start_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _heads.question_span._start_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _heads.question_span._start_output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _heads.question_span._start_output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _passage_summary_vector_module._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _passage_summary_vector_module._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _question_summary_vector_module._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _question_summary_vector_module._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.embeddings.LayerNorm.bias\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.embeddings.LayerNorm.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.embeddings.position_embeddings.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.embeddings.word_embeddings.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,591 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,592 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,593 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,594 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,595 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.self.key.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.self.key.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.self.query.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.self.query.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.self.value.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.attention.self.value.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.output.dense.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.12.output.dense.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,596 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.self.key.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.self.key.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.self.query.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.self.query.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.self.value.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.attention.self.value.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.output.dense.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.13.output.dense.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,597 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.self.key.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.self.key.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.self.query.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.self.query.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.self.value.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.attention.self.value.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.output.dense.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.14.output.dense.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,598 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.self.key.bias\n",
            "2022-04-23 02:42:26,599 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.self.key.weight\n",
            "2022-04-23 02:42:26,599 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.self.query.bias\n",
            "2022-04-23 02:42:26,599 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.self.query.weight\n",
            "2022-04-23 02:42:26,642 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.self.value.bias\n",
            "2022-04-23 02:42:26,642 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.attention.self.value.weight\n",
            "2022-04-23 02:42:26,642 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,642 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,642 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.output.dense.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.15.output.dense.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.self.key.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.self.key.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.self.query.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.self.query.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.self.value.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.attention.self.value.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,643 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.output.dense.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.16.output.dense.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.self.key.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.self.key.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.self.query.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.self.query.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.self.value.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.attention.self.value.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,644 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.output.dense.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.17.output.dense.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.self.key.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.self.key.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.self.query.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.self.query.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.self.value.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.attention.self.value.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,645 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.output.dense.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.18.output.dense.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.self.key.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.self.key.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.self.query.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.self.query.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.self.value.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.attention.self.value.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.output.dense.bias\n",
            "2022-04-23 02:42:26,646 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.19.output.dense.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-23 02:42:26,647 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.self.key.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.self.key.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.self.query.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.self.query.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.self.value.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.attention.self.value.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.output.dense.bias\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.20.output.dense.weight\n",
            "2022-04-23 02:42:26,648 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.self.key.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.self.key.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.self.query.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.self.query.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.self.value.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.attention.self.value.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,649 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.output.dense.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.21.output.dense.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.self.key.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.self.key.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.self.query.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.self.query.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.self.value.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.attention.self.value.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,650 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.output.dense.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.22.output.dense.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.self.key.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.self.key.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.self.query.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.self.query.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.self.value.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.attention.self.value.weight\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,651 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.output.dense.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.23.output.dense.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-23 02:42:26,652 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-23 02:42:26,653 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-23 02:42:26,654 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-23 02:42:26,655 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,656 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,657 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-23 02:42:26,658 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,659 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-23 02:42:26,660 - INFO - allennlp.nn.initializers -    _transformers_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-23 02:42:26,660 - INFO - allennlp.nn.initializers -    _transformers_model.pooler.dense.bias\n",
            "2022-04-23 02:42:26,660 - INFO - allennlp.nn.initializers -    _transformers_model.pooler.dense.weight\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 2, 'type': 'basic'} and extras set()\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.type = basic\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 2} and extras set()\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.batch_size = 2\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.cache_instances = False\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
            "2022-04-23 02:42:26,662 - INFO - allennlp.common.params - validation_iterator = None\n",
            "2022-04-23 02:42:26,663 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.embeddings.word_embeddings.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.embeddings.position_embeddings.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.embeddings.LayerNorm.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.embeddings.LayerNorm.bias\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-23 02:42:26,665 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,666 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-23 02:42:26,667 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,668 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-23 02:42:26,669 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-23 02:42:26,670 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-23 02:42:26,671 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,761 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,762 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-23 02:42:26,763 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-23 02:42:26,764 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-23 02:42:26,765 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.self.query.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.self.query.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.self.key.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.self.key.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.self.value.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.self.value.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.output.dense.weight\n",
            "2022-04-23 02:42:26,766 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.output.dense.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.12.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.self.query.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.self.query.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.self.key.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.self.key.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.self.value.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.self.value.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,767 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.output.dense.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.output.dense.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.13.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.self.query.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.self.query.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.self.key.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.self.key.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.self.value.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.self.value.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,768 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.output.dense.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.output.dense.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.14.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.self.query.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.self.query.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.self.key.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.self.key.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.self.value.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.self.value.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,769 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.output.dense.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.output.dense.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.15.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.self.query.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.self.query.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.self.key.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.self.key.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.self.value.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.self.value.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,770 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.output.dense.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.output.dense.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.16.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.self.query.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.self.query.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.self.key.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.self.key.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.self.value.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.self.value.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,771 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.output.dense.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.output.dense.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.17.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.self.query.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.self.query.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.self.key.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.self.key.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.self.value.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.self.value.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,772 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.output.dense.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.output.dense.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.18.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.self.query.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.self.query.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.self.key.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.self.key.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.self.value.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.self.value.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,773 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.output.dense.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.output.dense.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.19.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.self.query.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.self.query.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.self.key.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.self.key.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.self.value.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.self.value.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,774 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.output.dense.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.output.dense.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.20.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.self.query.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.self.query.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.self.key.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.self.key.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.self.value.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.self.value.bias\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,775 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.output.dense.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.output.dense.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.21.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.self.query.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.self.query.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.self.key.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.self.key.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.self.value.weight\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.self.value.bias\n",
            "2022-04-23 02:42:26,776 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.output.dense.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.output.dense.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.22.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.self.query.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.self.query.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.self.key.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.self.key.bias\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.self.value.weight\n",
            "2022-04-23 02:42:26,777 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.self.value.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.output.dense.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.output.dense.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.intermediate.dense.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.intermediate.dense.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.output.dense.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.output.dense.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.output.LayerNorm.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.encoder.layer.23.output.LayerNorm.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.pooler.dense.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _transformers_model.pooler.dense.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _heads.arithmetic._output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _heads.arithmetic._output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _heads.arithmetic._output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,778 - INFO - allennlp.training.trainer_pieces - _heads.arithmetic._output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.arithmetic._special_embeddings.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.count._output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.count._output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.count._output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.count._output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.multi_span._output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.multi_span._output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.multi_span._output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.multi_span._output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.passage_span._start_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.passage_span._start_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.passage_span._end_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,779 - INFO - allennlp.training.trainer_pieces - _heads.passage_span._end_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._start_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._start_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._start_output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._start_output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._end_output_layer._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._end_output_layer._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._end_output_layer._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _heads.question_span._end_output_layer._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _head_predictor._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _head_predictor._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _head_predictor._linear_layers.1.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _head_predictor._linear_layers.1.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _passage_summary_vector_module._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _passage_summary_vector_module._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,780 - INFO - allennlp.training.trainer_pieces - _question_summary_vector_module._linear_layers.0.weight\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.training.trainer_pieces - _question_summary_vector_module._linear_layers.0.bias\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.patience = 10\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.shuffle = True\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.num_epochs = 35\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2022-04-23 02:42:26,781 - INFO - allennlp.common.params - trainer.num_steps_to_accumulate = 6\n",
            "2022-04-23 02:42:36,339 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n",
            "2022-04-23 02:42:36,339 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2022-04-23 02:42:36,339 - INFO - allennlp.training.optimizers - Number of trainable parameters: 365881371\n",
            "2022-04-23 02:42:36,340 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n",
            "2022-04-23 02:42:36,340 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2022-04-23 02:42:36,340 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2022-04-23 02:42:36,340 - INFO - allennlp.common.params - trainer.optimizer.lr = 5e-06\n",
            "2022-04-23 02:42:36,340 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = 3600\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n",
            "2022-04-23 02:42:36,341 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n",
            "2022-04-23 02:42:36,343 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2022-04-23 02:42:36,343 - INFO - allennlp.training.trainer - Epoch 0/34\n",
            "2022-04-23 02:42:36,344 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8223.652\n",
            "2022-04-23 02:42:36,464 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 2728\n",
            "2022-04-23 02:42:36,468 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "2022-04-23 02:42:39,853 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n",
            "em: 0.0000, f1: 0.0173, em_spans: 0.0000, f1_spans: 0.0173, loss: 26.8460 ||: 100%|##########| 4/4 [00:12<00:00,  3.17s/it]\n",
            "2022-04-23 02:42:49,137 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.0000, f1: 0.0589, em_spans_multi_span: 0.0000, f1_spans_multi_span: 0.0000, em_spans: 0.0000, f1_spans: 0.0000, em_span: 0.0000, f1_span: 0.2650, em_multi_span: 0.0000, f1_multi_span: 0.0000, em_all_spans: 0.0000, f1_all_spans: 0.0589, loss: 1111122.1570 ||: 100%|##########| 9/9 [00:01<00:00,  5.87it/s]\n",
            "2022-04-23 02:42:50,672 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
            "2022-04-23 02:42:50,673 - INFO - allennlp.training.tensorboard_writer - _f1_passage_span            |     0.017  |     0.076\n",
            "2022-04-23 02:42:50,674 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span         |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,675 - INFO - allennlp.training.tensorboard_writer - f1_multi_span               |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,675 - INFO - allennlp.training.tensorboard_writer - _counter_span               |       N/A  |     4.000\n",
            "2022-04-23 02:42:50,676 - INFO - allennlp.training.tensorboard_writer - loss                        |    26.846  |  1111122.157\n",
            "2022-04-23 02:42:50,676 - INFO - allennlp.training.tensorboard_writer - _em_passage_span            |     0.000  |     0.000\n",
            "2022-04-23 02:42:50,676 - INFO - allennlp.training.tensorboard_writer - _counter_passage_span       |    48.000  |    14.000\n",
            "2022-04-23 02:42:50,676 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span         |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,677 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span   |       N/A  |     4.000\n",
            "2022-04-23 02:42:50,677 - INFO - allennlp.training.tensorboard_writer - _f1_spans_passage_span      |     0.017  |     0.000\n",
            "2022-04-23 02:42:50,677 - INFO - allennlp.training.tensorboard_writer - f1_span                     |       N/A  |     0.265\n",
            "2022-04-23 02:42:50,678 - INFO - allennlp.training.tensorboard_writer - _em_spans_passage_span      |     0.000  |     0.000\n",
            "2022-04-23 02:42:50,678 - INFO - allennlp.training.tensorboard_writer - f1                          |     0.017  |     0.059\n",
            "2022-04-23 02:42:50,680 - INFO - allennlp.training.tensorboard_writer - _em_span_passage_span       |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,681 - INFO - allennlp.training.tensorboard_writer - em_all_spans                |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,681 - INFO - allennlp.training.tensorboard_writer - em_spans                    |     0.000  |     0.000\n",
            "2022-04-23 02:42:50,681 - INFO - allennlp.training.tensorboard_writer - _counter_spans              |    48.000  |    14.000\n",
            "2022-04-23 02:42:50,681 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span         |       N/A  |     4.000\n",
            "2022-04-23 02:42:50,682 - INFO - allennlp.training.tensorboard_writer - f1_spans                    |     0.017  |     0.000\n",
            "2022-04-23 02:42:50,682 - INFO - allennlp.training.tensorboard_writer - f1_all_spans                |       N/A  |     0.059\n",
            "2022-04-23 02:42:50,683 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB               |  8223.652  |       N/A\n",
            "2022-04-23 02:42:50,684 - INFO - allennlp.training.tensorboard_writer - em                          |     0.000  |     0.000\n",
            "2022-04-23 02:42:50,684 - INFO - allennlp.training.tensorboard_writer - em_multi_span               |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,685 - INFO - allennlp.training.tensorboard_writer - _counter_spans_passage_span |    48.000  |    10.000\n",
            "2022-04-23 02:42:50,686 - INFO - allennlp.training.tensorboard_writer - em_span                     |       N/A  |     0.000\n",
            "2022-04-23 02:42:50,686 - INFO - allennlp.training.tensorboard_writer - _counter_span_passage_span  |       N/A  |     4.000\n",
            "2022-04-23 02:42:50,686 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |  2728.000  |       N/A\n",
            "2022-04-23 02:42:50,687 - INFO - allennlp.training.tensorboard_writer - _f1_span_passage_span       |       N/A  |     0.265\n",
            "2022-04-23 02:43:06,548 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:43:12,226 - INFO - allennlp.training.trainer - Epoch duration: 0:00:35.882016\n",
            "2022-04-23 02:43:12,226 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:20:20\n",
            "2022-04-23 02:43:12,226 - INFO - allennlp.training.trainer - Epoch 1/34\n",
            "2022-04-23 02:43:12,226 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:43:12,343 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:43:12,347 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.0000, f1: 0.0035, em_spans_multi_span: 0.0000, f1_spans_multi_span: 0.0000, em_spans: 0.0000, f1_spans: 0.0035, em_multi_span: 0.0000, f1_multi_span: 0.0000, loss: 10.1749 ||: 100%|##########| 4/4 [00:14<00:00,  3.55s/it]\n",
            "2022-04-23 02:43:26,540 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.0000, f1: 0.1806, em_span_multi_span: 0.0000, f1_span_multi_span: 0.3840, em_spans_multi_span: 0.0000, f1_spans_multi_span: 0.1023, em_span: 0.0000, f1_span: 0.3840, em_spans: 0.0000, f1_spans: 0.1023, em_multi_span: 0.0000, f1_multi_span: 0.1806, em_all_spans: 0.0000, f1_all_spans: 0.1806, loss: 1111122.5151 ||: 100%|##########| 9/9 [00:01<00:00,  5.33it/s]\n",
            "2022-04-23 02:43:28,231 - INFO - allennlp.training.tensorboard_writer -                                 Training |  Validation\n",
            "2022-04-23 02:43:28,231 - INFO - allennlp.training.tensorboard_writer - _f1_passage_span            |     0.024  |       N/A\n",
            "2022-04-23 02:43:28,232 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span         |     0.000  |     0.102\n",
            "2022-04-23 02:43:28,233 - INFO - allennlp.training.tensorboard_writer - f1_multi_span               |     0.000  |     0.181\n",
            "2022-04-23 02:43:28,233 - INFO - allennlp.training.tensorboard_writer - _counter_span               |       N/A  |     5.000\n",
            "2022-04-23 02:43:28,233 - INFO - allennlp.training.tensorboard_writer - loss                        |    10.175  |  1111122.515\n",
            "2022-04-23 02:43:28,233 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span   |    41.000  |    13.000\n",
            "2022-04-23 02:43:28,234 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span         |     0.000  |     0.000\n",
            "2022-04-23 02:43:28,235 - INFO - allennlp.training.tensorboard_writer - _em_passage_span            |     0.000  |       N/A\n",
            "2022-04-23 02:43:28,235 - INFO - allennlp.training.tensorboard_writer - _counter_passage_span       |     7.000  |       N/A\n",
            "2022-04-23 02:43:28,236 - INFO - allennlp.training.tensorboard_writer - _f1_spans_passage_span      |     0.024  |       N/A\n",
            "2022-04-23 02:43:28,237 - INFO - allennlp.training.tensorboard_writer - f1_span                     |       N/A  |     0.384\n",
            "2022-04-23 02:43:28,237 - INFO - allennlp.training.tensorboard_writer - _em_spans_passage_span      |     0.000  |       N/A\n",
            "2022-04-23 02:43:28,238 - INFO - allennlp.training.tensorboard_writer - f1                          |     0.004  |     0.181\n",
            "2022-04-23 02:43:28,239 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span          |       N/A  |     0.000\n",
            "2022-04-23 02:43:28,240 - INFO - allennlp.training.tensorboard_writer - em_all_spans                |       N/A  |     0.000\n",
            "2022-04-23 02:43:28,240 - INFO - allennlp.training.tensorboard_writer - em_spans                    |     0.000  |     0.000\n",
            "2022-04-23 02:43:28,240 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span         |    41.000  |    18.000\n",
            "2022-04-23 02:43:28,240 - INFO - allennlp.training.tensorboard_writer - _counter_spans              |    48.000  |    13.000\n",
            "2022-04-23 02:43:28,242 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span    |       N/A  |     5.000\n",
            "2022-04-23 02:43:28,242 - INFO - allennlp.training.tensorboard_writer - f1_spans                    |     0.004  |     0.102\n",
            "2022-04-23 02:43:28,242 - INFO - allennlp.training.tensorboard_writer - f1_all_spans                |       N/A  |     0.181\n",
            "2022-04-23 02:43:28,243 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB               |  8246.056  |       N/A\n",
            "2022-04-23 02:43:28,244 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span          |       N/A  |     0.384\n",
            "2022-04-23 02:43:28,244 - INFO - allennlp.training.tensorboard_writer - em                          |     0.000  |     0.000\n",
            "2022-04-23 02:43:28,244 - INFO - allennlp.training.tensorboard_writer - em_multi_span               |     0.000  |     0.000\n",
            "2022-04-23 02:43:28,245 - INFO - allennlp.training.tensorboard_writer - _counter_spans_passage_span |     7.000  |       N/A\n",
            "2022-04-23 02:43:28,246 - INFO - allennlp.training.tensorboard_writer - em_span                     |       N/A  |     0.000\n",
            "2022-04-23 02:43:28,246 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB             |  13076.000  |       N/A\n",
            "2022-04-23 02:43:44,612 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:43:50,906 - INFO - allennlp.training.trainer - Epoch duration: 0:00:38.679648\n",
            "2022-04-23 02:43:51,295 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:20:36\n",
            "2022-04-23 02:43:51,296 - INFO - allennlp.training.trainer - Epoch 2/34\n",
            "2022-04-23 02:43:51,296 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:43:51,398 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:43:51,402 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.0000, f1: 0.1256, em_spans_multi_span: 0.0000, f1_spans_multi_span: 0.1256, em_spans: 0.0000, f1_spans: 0.1256, em_multi_span: 0.0000, f1_multi_span: 0.1256, loss: 5.9166 ||: 100%|##########| 4/4 [00:14<00:00,  3.54s/it]\n",
            "2022-04-23 02:44:05,576 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.0000, f1: 0.1356, em_span_multi_span: 0.0000, f1_span_multi_span: 0.3640, em_spans_multi_span: 0.0000, f1_spans_multi_span: 0.0477, em_span: 0.0000, f1_span: 0.3640, em_spans: 0.0000, f1_spans: 0.0477, em_multi_span: 0.0000, f1_multi_span: 0.1356, em_all_spans: 0.0000, f1_all_spans: 0.1356, loss: 1111122.4583 ||: 100%|##########| 9/9 [00:01<00:00,  5.28it/s]\n",
            "2022-04-23 02:44:07,284 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:44:07,284 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.126  |     0.048\n",
            "2022-04-23 02:44:07,286 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.126  |     0.136\n",
            "2022-04-23 02:44:07,286 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     5.000\n",
            "2022-04-23 02:44:07,287 - INFO - allennlp.training.tensorboard_writer - loss                      |     5.917  |  1111122.458\n",
            "2022-04-23 02:44:07,287 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    13.000\n",
            "2022-04-23 02:44:07,288 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.000  |     0.000\n",
            "2022-04-23 02:44:07,288 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.364\n",
            "2022-04-23 02:44:07,288 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.126  |     0.136\n",
            "2022-04-23 02:44:07,289 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:44:07,289 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.000\n",
            "2022-04-23 02:44:07,289 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.000  |     0.000\n",
            "2022-04-23 02:44:07,289 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:44:07,290 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    13.000\n",
            "2022-04-23 02:44:07,290 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     5.000\n",
            "2022-04-23 02:44:07,292 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.126  |     0.048\n",
            "2022-04-23 02:44:07,292 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.136\n",
            "2022-04-23 02:44:07,293 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.364\n",
            "2022-04-23 02:44:07,293 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:44:07,295 - INFO - allennlp.training.tensorboard_writer - em                        |     0.000  |     0.000\n",
            "2022-04-23 02:44:07,295 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.000  |     0.000\n",
            "2022-04-23 02:44:07,296 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:44:07,296 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:44:23,151 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.855166\n",
            "2022-04-23 02:44:23,151 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:18:59\n",
            "2022-04-23 02:44:23,151 - INFO - allennlp.training.trainer - Epoch 3/34\n",
            "2022-04-23 02:44:23,151 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:44:23,265 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:44:23,269 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.0000, f1: 0.1875, em_spans_multi_span: 0.0000, f1_spans_multi_span: 0.1875, em_spans: 0.0000, f1_spans: 0.1875, em_multi_span: 0.0000, f1_multi_span: 0.1875, loss: 4.3430 ||: 100%|##########| 4/4 [00:14<00:00,  3.55s/it]\n",
            "2022-04-23 02:44:37,490 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2222, f1: 0.4544, em_spans_multi_span: 0.2222, f1_spans_multi_span: 0.4544, em_spans: 0.2222, f1_spans: 0.4544, em_multi_span: 0.2222, f1_multi_span: 0.4544, loss: 1111123.6780 ||: 100%|##########| 9/9 [00:01<00:00,  5.22it/s]\n",
            "2022-04-23 02:44:39,217 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:44:39,218 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:44:39,218 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.000  |     0.222\n",
            "2022-04-23 02:44:39,219 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.000  |     0.222\n",
            "2022-04-23 02:44:39,221 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:44:39,221 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.188  |     0.454\n",
            "2022-04-23 02:44:39,222 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.188  |     0.454\n",
            "2022-04-23 02:44:39,222 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.188  |     0.454\n",
            "2022-04-23 02:44:39,222 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.188  |     0.454\n",
            "2022-04-23 02:44:39,222 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:44:39,223 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:44:39,225 - INFO - allennlp.training.tensorboard_writer - em                        |     0.000  |     0.222\n",
            "2022-04-23 02:44:39,226 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.343  |  1111123.678\n",
            "2022-04-23 02:44:39,227 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.000  |     0.222\n",
            "2022-04-23 02:44:39,228 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:44:55,303 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:45:01,055 - INFO - allennlp.training.trainer - Epoch duration: 0:00:37.903300\n",
            "2022-04-23 02:45:01,069 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:18:41\n",
            "2022-04-23 02:45:01,070 - INFO - allennlp.training.trainer - Epoch 4/34\n",
            "2022-04-23 02:45:01,070 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:45:01,183 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:45:01,187 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.3542, f1: 0.6521, em_spans_multi_span: 0.3542, f1_spans_multi_span: 0.6521, em_spans: 0.3542, f1_spans: 0.6521, em_multi_span: 0.3542, f1_multi_span: 0.6521, loss: 3.7272 ||: 100%|##########| 4/4 [00:13<00:00,  3.44s/it]\n",
            "2022-04-23 02:45:14,946 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.1667, f1: 0.4722, em_spans_multi_span: 0.1667, f1_spans_multi_span: 0.4722, em_spans: 0.1667, f1_spans: 0.4722, em_multi_span: 0.1667, f1_multi_span: 0.4722, loss: 1111124.6137 ||: 100%|##########| 9/9 [00:01<00:00,  5.23it/s]\n",
            "2022-04-23 02:45:16,668 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:45:16,668 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:45:16,670 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.354  |     0.167\n",
            "2022-04-23 02:45:16,671 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.354  |     0.167\n",
            "2022-04-23 02:45:16,671 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:45:16,671 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.652  |     0.472\n",
            "2022-04-23 02:45:16,672 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.652  |     0.472\n",
            "2022-04-23 02:45:16,672 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.652  |     0.472\n",
            "2022-04-23 02:45:16,673 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.652  |     0.472\n",
            "2022-04-23 02:45:16,674 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:45:16,676 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:45:16,676 - INFO - allennlp.training.tensorboard_writer - em                        |     0.354  |     0.167\n",
            "2022-04-23 02:45:16,677 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.727  |  1111124.614\n",
            "2022-04-23 02:45:16,678 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.354  |     0.167\n",
            "2022-04-23 02:45:16,679 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:45:32,454 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:45:38,400 - INFO - allennlp.training.trainer - Epoch duration: 0:00:37.329983\n",
            "2022-04-23 02:45:38,400 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:18:12\n",
            "2022-04-23 02:45:38,400 - INFO - allennlp.training.trainer - Epoch 5/34\n",
            "2022-04-23 02:45:38,400 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:45:38,503 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:45:38,507 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.4375, f1: 0.7002, em_spans_multi_span: 0.4375, f1_spans_multi_span: 0.7002, em_spans: 0.4375, f1_spans: 0.7002, em_multi_span: 0.4375, f1_multi_span: 0.7002, loss: 3.0398 ||: 100%|##########| 4/4 [00:14<00:00,  3.53s/it]\n",
            "2022-04-23 02:45:52,629 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2222, f1: 0.4589, em_span_multi_span: 0.0000, f1_span_multi_span: 0.4000, em_spans_multi_span: 0.2500, f1_spans_multi_span: 0.4663, em_span: 0.0000, f1_span: 0.4000, em_spans: 0.2500, f1_spans: 0.4663, em_multi_span: 0.2222, f1_multi_span: 0.4589, em_all_spans: 0.2222, f1_all_spans: 0.4589, loss: 1111125.0701 ||: 100%|##########| 9/9 [00:01<00:00,  5.18it/s]\n",
            "2022-04-23 02:45:54,368 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:45:54,368 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.700  |     0.466\n",
            "2022-04-23 02:45:54,370 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.700  |     0.459\n",
            "2022-04-23 02:45:54,371 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     2.000\n",
            "2022-04-23 02:45:54,371 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.040  |  1111125.070\n",
            "2022-04-23 02:45:54,372 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    16.000\n",
            "2022-04-23 02:45:54,373 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.438  |     0.250\n",
            "2022-04-23 02:45:54,373 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.400\n",
            "2022-04-23 02:45:54,374 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.700  |     0.459\n",
            "2022-04-23 02:45:54,374 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:45:54,375 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.222\n",
            "2022-04-23 02:45:54,375 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.438  |     0.250\n",
            "2022-04-23 02:45:54,376 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:45:54,377 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    16.000\n",
            "2022-04-23 02:45:54,377 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     2.000\n",
            "2022-04-23 02:45:54,377 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.700  |     0.466\n",
            "2022-04-23 02:45:54,378 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.459\n",
            "2022-04-23 02:45:54,379 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.400\n",
            "2022-04-23 02:45:54,379 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:45:54,380 - INFO - allennlp.training.tensorboard_writer - em                        |     0.438  |     0.222\n",
            "2022-04-23 02:45:54,381 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.438  |     0.222\n",
            "2022-04-23 02:45:54,381 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:45:54,381 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:46:10,294 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.894373\n",
            "2022-04-23 02:46:10,295 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:17:14\n",
            "2022-04-23 02:46:10,295 - INFO - allennlp.training.trainer - Epoch 6/34\n",
            "2022-04-23 02:46:10,295 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:46:10,409 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:46:10,413 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.6458, f1: 0.7775, em_spans_multi_span: 0.6458, f1_spans_multi_span: 0.7775, em_spans: 0.6458, f1_spans: 0.7775, em_multi_span: 0.6458, f1_multi_span: 0.7775, loss: 2.0300 ||: 100%|##########| 4/4 [00:13<00:00,  3.44s/it]\n",
            "2022-04-23 02:46:24,195 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2222, f1: 0.5000, em_span_multi_span: 0.0000, f1_span_multi_span: 0.4000, em_spans_multi_span: 0.2500, f1_spans_multi_span: 0.5125, em_span: 0.0000, f1_span: 0.4000, em_spans: 0.2500, f1_spans: 0.5125, em_multi_span: 0.2222, f1_multi_span: 0.5000, em_all_spans: 0.2222, f1_all_spans: 0.5000, loss: 1111125.7285 ||: 100%|##########| 9/9 [00:01<00:00,  5.16it/s]\n",
            "2022-04-23 02:46:25,941 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:46:25,942 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.778  |     0.512\n",
            "2022-04-23 02:46:25,942 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.778  |     0.500\n",
            "2022-04-23 02:46:25,942 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     2.000\n",
            "2022-04-23 02:46:25,943 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.030  |  1111125.728\n",
            "2022-04-23 02:46:25,943 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    16.000\n",
            "2022-04-23 02:46:25,943 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.646  |     0.250\n",
            "2022-04-23 02:46:25,943 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.400\n",
            "2022-04-23 02:46:25,943 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.778  |     0.500\n",
            "2022-04-23 02:46:25,944 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:46:25,944 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.222\n",
            "2022-04-23 02:46:25,946 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.646  |     0.250\n",
            "2022-04-23 02:46:25,948 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:46:25,948 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    16.000\n",
            "2022-04-23 02:46:25,950 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     2.000\n",
            "2022-04-23 02:46:25,950 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.778  |     0.512\n",
            "2022-04-23 02:46:25,951 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.500\n",
            "2022-04-23 02:46:25,951 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.400\n",
            "2022-04-23 02:46:25,951 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:46:25,952 - INFO - allennlp.training.tensorboard_writer - em                        |     0.646  |     0.222\n",
            "2022-04-23 02:46:25,953 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.646  |     0.222\n",
            "2022-04-23 02:46:25,953 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:46:25,953 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:46:41,705 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:46:47,434 - INFO - allennlp.training.trainer - Epoch duration: 0:00:37.139507\n",
            "2022-04-23 02:46:47,435 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:16:44\n",
            "2022-04-23 02:46:47,435 - INFO - allennlp.training.trainer - Epoch 7/34\n",
            "2022-04-23 02:46:47,435 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:46:47,539 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:46:47,543 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.5208, f1: 0.7410, em_spans_multi_span: 0.5208, f1_spans_multi_span: 0.7410, em_spans: 0.5208, f1_spans: 0.7410, em_multi_span: 0.5208, f1_multi_span: 0.7410, loss: 1.8143 ||: 100%|##########| 4/4 [00:14<00:00,  3.51s/it]\n",
            "2022-04-23 02:47:01,599 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.1111, f1: 0.3139, em_span_multi_span: 0.0000, f1_span_multi_span: 0.4000, em_spans_multi_span: 0.1250, f1_spans_multi_span: 0.3031, em_span: 0.0000, f1_span: 0.4000, em_spans: 0.1250, f1_spans: 0.3031, em_multi_span: 0.1111, f1_multi_span: 0.3139, em_all_spans: 0.1111, f1_all_spans: 0.3139, loss: 1111126.3197 ||: 100%|##########| 9/9 [00:01<00:00,  5.14it/s]\n",
            "2022-04-23 02:47:03,353 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:47:03,354 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.741  |     0.303\n",
            "2022-04-23 02:47:03,354 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.741  |     0.314\n",
            "2022-04-23 02:47:03,355 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     2.000\n",
            "2022-04-23 02:47:03,355 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.814  |  1111126.320\n",
            "2022-04-23 02:47:03,356 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    16.000\n",
            "2022-04-23 02:47:03,356 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.521  |     0.125\n",
            "2022-04-23 02:47:03,357 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.400\n",
            "2022-04-23 02:47:03,357 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.741  |     0.314\n",
            "2022-04-23 02:47:03,357 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:47:03,357 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.111\n",
            "2022-04-23 02:47:03,359 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.521  |     0.125\n",
            "2022-04-23 02:47:03,360 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:47:03,361 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    16.000\n",
            "2022-04-23 02:47:03,362 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     2.000\n",
            "2022-04-23 02:47:03,363 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.741  |     0.303\n",
            "2022-04-23 02:47:03,363 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.314\n",
            "2022-04-23 02:47:03,364 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.400\n",
            "2022-04-23 02:47:03,364 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:47:03,365 - INFO - allennlp.training.tensorboard_writer - em                        |     0.521  |     0.111\n",
            "2022-04-23 02:47:03,365 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.521  |     0.111\n",
            "2022-04-23 02:47:03,366 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:47:03,367 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:47:19,517 - INFO - allennlp.training.trainer - Epoch duration: 0:00:32.081925\n",
            "2022-04-23 02:47:19,517 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:15:55\n",
            "2022-04-23 02:47:19,517 - INFO - allennlp.training.trainer - Epoch 8/34\n",
            "2022-04-23 02:47:19,517 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:47:19,630 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:47:19,635 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.6042, f1: 0.7617, em_spans_multi_span: 0.6042, f1_spans_multi_span: 0.7617, em_spans: 0.6042, f1_spans: 0.7617, em_multi_span: 0.6042, f1_multi_span: 0.7617, loss: 2.0928 ||: 100%|##########| 4/4 [00:13<00:00,  3.48s/it]\n",
            "2022-04-23 02:47:33,558 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.1111, f1: 0.4950, em_spans_multi_span: 0.1111, f1_spans_multi_span: 0.4950, em_spans: 0.1111, f1_spans: 0.4950, em_multi_span: 0.1111, f1_multi_span: 0.4950, loss: 1111126.4847 ||: 100%|##########| 9/9 [00:01<00:00,  5.04it/s]\n",
            "2022-04-23 02:47:35,345 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:47:35,346 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:47:35,347 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.604  |     0.111\n",
            "2022-04-23 02:47:35,347 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.604  |     0.111\n",
            "2022-04-23 02:47:35,348 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:47:35,348 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.762  |     0.495\n",
            "2022-04-23 02:47:35,349 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.762  |     0.495\n",
            "2022-04-23 02:47:35,350 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.762  |     0.495\n",
            "2022-04-23 02:47:35,351 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.762  |     0.495\n",
            "2022-04-23 02:47:35,351 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:47:35,352 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:47:35,352 - INFO - allennlp.training.tensorboard_writer - em                        |     0.604  |     0.111\n",
            "2022-04-23 02:47:35,352 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.093  |  1111126.485\n",
            "2022-04-23 02:47:35,352 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.604  |     0.111\n",
            "2022-04-23 02:47:35,352 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:47:51,248 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.731353\n",
            "2022-04-23 02:47:51,730 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:15:11\n",
            "2022-04-23 02:47:51,730 - INFO - allennlp.training.trainer - Epoch 9/34\n",
            "2022-04-23 02:47:51,730 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:47:51,850 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:47:51,855 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.6875, f1: 0.7869, em_spans_multi_span: 0.6875, f1_spans_multi_span: 0.7869, em_spans: 0.6875, f1_spans: 0.7869, em_multi_span: 0.6875, f1_multi_span: 0.7869, loss: 1.7962 ||: 100%|##########| 4/4 [00:13<00:00,  3.46s/it]\n",
            "2022-04-23 02:48:05,696 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.1667, f1: 0.3883, em_span_multi_span: 0.0000, f1_span_multi_span: 0.4900, em_spans_multi_span: 0.2000, f1_spans_multi_span: 0.3680, em_span: 0.0000, f1_span: 0.4900, em_spans: 0.2000, f1_spans: 0.3680, em_multi_span: 0.1667, f1_multi_span: 0.3883, em_all_spans: 0.1667, f1_all_spans: 0.3883, loss: 1111127.0361 ||: 100%|##########| 9/9 [00:01<00:00,  5.09it/s]\n",
            "2022-04-23 02:48:07,466 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:48:07,467 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.787  |     0.368\n",
            "2022-04-23 02:48:07,468 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.787  |     0.388\n",
            "2022-04-23 02:48:07,469 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     3.000\n",
            "2022-04-23 02:48:07,469 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.796  |  1111127.036\n",
            "2022-04-23 02:48:07,469 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    15.000\n",
            "2022-04-23 02:48:07,469 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.688  |     0.200\n",
            "2022-04-23 02:48:07,469 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.490\n",
            "2022-04-23 02:48:07,470 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.787  |     0.388\n",
            "2022-04-23 02:48:07,470 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:48:07,471 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.167\n",
            "2022-04-23 02:48:07,471 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.688  |     0.200\n",
            "2022-04-23 02:48:07,472 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:48:07,473 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    15.000\n",
            "2022-04-23 02:48:07,474 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     3.000\n",
            "2022-04-23 02:48:07,474 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.787  |     0.368\n",
            "2022-04-23 02:48:07,475 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.388\n",
            "2022-04-23 02:48:07,475 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.490\n",
            "2022-04-23 02:48:07,475 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:48:07,476 - INFO - allennlp.training.tensorboard_writer - em                        |     0.688  |     0.167\n",
            "2022-04-23 02:48:07,477 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.688  |     0.167\n",
            "2022-04-23 02:48:07,477 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:48:07,477 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:48:23,242 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.511497\n",
            "2022-04-23 02:48:23,242 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:14:27\n",
            "2022-04-23 02:48:23,242 - INFO - allennlp.training.trainer - Epoch 10/34\n",
            "2022-04-23 02:48:23,242 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:48:23,690 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:48:23,694 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.7708, f1: 0.8533, em_spans_multi_span: 0.7708, f1_spans_multi_span: 0.8533, em_spans: 0.7708, f1_spans: 0.8533, em_multi_span: 0.7708, f1_multi_span: 0.8533, loss: 2.9451 ||: 100%|##########| 4/4 [00:14<00:00,  3.51s/it]\n",
            "2022-04-23 02:48:37,747 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.1667, f1: 0.4983, em_spans_multi_span: 0.1667, f1_spans_multi_span: 0.4983, em_spans: 0.1667, f1_spans: 0.4983, em_multi_span: 0.1667, f1_multi_span: 0.4983, loss: 1111126.8806 ||: 100%|##########| 9/9 [00:01<00:00,  5.11it/s]\n",
            "2022-04-23 02:48:39,512 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:48:39,519 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:48:39,520 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.771  |     0.167\n",
            "2022-04-23 02:48:39,521 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.771  |     0.167\n",
            "2022-04-23 02:48:39,522 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:48:39,524 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.853  |     0.498\n",
            "2022-04-23 02:48:39,525 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.853  |     0.498\n",
            "2022-04-23 02:48:39,526 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.853  |     0.498\n",
            "2022-04-23 02:48:39,526 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.853  |     0.498\n",
            "2022-04-23 02:48:39,526 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:48:39,527 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:48:39,527 - INFO - allennlp.training.tensorboard_writer - em                        |     0.771  |     0.167\n",
            "2022-04-23 02:48:39,528 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.945  |  1111126.881\n",
            "2022-04-23 02:48:39,529 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.771  |     0.167\n",
            "2022-04-23 02:48:39,530 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:48:55,373 - INFO - allennlp.training.trainer - Epoch duration: 0:00:32.130207\n",
            "2022-04-23 02:48:55,373 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:46\n",
            "2022-04-23 02:48:55,373 - INFO - allennlp.training.trainer - Epoch 11/34\n",
            "2022-04-23 02:48:55,373 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:48:55,482 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:48:55,486 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.7500, f1: 0.8467, em_spans_multi_span: 0.7500, f1_spans_multi_span: 0.8467, em_spans: 0.7500, f1_spans: 0.8467, em_multi_span: 0.7500, f1_multi_span: 0.8467, loss: 0.3468 ||: 100%|##########| 4/4 [00:13<00:00,  3.40s/it]\n",
            "2022-04-23 02:49:09,081 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.1111, f1: 0.2950, em_spans_multi_span: 0.1176, f1_spans_multi_span: 0.2729, em_span_multi_span: 0.0000, f1_span_multi_span: 0.6700, em_spans: 0.1176, f1_spans: 0.2729, em_span: 0.0000, f1_span: 0.6700, em_multi_span: 0.1111, f1_multi_span: 0.2950, em_all_spans: 0.1111, f1_all_spans: 0.2950, loss: 1111126.5899 ||: 100%|##########| 9/9 [00:01<00:00,  5.07it/s]\n",
            "2022-04-23 02:49:10,860 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:49:10,860 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.847  |     0.273\n",
            "2022-04-23 02:49:10,861 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.847  |     0.295\n",
            "2022-04-23 02:49:10,862 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     1.000\n",
            "2022-04-23 02:49:10,862 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.347  |  1111126.590\n",
            "2022-04-23 02:49:10,862 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    17.000\n",
            "2022-04-23 02:49:10,863 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.750  |     0.118\n",
            "2022-04-23 02:49:10,863 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.670\n",
            "2022-04-23 02:49:10,863 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.847  |     0.295\n",
            "2022-04-23 02:49:10,864 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:49:10,864 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.111\n",
            "2022-04-23 02:49:10,865 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.750  |     0.118\n",
            "2022-04-23 02:49:10,866 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:49:10,867 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    17.000\n",
            "2022-04-23 02:49:10,867 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     1.000\n",
            "2022-04-23 02:49:10,868 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.847  |     0.273\n",
            "2022-04-23 02:49:10,868 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.295\n",
            "2022-04-23 02:49:10,869 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.670\n",
            "2022-04-23 02:49:10,869 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:49:10,870 - INFO - allennlp.training.tensorboard_writer - em                        |     0.750  |     0.111\n",
            "2022-04-23 02:49:10,870 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.750  |     0.111\n",
            "2022-04-23 02:49:10,872 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:49:10,873 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:49:26,731 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.357869\n",
            "2022-04-23 02:49:26,757 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:06\n",
            "2022-04-23 02:49:26,757 - INFO - allennlp.training.trainer - Epoch 12/34\n",
            "2022-04-23 02:49:26,757 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:49:26,874 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:49:26,878 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.7708, f1: 0.8323, em_spans_multi_span: 0.7708, f1_spans_multi_span: 0.8323, em_spans: 0.7708, f1_spans: 0.8323, em_multi_span: 0.7708, f1_multi_span: 0.8323, loss: 0.7074 ||: 100%|##########| 4/4 [00:13<00:00,  3.44s/it]\n",
            "2022-04-23 02:49:40,649 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2778, f1: 0.5494, em_spans_multi_span: 0.2778, f1_spans_multi_span: 0.5494, em_spans: 0.2778, f1_spans: 0.5494, em_multi_span: 0.2778, f1_multi_span: 0.5494, loss: 1111127.2471 ||: 100%|##########| 9/9 [00:01<00:00,  5.04it/s]\n",
            "2022-04-23 02:49:42,438 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:49:42,439 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:49:42,440 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.771  |     0.278\n",
            "2022-04-23 02:49:42,441 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.771  |     0.278\n",
            "2022-04-23 02:49:42,442 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:49:42,443 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.832  |     0.549\n",
            "2022-04-23 02:49:42,443 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.832  |     0.549\n",
            "2022-04-23 02:49:42,443 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.832  |     0.549\n",
            "2022-04-23 02:49:42,443 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.832  |     0.549\n",
            "2022-04-23 02:49:42,444 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:49:42,444 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:49:42,446 - INFO - allennlp.training.tensorboard_writer - em                        |     0.771  |     0.278\n",
            "2022-04-23 02:49:42,447 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.707  |  1111127.247\n",
            "2022-04-23 02:49:42,447 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.771  |     0.278\n",
            "2022-04-23 02:49:42,448 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:49:58,428 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:50:04,137 - INFO - allennlp.training.trainer - Epoch duration: 0:00:37.379936\n",
            "2022-04-23 02:50:04,137 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:12:37\n",
            "2022-04-23 02:50:04,137 - INFO - allennlp.training.trainer - Epoch 13/34\n",
            "2022-04-23 02:50:04,137 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:50:04,252 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:50:04,256 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8333, f1: 0.8923, em_spans_multi_span: 0.8333, f1_spans_multi_span: 0.8923, em_spans: 0.8333, f1_spans: 0.8923, em_multi_span: 0.8333, f1_multi_span: 0.8923, loss: 0.0400 ||: 100%|##########| 4/4 [00:14<00:00,  3.51s/it]\n",
            "2022-04-23 02:50:18,304 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2222, f1: 0.3817, em_spans_multi_span: 0.2353, f1_spans_multi_span: 0.3647, em_span_multi_span: 0.0000, f1_span_multi_span: 0.6700, em_spans: 0.2353, f1_spans: 0.3647, em_span: 0.0000, f1_span: 0.6700, em_multi_span: 0.2222, f1_multi_span: 0.3817, em_all_spans: 0.2222, f1_all_spans: 0.3817, loss: 1111127.0304 ||: 100%|##########| 9/9 [00:01<00:00,  5.07it/s]\n",
            "2022-04-23 02:50:20,082 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:50:20,082 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.892  |     0.365\n",
            "2022-04-23 02:50:20,084 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.892  |     0.382\n",
            "2022-04-23 02:50:20,085 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     1.000\n",
            "2022-04-23 02:50:20,085 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.040  |  1111127.030\n",
            "2022-04-23 02:50:20,086 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    17.000\n",
            "2022-04-23 02:50:20,087 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.833  |     0.235\n",
            "2022-04-23 02:50:20,087 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.670\n",
            "2022-04-23 02:50:20,087 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.892  |     0.382\n",
            "2022-04-23 02:50:20,088 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:50:20,088 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.222\n",
            "2022-04-23 02:50:20,088 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.833  |     0.235\n",
            "2022-04-23 02:50:20,090 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:50:20,090 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    17.000\n",
            "2022-04-23 02:50:20,090 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     1.000\n",
            "2022-04-23 02:50:20,091 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.892  |     0.365\n",
            "2022-04-23 02:50:20,091 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.382\n",
            "2022-04-23 02:50:20,091 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.670\n",
            "2022-04-23 02:50:20,092 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:50:20,092 - INFO - allennlp.training.tensorboard_writer - em                        |     0.833  |     0.222\n",
            "2022-04-23 02:50:20,092 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.833  |     0.222\n",
            "2022-04-23 02:50:20,093 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:50:20,093 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:50:35,893 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.756102\n",
            "2022-04-23 02:50:35,894 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:59\n",
            "2022-04-23 02:50:35,894 - INFO - allennlp.training.trainer - Epoch 14/34\n",
            "2022-04-23 02:50:35,894 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:50:36,014 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:50:36,019 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8333, f1: 0.8677, em_spans_multi_span: 0.8333, f1_spans_multi_span: 0.8677, em_spans: 0.8333, f1_spans: 0.8677, em_multi_span: 0.8333, f1_multi_span: 0.8677, loss: 1.7489 ||: 100%|##########| 4/4 [00:13<00:00,  3.39s/it]\n",
            "2022-04-23 02:50:49,581 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.4878, em_spans_multi_span: 0.3333, f1_spans_multi_span: 0.4878, em_spans: 0.3333, f1_spans: 0.4878, em_multi_span: 0.3333, f1_multi_span: 0.4878, loss: 1111126.6536 ||: 100%|##########| 9/9 [00:01<00:00,  5.08it/s]\n",
            "2022-04-23 02:50:51,355 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:50:51,355 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:50:51,357 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.833  |     0.333\n",
            "2022-04-23 02:50:51,357 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.833  |     0.333\n",
            "2022-04-23 02:50:51,357 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:50:51,358 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.868  |     0.488\n",
            "2022-04-23 02:50:51,358 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.868  |     0.488\n",
            "2022-04-23 02:50:51,358 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.868  |     0.488\n",
            "2022-04-23 02:50:51,358 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.868  |     0.488\n",
            "2022-04-23 02:50:51,358 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:50:51,359 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:50:51,359 - INFO - allennlp.training.tensorboard_writer - em                        |     0.833  |     0.333\n",
            "2022-04-23 02:50:51,361 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.749  |  1111126.654\n",
            "2022-04-23 02:50:51,362 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.833  |     0.333\n",
            "2022-04-23 02:50:51,362 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:51:07,468 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.574327\n",
            "2022-04-23 02:51:07,470 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:21\n",
            "2022-04-23 02:51:07,470 - INFO - allennlp.training.trainer - Epoch 15/34\n",
            "2022-04-23 02:51:07,470 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:51:07,598 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:51:07,602 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8958, f1: 0.9140, em_spans_multi_span: 0.8958, f1_spans_multi_span: 0.9140, em_spans: 0.8958, f1_spans: 0.9140, em_multi_span: 0.8958, f1_multi_span: 0.9140, loss: 0.1490 ||: 100%|##########| 4/4 [00:13<00:00,  3.50s/it]\n",
            "2022-04-23 02:51:21,598 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2222, f1: 0.5372, em_spans_multi_span: 0.2222, f1_spans_multi_span: 0.5372, em_spans: 0.2222, f1_spans: 0.5372, em_multi_span: 0.2222, f1_multi_span: 0.5372, loss: 1111127.1012 ||: 100%|##########| 9/9 [00:01<00:00,  5.06it/s]\n",
            "2022-04-23 02:51:23,379 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:51:23,380 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:51:23,380 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.896  |     0.222\n",
            "2022-04-23 02:51:23,380 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.896  |     0.222\n",
            "2022-04-23 02:51:23,380 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:51:23,381 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.914  |     0.537\n",
            "2022-04-23 02:51:23,381 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.914  |     0.537\n",
            "2022-04-23 02:51:23,383 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.914  |     0.537\n",
            "2022-04-23 02:51:23,384 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.914  |     0.537\n",
            "2022-04-23 02:51:23,384 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:51:23,384 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:51:23,385 - INFO - allennlp.training.tensorboard_writer - em                        |     0.896  |     0.222\n",
            "2022-04-23 02:51:23,385 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.149  |  1111127.101\n",
            "2022-04-23 02:51:23,386 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.896  |     0.222\n",
            "2022-04-23 02:51:23,387 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:51:39,234 - INFO - allennlp.training.trainer - Epoch duration: 0:00:31.763575\n",
            "2022-04-23 02:51:39,234 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:44\n",
            "2022-04-23 02:51:39,234 - INFO - allennlp.training.trainer - Epoch 16/34\n",
            "2022-04-23 02:51:39,234 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:51:39,349 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:51:39,353 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8958, f1: 0.9508, em_spans_multi_span: 0.8958, f1_spans_multi_span: 0.9508, em_spans: 0.8958, f1_spans: 0.9508, em_multi_span: 0.8958, f1_multi_span: 0.9508, loss: 0.9847 ||: 100%|##########| 4/4 [00:14<00:00,  3.54s/it]\n",
            "2022-04-23 02:51:53,501 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6228, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6228, em_spans: 0.3889, f1_spans: 0.6228, em_multi_span: 0.3889, f1_multi_span: 0.6228, loss: 1111127.7801 ||: 100%|##########| 9/9 [00:01<00:00,  5.08it/s]\n",
            "2022-04-23 02:51:55,276 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:51:55,277 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:51:55,278 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.896  |     0.389\n",
            "2022-04-23 02:51:55,279 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.896  |     0.389\n",
            "2022-04-23 02:51:55,279 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:51:55,279 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.951  |     0.623\n",
            "2022-04-23 02:51:55,280 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.951  |     0.623\n",
            "2022-04-23 02:51:55,280 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.951  |     0.623\n",
            "2022-04-23 02:51:55,280 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.951  |     0.623\n",
            "2022-04-23 02:51:55,281 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:51:55,281 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:51:55,282 - INFO - allennlp.training.tensorboard_writer - em                        |     0.896  |     0.389\n",
            "2022-04-23 02:51:55,282 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.985  |  1111127.780\n",
            "2022-04-23 02:51:55,284 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.896  |     0.389\n",
            "2022-04-23 02:51:55,284 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:52:11,435 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:52:16,872 - INFO - allennlp.training.trainer - Epoch duration: 0:00:37.638255\n",
            "2022-04-23 02:52:16,873 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:14\n",
            "2022-04-23 02:52:16,873 - INFO - allennlp.training.trainer - Epoch 17/34\n",
            "2022-04-23 02:52:16,873 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:52:16,990 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:52:16,994 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9375, f1: 0.9781, em_spans_multi_span: 0.9375, f1_spans_multi_span: 0.9781, em_spans: 0.9375, f1_spans: 0.9781, em_multi_span: 0.9375, f1_multi_span: 0.9781, loss: 0.9766 ||: 100%|##########| 4/4 [00:14<00:00,  3.52s/it]\n",
            "2022-04-23 02:52:31,060 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6378, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6378, em_spans: 0.3889, f1_spans: 0.6378, em_multi_span: 0.3889, f1_multi_span: 0.6378, loss: 1111127.4377 ||: 100%|##########| 9/9 [00:01<00:00,  5.03it/s]\n",
            "2022-04-23 02:52:32,851 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:52:32,852 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:52:32,854 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.938  |     0.389\n",
            "2022-04-23 02:52:32,854 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.938  |     0.389\n",
            "2022-04-23 02:52:32,855 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:52:32,855 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.978  |     0.638\n",
            "2022-04-23 02:52:32,856 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.978  |     0.638\n",
            "2022-04-23 02:52:32,856 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.978  |     0.638\n",
            "2022-04-23 02:52:32,856 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.978  |     0.638\n",
            "2022-04-23 02:52:32,857 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:52:32,859 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:52:32,859 - INFO - allennlp.training.tensorboard_writer - em                        |     0.938  |     0.389\n",
            "2022-04-23 02:52:32,860 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.977  |  1111127.438\n",
            "2022-04-23 02:52:32,860 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.938  |     0.389\n",
            "2022-04-23 02:52:32,860 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:52:48,812 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:53:07,797 - INFO - allennlp.training.trainer - Epoch duration: 0:00:50.924419\n",
            "2022-04-23 02:53:07,798 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:56\n",
            "2022-04-23 02:53:07,798 - INFO - allennlp.training.trainer - Epoch 18/34\n",
            "2022-04-23 02:53:07,798 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:53:07,907 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:53:07,910 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8542, f1: 0.9169, em_spans_multi_span: 0.8542, f1_spans_multi_span: 0.9169, em_spans: 0.8542, f1_spans: 0.9169, em_multi_span: 0.8542, f1_multi_span: 0.9169, loss: 0.2867 ||: 100%|##########| 4/4 [00:13<00:00,  3.43s/it]\n",
            "2022-04-23 02:53:21,625 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2778, f1: 0.4711, em_spans_multi_span: 0.2778, f1_spans_multi_span: 0.4711, em_spans: 0.2778, f1_spans: 0.4711, em_multi_span: 0.2778, f1_multi_span: 0.4711, loss: 1111127.3229 ||: 100%|##########| 9/9 [00:01<00:00,  5.12it/s]\n",
            "2022-04-23 02:53:23,385 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:53:23,385 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:53:23,387 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.854  |     0.278\n",
            "2022-04-23 02:53:23,387 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.854  |     0.278\n",
            "2022-04-23 02:53:23,387 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:53:23,389 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.917  |     0.471\n",
            "2022-04-23 02:53:23,389 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.917  |     0.471\n",
            "2022-04-23 02:53:23,390 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.917  |     0.471\n",
            "2022-04-23 02:53:23,391 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.917  |     0.471\n",
            "2022-04-23 02:53:23,391 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:53:23,392 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:53:23,392 - INFO - allennlp.training.tensorboard_writer - em                        |     0.854  |     0.278\n",
            "2022-04-23 02:53:23,393 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.287  |  1111127.323\n",
            "2022-04-23 02:53:23,393 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.854  |     0.278\n",
            "2022-04-23 02:53:23,394 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:53:55,210 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.412353\n",
            "2022-04-23 02:53:55,210 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:31\n",
            "2022-04-23 02:53:55,211 - INFO - allennlp.training.trainer - Epoch 19/34\n",
            "2022-04-23 02:53:55,211 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:53:55,320 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:53:55,324 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8542, f1: 0.9231, em_spans_multi_span: 0.8542, f1_spans_multi_span: 0.9231, em_spans: 0.8542, f1_spans: 0.9231, em_multi_span: 0.8542, f1_multi_span: 0.9231, loss: 0.7841 ||: 100%|##########| 4/4 [00:13<00:00,  3.50s/it]\n",
            "2022-04-23 02:54:09,318 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6439, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6439, em_spans: 0.3889, f1_spans: 0.6439, em_multi_span: 0.3889, f1_multi_span: 0.6439, loss: 1111126.6936 ||: 100%|##########| 9/9 [00:01<00:00,  5.09it/s]\n",
            "2022-04-23 02:54:11,089 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:54:11,089 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:54:11,091 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.854  |     0.389\n",
            "2022-04-23 02:54:11,091 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.854  |     0.389\n",
            "2022-04-23 02:54:11,092 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:54:11,092 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.923  |     0.644\n",
            "2022-04-23 02:54:11,092 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.923  |     0.644\n",
            "2022-04-23 02:54:11,093 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.923  |     0.644\n",
            "2022-04-23 02:54:11,093 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.923  |     0.644\n",
            "2022-04-23 02:54:11,093 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:54:11,093 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:54:11,094 - INFO - allennlp.training.tensorboard_writer - em                        |     0.854  |     0.389\n",
            "2022-04-23 02:54:11,094 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.784  |  1111126.694\n",
            "2022-04-23 02:54:11,094 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.854  |     0.389\n",
            "2022-04-23 02:54:11,096 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:54:39,112 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:54:57,430 - INFO - allennlp.training.trainer - Epoch duration: 0:01:02.219338\n",
            "2022-04-23 02:54:57,430 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:15\n",
            "2022-04-23 02:54:57,430 - INFO - allennlp.training.trainer - Epoch 20/34\n",
            "2022-04-23 02:54:57,430 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:54:57,537 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:54:57,540 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8333, f1: 0.9031, em_spans_multi_span: 0.8333, f1_spans_multi_span: 0.9031, em_spans: 0.8333, f1_spans: 0.9031, em_multi_span: 0.8333, f1_multi_span: 0.9031, loss: 0.4335 ||: 100%|##########| 4/4 [00:13<00:00,  3.44s/it]\n",
            "2022-04-23 02:55:11,307 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.5000, f1: 0.6450, em_spans_multi_span: 0.5000, f1_spans_multi_span: 0.6450, em_spans: 0.5000, f1_spans: 0.6450, em_multi_span: 0.5000, f1_multi_span: 0.6450, loss: 1111126.8393 ||: 100%|##########| 9/9 [00:01<00:00,  5.15it/s]\n",
            "2022-04-23 02:55:13,056 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:55:13,057 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:55:13,057 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.833  |     0.500\n",
            "2022-04-23 02:55:13,059 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.833  |     0.500\n",
            "2022-04-23 02:55:13,060 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:55:13,061 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.903  |     0.645\n",
            "2022-04-23 02:55:13,061 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.903  |     0.645\n",
            "2022-04-23 02:55:13,062 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.903  |     0.645\n",
            "2022-04-23 02:55:13,062 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.903  |     0.645\n",
            "2022-04-23 02:55:13,063 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:55:13,064 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:55:13,065 - INFO - allennlp.training.tensorboard_writer - em                        |     0.833  |     0.500\n",
            "2022-04-23 02:55:13,065 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.434  |  1111126.839\n",
            "2022-04-23 02:55:13,065 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.833  |     0.500\n",
            "2022-04-23 02:55:13,066 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:55:42,529 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 02:55:58,353 - INFO - allennlp.training.trainer - Epoch duration: 0:01:00.922532\n",
            "2022-04-23 02:55:58,354 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:08:54\n",
            "2022-04-23 02:55:58,354 - INFO - allennlp.training.trainer - Epoch 21/34\n",
            "2022-04-23 02:55:58,354 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:55:58,458 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:55:58,462 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8750, f1: 0.9546, em_spans_multi_span: 0.8750, f1_spans_multi_span: 0.9546, em_spans: 0.8750, f1_spans: 0.9546, em_multi_span: 0.8750, f1_multi_span: 0.9546, loss: 0.2217 ||: 100%|##########| 4/4 [00:13<00:00,  3.43s/it]\n",
            "2022-04-23 02:56:12,192 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.6033, em_spans_multi_span: 0.3333, f1_spans_multi_span: 0.6033, em_spans: 0.3333, f1_spans: 0.6033, em_multi_span: 0.3333, f1_multi_span: 0.6033, loss: 1111127.5558 ||: 100%|##########| 9/9 [00:01<00:00,  5.14it/s]\n",
            "2022-04-23 02:56:13,946 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:56:13,946 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:56:13,948 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.875  |     0.333\n",
            "2022-04-23 02:56:13,949 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.875  |     0.333\n",
            "2022-04-23 02:56:13,950 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:56:13,950 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.955  |     0.603\n",
            "2022-04-23 02:56:13,950 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.955  |     0.603\n",
            "2022-04-23 02:56:13,951 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.955  |     0.603\n",
            "2022-04-23 02:56:13,951 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.955  |     0.603\n",
            "2022-04-23 02:56:13,951 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:56:13,951 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:56:13,951 - INFO - allennlp.training.tensorboard_writer - em                        |     0.875  |     0.333\n",
            "2022-04-23 02:56:13,952 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.222  |  1111127.556\n",
            "2022-04-23 02:56:13,952 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.875  |     0.333\n",
            "2022-04-23 02:56:13,954 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:56:46,702 - INFO - allennlp.training.trainer - Epoch duration: 0:00:48.347796\n",
            "2022-04-23 02:56:46,702 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:08:22\n",
            "2022-04-23 02:56:46,702 - INFO - allennlp.training.trainer - Epoch 22/34\n",
            "2022-04-23 02:56:46,702 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:56:46,811 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:56:46,815 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9167, f1: 0.9646, em_spans_multi_span: 0.9167, f1_spans_multi_span: 0.9646, em_spans: 0.9167, f1_spans: 0.9646, em_multi_span: 0.9167, f1_multi_span: 0.9646, loss: 0.2687 ||: 100%|##########| 4/4 [00:13<00:00,  3.42s/it]\n",
            "2022-04-23 02:57:00,515 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.6061, em_spans_multi_span: 0.3333, f1_spans_multi_span: 0.6061, em_spans: 0.3333, f1_spans: 0.6061, em_multi_span: 0.3333, f1_multi_span: 0.6061, loss: 1111127.3667 ||: 100%|##########| 9/9 [00:01<00:00,  5.06it/s]\n",
            "2022-04-23 02:57:02,296 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:57:02,296 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:57:02,298 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.917  |     0.333\n",
            "2022-04-23 02:57:02,298 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.917  |     0.333\n",
            "2022-04-23 02:57:02,298 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:57:02,299 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.965  |     0.606\n",
            "2022-04-23 02:57:02,300 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.965  |     0.606\n",
            "2022-04-23 02:57:02,301 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.965  |     0.606\n",
            "2022-04-23 02:57:02,301 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.965  |     0.606\n",
            "2022-04-23 02:57:02,302 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:57:02,303 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:57:02,304 - INFO - allennlp.training.tensorboard_writer - em                        |     0.917  |     0.333\n",
            "2022-04-23 02:57:02,304 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.269  |  1111127.367\n",
            "2022-04-23 02:57:02,304 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.917  |     0.333\n",
            "2022-04-23 02:57:02,304 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:57:33,106 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.403802\n",
            "2022-04-23 02:57:33,795 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:48\n",
            "2022-04-23 02:57:33,795 - INFO - allennlp.training.trainer - Epoch 23/34\n",
            "2022-04-23 02:57:33,795 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:57:33,917 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:57:33,924 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9583, f1: 0.9850, em_spans_multi_span: 0.9583, f1_spans_multi_span: 0.9850, em_spans: 0.9583, f1_spans: 0.9850, em_multi_span: 0.9583, f1_multi_span: 0.9850, loss: 0.0500 ||: 100%|##########| 4/4 [00:13<00:00,  3.45s/it]\n",
            "2022-04-23 02:57:47,708 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.6050, em_spans_multi_span: 0.3333, f1_spans_multi_span: 0.6050, em_spans: 0.3333, f1_spans: 0.6050, em_multi_span: 0.3333, f1_multi_span: 0.6050, loss: 1111126.3096 ||: 100%|##########| 9/9 [00:01<00:00,  5.13it/s]\n",
            "2022-04-23 02:57:49,463 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:57:49,464 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 02:57:49,464 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.958  |     0.333\n",
            "2022-04-23 02:57:49,464 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.958  |     0.333\n",
            "2022-04-23 02:57:49,465 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:57:49,465 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.985  |     0.605\n",
            "2022-04-23 02:57:49,465 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.985  |     0.605\n",
            "2022-04-23 02:57:49,465 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.985  |     0.605\n",
            "2022-04-23 02:57:49,465 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.985  |     0.605\n",
            "2022-04-23 02:57:49,466 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:57:49,466 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:57:49,468 - INFO - allennlp.training.tensorboard_writer - em                        |     0.958  |     0.333\n",
            "2022-04-23 02:57:49,470 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.050  |  1111126.310\n",
            "2022-04-23 02:57:49,471 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.958  |     0.333\n",
            "2022-04-23 02:57:49,471 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 02:58:20,635 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.839838\n",
            "2022-04-23 02:58:20,635 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:12\n",
            "2022-04-23 02:58:20,635 - INFO - allennlp.training.trainer - Epoch 24/34\n",
            "2022-04-23 02:58:20,635 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:58:20,741 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:58:20,745 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9167, f1: 0.9729, em_spans_multi_span: 0.9167, f1_spans_multi_span: 0.9729, em_spans: 0.9167, f1_spans: 0.9729, em_multi_span: 0.9167, f1_multi_span: 0.9729, loss: 0.5214 ||: 100%|##########| 4/4 [00:14<00:00,  3.62s/it]\n",
            "2022-04-23 02:58:35,207 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.5517, em_span_multi_span: 0.0000, f1_span_multi_span: 0.4000, em_spans_multi_span: 0.3750, f1_spans_multi_span: 0.5706, em_span: 0.0000, f1_span: 0.4000, em_spans: 0.3750, f1_spans: 0.5706, em_multi_span: 0.3333, f1_multi_span: 0.5517, em_all_spans: 0.3333, f1_all_spans: 0.5517, loss: 1111126.9085 ||: 100%|##########| 9/9 [00:01<00:00,  5.17it/s]\n",
            "2022-04-23 02:58:36,951 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:58:36,952 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.973  |     0.571\n",
            "2022-04-23 02:58:36,953 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.973  |     0.552\n",
            "2022-04-23 02:58:36,954 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     2.000\n",
            "2022-04-23 02:58:36,954 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.521  |  1111126.908\n",
            "2022-04-23 02:58:36,954 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    16.000\n",
            "2022-04-23 02:58:36,955 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.917  |     0.375\n",
            "2022-04-23 02:58:36,956 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.400\n",
            "2022-04-23 02:58:36,957 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.973  |     0.552\n",
            "2022-04-23 02:58:36,958 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:58:36,958 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.333\n",
            "2022-04-23 02:58:36,958 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.917  |     0.375\n",
            "2022-04-23 02:58:36,959 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:58:36,960 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    16.000\n",
            "2022-04-23 02:58:36,960 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     2.000\n",
            "2022-04-23 02:58:36,961 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.973  |     0.571\n",
            "2022-04-23 02:58:36,961 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.552\n",
            "2022-04-23 02:58:36,962 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.400\n",
            "2022-04-23 02:58:36,963 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:58:36,963 - INFO - allennlp.training.tensorboard_writer - em                        |     0.917  |     0.333\n",
            "2022-04-23 02:58:36,963 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.917  |     0.333\n",
            "2022-04-23 02:58:36,963 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:58:36,963 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:59:06,573 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.937928\n",
            "2022-04-23 02:59:06,573 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:36\n",
            "2022-04-23 02:59:06,573 - INFO - allennlp.training.trainer - Epoch 25/34\n",
            "2022-04-23 02:59:06,574 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:59:06,685 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:59:06,689 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9375, f1: 0.9785, em_spans_multi_span: 0.9375, f1_spans_multi_span: 0.9785, em_spans: 0.9375, f1_spans: 0.9785, em_multi_span: 0.9375, f1_multi_span: 0.9785, loss: 0.3574 ||: 100%|##########| 4/4 [00:13<00:00,  3.41s/it]\n",
            "2022-04-23 02:59:20,332 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.5739, em_span_multi_span: 0.0000, f1_span_multi_span: 0.4000, em_spans_multi_span: 0.3750, f1_spans_multi_span: 0.5956, em_span: 0.0000, f1_span: 0.4000, em_spans: 0.3750, f1_spans: 0.5956, em_multi_span: 0.3333, f1_multi_span: 0.5739, em_all_spans: 0.3333, f1_all_spans: 0.5739, loss: 1111127.9974 ||: 100%|##########| 9/9 [00:01<00:00,  5.13it/s]\n",
            "2022-04-23 02:59:22,089 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 02:59:22,089 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.979  |     0.596\n",
            "2022-04-23 02:59:22,091 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.979  |     0.574\n",
            "2022-04-23 02:59:22,092 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     2.000\n",
            "2022-04-23 02:59:22,092 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.357  |  1111127.997\n",
            "2022-04-23 02:59:22,093 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    16.000\n",
            "2022-04-23 02:59:22,094 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.938  |     0.375\n",
            "2022-04-23 02:59:22,094 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.400\n",
            "2022-04-23 02:59:22,095 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.979  |     0.574\n",
            "2022-04-23 02:59:22,095 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 02:59:22,096 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.333\n",
            "2022-04-23 02:59:22,097 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.938  |     0.375\n",
            "2022-04-23 02:59:22,098 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 02:59:22,098 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    16.000\n",
            "2022-04-23 02:59:22,099 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     2.000\n",
            "2022-04-23 02:59:22,100 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.979  |     0.596\n",
            "2022-04-23 02:59:22,100 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.574\n",
            "2022-04-23 02:59:22,100 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.400\n",
            "2022-04-23 02:59:22,101 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 02:59:22,101 - INFO - allennlp.training.tensorboard_writer - em                        |     0.938  |     0.333\n",
            "2022-04-23 02:59:22,101 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.938  |     0.333\n",
            "2022-04-23 02:59:22,102 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 02:59:22,102 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 02:59:55,066 - INFO - allennlp.training.trainer - Epoch duration: 0:00:48.492623\n",
            "2022-04-23 02:59:55,066 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:59\n",
            "2022-04-23 02:59:55,066 - INFO - allennlp.training.trainer - Epoch 26/34\n",
            "2022-04-23 02:59:55,067 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 02:59:55,183 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 02:59:55,187 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9583, f1: 0.9902, em_spans_multi_span: 0.9583, f1_spans_multi_span: 0.9902, em_spans: 0.9583, f1_spans: 0.9902, em_multi_span: 0.9583, f1_multi_span: 0.9902, loss: 0.1031 ||: 100%|##########| 4/4 [00:14<00:00,  3.51s/it]\n",
            "2022-04-23 03:00:09,226 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6217, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6217, em_spans: 0.3889, f1_spans: 0.6217, em_multi_span: 0.3889, f1_multi_span: 0.6217, loss: 1111127.3157 ||: 100%|##########| 9/9 [00:01<00:00,  5.16it/s]\n",
            "2022-04-23 03:00:10,973 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:00:10,973 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:00:10,975 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.958  |     0.389\n",
            "2022-04-23 03:00:10,976 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.958  |     0.389\n",
            "2022-04-23 03:00:10,976 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:00:10,977 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.990  |     0.622\n",
            "2022-04-23 03:00:10,978 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.990  |     0.622\n",
            "2022-04-23 03:00:10,978 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.990  |     0.622\n",
            "2022-04-23 03:00:10,979 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.990  |     0.622\n",
            "2022-04-23 03:00:10,979 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:00:10,980 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:00:10,981 - INFO - allennlp.training.tensorboard_writer - em                        |     0.958  |     0.389\n",
            "2022-04-23 03:00:10,981 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.103  |  1111127.316\n",
            "2022-04-23 03:00:10,982 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.958  |     0.389\n",
            "2022-04-23 03:00:10,982 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:00:39,536 - INFO - allennlp.training.trainer - Epoch duration: 0:00:44.469588\n",
            "2022-04-23 03:00:40,139 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:21\n",
            "2022-04-23 03:00:40,140 - INFO - allennlp.training.trainer - Epoch 27/34\n",
            "2022-04-23 03:00:40,140 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:00:40,253 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:00:40,283 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9583, f1: 0.9856, em_spans_multi_span: 0.9583, f1_spans_multi_span: 0.9856, em_spans: 0.9583, f1_spans: 0.9856, em_multi_span: 0.9583, f1_multi_span: 0.9856, loss: 0.5266 ||: 100%|##########| 4/4 [00:13<00:00,  3.46s/it]\n",
            "2022-04-23 03:00:54,129 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.6217, em_spans_multi_span: 0.3333, f1_spans_multi_span: 0.6217, em_spans: 0.3333, f1_spans: 0.6217, em_multi_span: 0.3333, f1_multi_span: 0.6217, loss: 1111127.5187 ||: 100%|##########| 9/9 [00:01<00:00,  5.15it/s]\n",
            "2022-04-23 03:00:55,880 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:00:55,880 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:00:55,881 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.958  |     0.333\n",
            "2022-04-23 03:00:55,882 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.958  |     0.333\n",
            "2022-04-23 03:00:55,883 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:00:55,884 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.986  |     0.622\n",
            "2022-04-23 03:00:55,884 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.986  |     0.622\n",
            "2022-04-23 03:00:55,885 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.986  |     0.622\n",
            "2022-04-23 03:00:55,885 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.986  |     0.622\n",
            "2022-04-23 03:00:55,886 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:00:55,886 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:00:55,886 - INFO - allennlp.training.tensorboard_writer - em                        |     0.958  |     0.333\n",
            "2022-04-23 03:00:55,886 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.527  |  1111127.519\n",
            "2022-04-23 03:00:55,886 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.958  |     0.333\n",
            "2022-04-23 03:00:55,888 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:01:26,368 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.227988\n",
            "2022-04-23 03:01:26,368 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:42\n",
            "2022-04-23 03:01:26,368 - INFO - allennlp.training.trainer - Epoch 28/34\n",
            "2022-04-23 03:01:26,368 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:01:26,477 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:01:26,481 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.8958, f1: 0.9690, em_spans_multi_span: 0.8958, f1_spans_multi_span: 0.9690, em_spans: 0.8958, f1_spans: 0.9690, em_multi_span: 0.8958, f1_multi_span: 0.9690, loss: 0.0924 ||: 100%|##########| 4/4 [00:14<00:00,  3.50s/it]\n",
            "2022-04-23 03:01:40,484 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6550, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6550, em_spans: 0.3889, f1_spans: 0.6550, em_multi_span: 0.3889, f1_multi_span: 0.6550, loss: 1111128.1550 ||: 100%|##########| 9/9 [00:01<00:00,  5.18it/s]\n",
            "2022-04-23 03:01:42,223 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:01:42,224 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:01:42,224 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.896  |     0.389\n",
            "2022-04-23 03:01:42,224 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.896  |     0.389\n",
            "2022-04-23 03:01:42,225 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:01:42,225 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.969  |     0.655\n",
            "2022-04-23 03:01:42,225 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.969  |     0.655\n",
            "2022-04-23 03:01:42,225 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.969  |     0.655\n",
            "2022-04-23 03:01:42,225 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.969  |     0.655\n",
            "2022-04-23 03:01:42,226 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:01:42,227 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:01:42,229 - INFO - allennlp.training.tensorboard_writer - em                        |     0.896  |     0.389\n",
            "2022-04-23 03:01:42,230 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.092  |  1111128.155\n",
            "2022-04-23 03:01:42,231 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.896  |     0.389\n",
            "2022-04-23 03:01:42,231 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:02:14,803 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to '/content/Training/best.th'.\n",
            "2022-04-23 03:02:30,155 - INFO - allennlp.training.trainer - Epoch duration: 0:01:03.787411\n",
            "2022-04-23 03:02:33,063 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:07\n",
            "2022-04-23 03:02:33,063 - INFO - allennlp.training.trainer - Epoch 29/34\n",
            "2022-04-23 03:02:33,064 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:02:33,177 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:02:33,181 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 1.0000, f1: 1.0000, em_spans_multi_span: 1.0000, f1_spans_multi_span: 1.0000, em_spans: 1.0000, f1_spans: 1.0000, em_multi_span: 1.0000, f1_multi_span: 1.0000, loss: 0.1238 ||: 100%|##########| 4/4 [00:13<00:00,  3.40s/it]\n",
            "2022-04-23 03:02:46,795 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.2222, f1: 0.5683, em_spans_multi_span: 0.2353, f1_spans_multi_span: 0.5624, em_span_multi_span: 0.0000, f1_span_multi_span: 0.6700, em_spans: 0.2353, f1_spans: 0.5624, em_span: 0.0000, f1_span: 0.6700, em_multi_span: 0.2222, f1_multi_span: 0.5683, em_all_spans: 0.2222, f1_all_spans: 0.5683, loss: 1111128.4659 ||: 100%|##########| 9/9 [00:01<00:00,  5.14it/s]\n",
            "2022-04-23 03:02:48,550 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:02:48,550 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     1.000  |     0.562\n",
            "2022-04-23 03:02:48,550 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     1.000  |     0.568\n",
            "2022-04-23 03:02:48,551 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     1.000\n",
            "2022-04-23 03:02:48,551 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.124  |  1111128.466\n",
            "2022-04-23 03:02:48,551 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    17.000\n",
            "2022-04-23 03:02:48,551 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     1.000  |     0.235\n",
            "2022-04-23 03:02:48,551 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.670\n",
            "2022-04-23 03:02:48,551 - INFO - allennlp.training.tensorboard_writer - f1                        |     1.000  |     0.568\n",
            "2022-04-23 03:02:48,552 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 03:02:48,552 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.222\n",
            "2022-04-23 03:02:48,555 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     1.000  |     0.235\n",
            "2022-04-23 03:02:48,555 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:02:48,557 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    17.000\n",
            "2022-04-23 03:02:48,557 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     1.000\n",
            "2022-04-23 03:02:48,558 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     1.000  |     0.562\n",
            "2022-04-23 03:02:48,559 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.568\n",
            "2022-04-23 03:02:48,559 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.670\n",
            "2022-04-23 03:02:48,560 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:02:48,560 - INFO - allennlp.training.tensorboard_writer - em                        |     1.000  |     0.222\n",
            "2022-04-23 03:02:48,560 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     1.000  |     0.222\n",
            "2022-04-23 03:02:48,561 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 03:02:48,561 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:03:17,596 - INFO - allennlp.training.trainer - Epoch duration: 0:00:44.532056\n",
            "2022-04-23 03:03:17,596 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:26\n",
            "2022-04-23 03:03:17,596 - INFO - allennlp.training.trainer - Epoch 30/34\n",
            "2022-04-23 03:03:17,596 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:03:17,707 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:03:17,710 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9167, f1: 0.9758, em_spans_multi_span: 0.9167, f1_spans_multi_span: 0.9758, em_spans: 0.9167, f1_spans: 0.9758, em_multi_span: 0.9167, f1_multi_span: 0.9758, loss: 0.2297 ||: 100%|##########| 4/4 [00:13<00:00,  3.39s/it]\n",
            "2022-04-23 03:03:31,275 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.5917, em_spans_multi_span: 0.4118, f1_spans_multi_span: 0.5871, em_span_multi_span: 0.0000, f1_span_multi_span: 0.6700, em_spans: 0.4118, f1_spans: 0.5871, em_span: 0.0000, f1_span: 0.6700, em_multi_span: 0.3889, f1_multi_span: 0.5917, em_all_spans: 0.3889, f1_all_spans: 0.5917, loss: 1111128.3747 ||: 100%|##########| 9/9 [00:01<00:00,  5.12it/s]\n",
            "2022-04-23 03:03:33,035 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:03:33,036 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.976  |     0.587\n",
            "2022-04-23 03:03:33,037 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.976  |     0.592\n",
            "2022-04-23 03:03:33,038 - INFO - allennlp.training.tensorboard_writer - _counter_span             |       N/A  |     1.000\n",
            "2022-04-23 03:03:33,039 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.230  |  1111128.375\n",
            "2022-04-23 03:03:33,039 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    17.000\n",
            "2022-04-23 03:03:33,039 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.917  |     0.412\n",
            "2022-04-23 03:03:33,039 - INFO - allennlp.training.tensorboard_writer - f1_span                   |       N/A  |     0.670\n",
            "2022-04-23 03:03:33,040 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.976  |     0.592\n",
            "2022-04-23 03:03:33,041 - INFO - allennlp.training.tensorboard_writer - em_span_multi_span        |       N/A  |     0.000\n",
            "2022-04-23 03:03:33,041 - INFO - allennlp.training.tensorboard_writer - em_all_spans              |       N/A  |     0.389\n",
            "2022-04-23 03:03:33,042 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.917  |     0.412\n",
            "2022-04-23 03:03:33,043 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:03:33,044 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    17.000\n",
            "2022-04-23 03:03:33,044 - INFO - allennlp.training.tensorboard_writer - _counter_span_multi_span  |       N/A  |     1.000\n",
            "2022-04-23 03:03:33,045 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.976  |     0.587\n",
            "2022-04-23 03:03:33,046 - INFO - allennlp.training.tensorboard_writer - f1_all_spans              |       N/A  |     0.592\n",
            "2022-04-23 03:03:33,047 - INFO - allennlp.training.tensorboard_writer - f1_span_multi_span        |       N/A  |     0.670\n",
            "2022-04-23 03:03:33,047 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:03:33,048 - INFO - allennlp.training.tensorboard_writer - em                        |     0.917  |     0.389\n",
            "2022-04-23 03:03:33,048 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.917  |     0.389\n",
            "2022-04-23 03:03:33,049 - INFO - allennlp.training.tensorboard_writer - em_span                   |       N/A  |     0.000\n",
            "2022-04-23 03:03:33,050 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:04:03,899 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.302891\n",
            "2022-04-23 03:04:03,899 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:46\n",
            "2022-04-23 03:04:03,899 - INFO - allennlp.training.trainer - Epoch 31/34\n",
            "2022-04-23 03:04:03,899 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:04:04,018 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:04:04,022 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9167, f1: 0.9729, em_spans_multi_span: 0.9167, f1_spans_multi_span: 0.9729, em_spans: 0.9167, f1_spans: 0.9729, em_multi_span: 0.9167, f1_multi_span: 0.9729, loss: 0.2059 ||: 100%|##########| 4/4 [00:13<00:00,  3.48s/it]\n",
            "2022-04-23 03:04:17,957 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.4444, f1: 0.6433, em_spans_multi_span: 0.4444, f1_spans_multi_span: 0.6433, em_spans: 0.4444, f1_spans: 0.6433, em_multi_span: 0.4444, f1_multi_span: 0.6433, loss: 1111128.3953 ||: 100%|##########| 9/9 [00:01<00:00,  5.13it/s]\n",
            "2022-04-23 03:04:19,713 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:04:19,713 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:04:19,715 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.917  |     0.444\n",
            "2022-04-23 03:04:19,716 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.917  |     0.444\n",
            "2022-04-23 03:04:19,716 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:04:19,716 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.973  |     0.643\n",
            "2022-04-23 03:04:19,717 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.973  |     0.643\n",
            "2022-04-23 03:04:19,717 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.973  |     0.643\n",
            "2022-04-23 03:04:19,717 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.973  |     0.643\n",
            "2022-04-23 03:04:19,717 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:04:19,717 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:04:19,718 - INFO - allennlp.training.tensorboard_writer - em                        |     0.917  |     0.444\n",
            "2022-04-23 03:04:19,718 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.206  |  1111128.395\n",
            "2022-04-23 03:04:19,719 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.917  |     0.444\n",
            "2022-04-23 03:04:19,719 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:04:53,888 - INFO - allennlp.training.trainer - Epoch duration: 0:00:49.988270\n",
            "2022-04-23 03:04:53,888 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:05\n",
            "2022-04-23 03:04:53,888 - INFO - allennlp.training.trainer - Epoch 32/34\n",
            "2022-04-23 03:04:53,888 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:04:53,996 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:04:54,000 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9375, f1: 0.9850, em_spans_multi_span: 0.9375, f1_spans_multi_span: 0.9850, em_spans: 0.9375, f1_spans: 0.9850, em_multi_span: 0.9375, f1_multi_span: 0.9850, loss: 0.0161 ||: 100%|##########| 4/4 [00:13<00:00,  3.45s/it]\n",
            "2022-04-23 03:05:07,790 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3333, f1: 0.6022, em_spans_multi_span: 0.3333, f1_spans_multi_span: 0.6022, em_spans: 0.3333, f1_spans: 0.6022, em_multi_span: 0.3333, f1_multi_span: 0.6022, loss: 1111128.2414 ||: 100%|##########| 9/9 [00:01<00:00,  5.14it/s]\n",
            "2022-04-23 03:05:09,544 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:05:09,544 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:05:09,546 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.938  |     0.333\n",
            "2022-04-23 03:05:09,547 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.938  |     0.333\n",
            "2022-04-23 03:05:09,548 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:05:09,548 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.985  |     0.602\n",
            "2022-04-23 03:05:09,549 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.985  |     0.602\n",
            "2022-04-23 03:05:09,549 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.985  |     0.602\n",
            "2022-04-23 03:05:09,550 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.985  |     0.602\n",
            "2022-04-23 03:05:09,550 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:05:09,551 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:05:09,551 - INFO - allennlp.training.tensorboard_writer - em                        |     0.938  |     0.333\n",
            "2022-04-23 03:05:09,551 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.016  |  1111128.241\n",
            "2022-04-23 03:05:09,552 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.938  |     0.333\n",
            "2022-04-23 03:05:09,553 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:05:38,219 - INFO - allennlp.training.trainer - Epoch duration: 0:00:44.330796\n",
            "2022-04-23 03:05:38,219 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:23\n",
            "2022-04-23 03:05:38,219 - INFO - allennlp.training.trainer - Epoch 33/34\n",
            "2022-04-23 03:05:38,219 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:05:38,347 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:05:38,351 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9583, f1: 0.9902, em_spans_multi_span: 0.9583, f1_spans_multi_span: 0.9902, em_spans: 0.9583, f1_spans: 0.9902, em_multi_span: 0.9583, f1_multi_span: 0.9902, loss: 0.0508 ||: 100%|##########| 4/4 [00:13<00:00,  3.50s/it]\n",
            "2022-04-23 03:05:52,347 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6344, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6344, em_spans: 0.3889, f1_spans: 0.6344, em_multi_span: 0.3889, f1_multi_span: 0.6344, loss: 1111128.1804 ||: 100%|##########| 9/9 [00:01<00:00,  5.21it/s]\n",
            "2022-04-23 03:05:54,076 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:05:54,077 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:05:54,078 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.958  |     0.389\n",
            "2022-04-23 03:05:54,078 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.958  |     0.389\n",
            "2022-04-23 03:05:54,079 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:05:54,080 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.990  |     0.634\n",
            "2022-04-23 03:05:54,080 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.990  |     0.634\n",
            "2022-04-23 03:05:54,080 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.990  |     0.634\n",
            "2022-04-23 03:05:54,080 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.990  |     0.634\n",
            "2022-04-23 03:05:54,080 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:05:54,081 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:05:54,082 - INFO - allennlp.training.tensorboard_writer - em                        |     0.958  |     0.389\n",
            "2022-04-23 03:05:54,082 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.051  |  1111128.180\n",
            "2022-04-23 03:05:54,083 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.958  |     0.389\n",
            "2022-04-23 03:05:54,084 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:06:25,548 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.328875\n",
            "2022-04-23 03:06:25,548 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:00:42\n",
            "2022-04-23 03:06:25,548 - INFO - allennlp.training.trainer - Epoch 34/34\n",
            "2022-04-23 03:06:25,548 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 8246.056\n",
            "2022-04-23 03:06:25,655 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 13076\n",
            "2022-04-23 03:06:25,658 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]./src/modules/heads/single_span_head.py:144: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  span_start_indices = best_spans // passage_length\n",
            "em: 0.9583, f1: 0.9902, em_spans_multi_span: 0.9583, f1_spans_multi_span: 0.9902, em_spans: 0.9583, f1_spans: 0.9902, em_multi_span: 0.9583, f1_multi_span: 0.9902, loss: 0.1419 ||: 100%|##########| 4/4 [00:13<00:00,  3.39s/it]\n",
            "2022-04-23 03:06:39,226 - INFO - allennlp.training.trainer - Validating\n",
            "em: 0.3889, f1: 0.6344, em_spans_multi_span: 0.3889, f1_spans_multi_span: 0.6344, em_spans: 0.3889, f1_spans: 0.6344, em_multi_span: 0.3889, f1_multi_span: 0.6344, loss: 1111128.1486 ||: 100%|##########| 9/9 [00:01<00:00,  5.11it/s]\n",
            "2022-04-23 03:06:40,990 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-23 03:06:40,990 - INFO - allennlp.training.tensorboard_writer - _counter_spans_multi_span |    48.000  |    18.000\n",
            "2022-04-23 03:06:40,992 - INFO - allennlp.training.tensorboard_writer - em_spans_multi_span       |     0.958  |     0.389\n",
            "2022-04-23 03:06:40,993 - INFO - allennlp.training.tensorboard_writer - em_multi_span             |     0.958  |     0.389\n",
            "2022-04-23 03:06:40,993 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  13076.000  |       N/A\n",
            "2022-04-23 03:06:40,994 - INFO - allennlp.training.tensorboard_writer - f1_spans_multi_span       |     0.990  |     0.634\n",
            "2022-04-23 03:06:40,995 - INFO - allennlp.training.tensorboard_writer - f1_spans                  |     0.990  |     0.634\n",
            "2022-04-23 03:06:40,995 - INFO - allennlp.training.tensorboard_writer - f1                        |     0.990  |     0.634\n",
            "2022-04-23 03:06:40,996 - INFO - allennlp.training.tensorboard_writer - f1_multi_span             |     0.990  |     0.634\n",
            "2022-04-23 03:06:40,996 - INFO - allennlp.training.tensorboard_writer - _counter_multi_span       |    48.000  |    18.000\n",
            "2022-04-23 03:06:40,996 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB             |  8246.056  |       N/A\n",
            "2022-04-23 03:06:40,996 - INFO - allennlp.training.tensorboard_writer - em                        |     0.958  |     0.389\n",
            "2022-04-23 03:06:40,997 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.142  |  1111128.149\n",
            "2022-04-23 03:06:40,997 - INFO - allennlp.training.tensorboard_writer - em_spans                  |     0.958  |     0.389\n",
            "2022-04-23 03:06:40,999 - INFO - allennlp.training.tensorboard_writer - _counter_spans            |    48.000  |    18.000\n",
            "2022-04-23 03:07:11,615 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.066908\n",
            "2022-04-23 03:07:11,617 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2022-04-23 03:07:20,287 - INFO - allennlp.models.archival - archiving weights and vocabulary to /content/Training/model.tar.gz\n",
            "2022-04-23 03:09:05,415 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"best_epoch\": 28,\n",
            "  \"peak_cpu_memory_MB\": 8246.056,\n",
            "  \"peak_gpu_0_memory_MB\": 13076,\n",
            "  \"training_duration\": \"0:24:04.655803\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 34,\n",
            "  \"epoch\": 34,\n",
            "  \"training_em\": 0.9583333333333334,\n",
            "  \"training_f1\": 0.9902083333333334,\n",
            "  \"training__em_spans_passage_span\": 0.0,\n",
            "  \"training__f1_spans_passage_span\": 0.02428571428571429,\n",
            "  \"training__counter_spans_passage_span\": 7,\n",
            "  \"training_em_spans\": 0.9583333333333334,\n",
            "  \"training_f1_spans\": 0.9902083333333334,\n",
            "  \"training__counter_spans\": 48,\n",
            "  \"training__em_passage_span\": 0.0,\n",
            "  \"training__f1_passage_span\": 0.02428571428571429,\n",
            "  \"training__counter_passage_span\": 7,\n",
            "  \"training_loss\": 0.14186292653903365,\n",
            "  \"training_cpu_memory_MB\": 8246.056,\n",
            "  \"training_gpu_0_memory_MB\": 13076,\n",
            "  \"validation_em\": 0.3888888888888889,\n",
            "  \"validation_f1\": 0.6344444444444445,\n",
            "  \"validation__em_spans_passage_span\": 0.0,\n",
            "  \"validation__f1_spans_passage_span\": 0.0,\n",
            "  \"validation__counter_spans_passage_span\": 10,\n",
            "  \"validation_em_spans_multi_span\": 0.3888888888888889,\n",
            "  \"validation_f1_spans_multi_span\": 0.6344444444444445,\n",
            "  \"validation__counter_spans_multi_span\": 18,\n",
            "  \"validation__em_span_passage_span\": 0.0,\n",
            "  \"validation__f1_span_passage_span\": 0.265,\n",
            "  \"validation__counter_span_passage_span\": 4,\n",
            "  \"validation_em_spans\": 0.3888888888888889,\n",
            "  \"validation_f1_spans\": 0.6344444444444445,\n",
            "  \"validation__counter_spans\": 18,\n",
            "  \"validation_em_span\": 0.0,\n",
            "  \"validation_f1_span\": 0.67,\n",
            "  \"validation__counter_span\": 1,\n",
            "  \"validation__em_passage_span\": 0.0,\n",
            "  \"validation__f1_passage_span\": 0.07571428571428572,\n",
            "  \"validation__counter_passage_span\": 14,\n",
            "  \"validation_em_multi_span\": 0.3888888888888889,\n",
            "  \"validation_f1_multi_span\": 0.6344444444444445,\n",
            "  \"validation__counter_multi_span\": 18,\n",
            "  \"validation_em_all_spans\": 0.38888888888888884,\n",
            "  \"validation_f1_all_spans\": 0.5916666666666667,\n",
            "  \"validation_loss\": 1111128.148630566,\n",
            "  \"best_validation_em\": 0.3888888888888889,\n",
            "  \"best_validation_f1\": 0.6549999999999999,\n",
            "  \"best_validation__em_spans_passage_span\": 0.0,\n",
            "  \"best_validation__f1_spans_passage_span\": 0.0,\n",
            "  \"best_validation__counter_spans_passage_span\": 10,\n",
            "  \"best_validation_em_spans_multi_span\": 0.3888888888888889,\n",
            "  \"best_validation_f1_spans_multi_span\": 0.6549999999999999,\n",
            "  \"best_validation__counter_spans_multi_span\": 18,\n",
            "  \"best_validation__em_span_passage_span\": 0.0,\n",
            "  \"best_validation__f1_span_passage_span\": 0.265,\n",
            "  \"best_validation__counter_span_passage_span\": 4,\n",
            "  \"best_validation_em_spans\": 0.3888888888888889,\n",
            "  \"best_validation_f1_spans\": 0.6549999999999999,\n",
            "  \"best_validation__counter_spans\": 18,\n",
            "  \"best_validation_em_span\": 0.0,\n",
            "  \"best_validation_f1_span\": 0.4,\n",
            "  \"best_validation__counter_span\": 2,\n",
            "  \"best_validation__em_passage_span\": 0.0,\n",
            "  \"best_validation__f1_passage_span\": 0.07571428571428572,\n",
            "  \"best_validation__counter_passage_span\": 14,\n",
            "  \"best_validation_em_multi_span\": 0.3888888888888889,\n",
            "  \"best_validation_f1_multi_span\": 0.6549999999999999,\n",
            "  \"best_validation__counter_multi_span\": 18,\n",
            "  \"best_validation_em_all_spans\": 0.2222222222222222,\n",
            "  \"best_validation_f1_all_spans\": 0.49999999999999994,\n",
            "  \"best_validation_loss\": 1111128.154978964,\n",
            "  \"training_em_spans_multi_span\": 0.9583333333333334,\n",
            "  \"training_f1_spans_multi_span\": 0.9902083333333334,\n",
            "  \"training__counter_spans_multi_span\": 48,\n",
            "  \"training_em_multi_span\": 0.9583333333333334,\n",
            "  \"training_f1_multi_span\": 0.9902083333333334,\n",
            "  \"training__counter_multi_span\": 48,\n",
            "  \"validation_em_span_multi_span\": 0.0,\n",
            "  \"validation_f1_span_multi_span\": 0.67,\n",
            "  \"validation__counter_span_multi_span\": 1,\n",
            "  \"best_validation_em_span_multi_span\": 0.0,\n",
            "  \"best_validation_f1_span_multi_span\": 0.4,\n",
            "  \"best_validation__counter_span_multi_span\": 2\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The previously trained fine-tuend model .tar.gz file is fed into here in the first place\n",
        "# And test dataset will be fed into the second place\n",
        "# And we get output file 'predictions.jsonl' in tag-based-multi-span-extraction direcotry \n",
        "# for visualization and evaluation check\n",
        "# Going to https://eladsegal.github.io/DROP-explorer/\n",
        "# Checking the metrics\n",
        "# And also possible to check loss and other values by opening the jsonl file\n",
        "\n",
        "!allennlp predict /content/Training/model.tar.gz /content/tag-based-multi-span-extraction/drop_data/EMF_multispan_test.json --predictor machine-comprehension \\\n",
        "--cuda-device 0 --output-file predictions.jsonl --use-dataset-reader --include-package src \\\n",
        "-o \"{'validation_dataset_reader.pickle.action': 'None'}\"\n",
        "\n",
        "# !allennlp predict /content/DROP_TASE_IO.tar.gz drop_data/drop_dataset_dev.json --predictor machine-comprehension \\\n",
        "# --cuda-device 0 --output-file predictions.jsonl --use-dataset-reader --include-package src \\\n",
        "# -o \"{'validation_dataset_reader.pickle.action': 'None'}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xr4dK1MZHjak",
        "outputId": "1db161c5-ca32-4c11-bbb9-3eb5f2fe2d9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, False, False, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, False, False, False, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 13 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[52]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[57]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[65, 66, 67]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[71]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[78]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[86, 87, 88, 89]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[91, 92]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[93]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[100]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[103]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[146]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 13 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (57, 58). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 9 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[62, 63]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[65, 66, 67]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[86, 87, 88, 89]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[91, 92]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[141, 142]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[148, 149]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 185 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 185 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 185 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 14.921026229858398, \"passage_id\": \"idx_51\", \"query_id\": \"qid_51-1\", \"answer\": {\"value\": [\"900 MHz\", \"1800 MHz\"], \"spans\": [[\"p\", 300, 307], [\"p\", 360, 368]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"900 MHz\", \"1800 MHz\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 2:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 407 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 33619, 2650, 3038, 9, 38966, 5447, 36, 5330, 597,\n",
            "\t\t43, 15, 14526, 8, 35478, 1575, 9, 5868, 8, 37304, 33, 57, 39298, 11416, 3373, 8, 1179, 13109, 2212,\n",
            "\t\t59, 12661, 3038, 9, 14850, 597, 15, 937, 2900, 8047, 4, 96, 5, 1455, 892, 52, 5049, 3188, 12, 36274,\n",
            "\t\t36, 30455, 43, 8724, 9, 5, 9973, 6698, 31121, 5149, 36, 5725, 2685, 43, 7, 455, 2900, 4924, 2943,\n",
            "\t\t305, 31732, 24162, 11, 645, 7, 10986, 342, 3693, 16882, 15, 3992, 20940, 800, 36, 438, 2723, 636,\n",
            "\t\t13991, 261, 131, 230, 12154, 8, 42761, 1975, 2723, 636, 45051, 20940, 131, 12928, 725, 43, 8, 15,\n",
            "\t\t48464, 337, 16934, 47621, 251, 12, 1279, 4136, 1571, 36, 574, 15993, 43, 8, 6943, 36, 574, 22615,\n",
            "\t\t43, 25, 10371, 21130, 2459, 35948, 5179, 23959, 13, 3783, 3521, 8, 3783, 13581, 4, 40032, 21, 3034,\n",
            "\t\t4875, 1976, 7709, 1274, 4, 11276, 6204, 2900, 12, 9903, 4628, 2167, 33131, 1162, 36, 104, 2747, 43,\n",
            "\t\t25, 10, 2450, 9, 5049, 2862, 12, 3368, 30809, 1070, 18044, 476, 58, 321, 6, 132, 6, 8, 158, 305, 73,\n",
            "\t\t9043, 81, 10, 675, 9, 5962, 5251, 4, 37070, 9, 16051, 4924, 3122, 1487, 6, 6069, 9, 14850, 597,\n",
            "\t\t4895, 6, 3625, 1130, 230, 12154, 8, 12928, 725, 1389, 61, 20719, 196, 19, 3489, 8065, 882, 801,\n",
            "\t\t25098, 8, 29455, 25917, 11, 48464, 337, 226, 15993, 8, 32567, 4, 24709, 511, 34565, 4895, 9, 132,\n",
            "\t\t305, 73, 9043, 36, 9903, 4628, 81, 5, 1086, 2900, 9, 132, 4, 246, 821, 11576, 2862, 43, 222, 45,\n",
            "\t\t10356, 31, 5, 31026, 12, 18793, 7878, 333, 11, 226, 15993, 8, 32567, 15491, 4, 96, 5709, 6, 10,\n",
            "\t\t1233, 4878, 11, 226, 15993, 8, 32567, 21, 6373, 23, 5, 239, 476, 731, 9, 34565, 36, 698, 305, 73,\n",
            "\t\t9043, 322, 20, 775, 8085, 14, 10, 731, 9, 132, 305, 73, 9043, 8612, 117, 12661, 913, 15, 226, 15993,\n",
            "\t\t8, 32567, 6, 150, 158, 305, 73, 9043, 3315, 7, 1233, 3038, 15, 5, 10371, 21130, 2459, 35948, 17294,\n",
            "\t\t6, 61, 64, 28, 2563, 19098, 31, 5, 3992, 16934, 3618, 4, 1541, 4139, 3608, 14, 22759, 2685, 4895,\n",
            "\t\t19, 34565, 11, 5, 1186, 9, 132, 305, 73, 9043, 16, 45, 11190, 7, 2008, 22462, 13, 3783, 3521, 8,\n",
            "\t\t3783, 13581, 6, 959, 6, 41, 2712, 9, 22759, 2685, 23, 239, 1007, 33131, 1162, 36, 698, 305, 73,\n",
            "\t\t9043, 43, 1395, 28, 15298, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 407 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 407 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 407 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 407 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False,\n",
            "\t\tFalse, False, True, True, False, True, True, False, False, False, False, True, True, True, False,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, False, True, True, False, True,\n",
            "\t\tTrue, True, True, True, False, True, True, True, False, False, False, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, False, True, True, False, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, False, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 12 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[181]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[183]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[186]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[194]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[243]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[255, 256, 257]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[300]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[312]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[327]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[367]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[397]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 12 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (183, 189). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 38 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[11, 12]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[18, 19]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[32, 33]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[43, 44]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[70, 71]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[78, 79]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[85, 86]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[93, 94, 95, 96, 97]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[99, 100]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[102, 103, 104, 105, 106]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[109, 110]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[114, 115]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[121, 122]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[124, 125]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[130, 131]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[134, 135, 136, 137]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[138, 139]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[155, 156]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[159, 160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[165, 166]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[176, 177]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[206, 207]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[212, 213]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[215, 216]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[219, 220]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[228, 229]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[231, 232]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[233, 234]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[248, 249]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[255, 256, 257]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[269, 270]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[273, 274]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[286, 287]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[321, 322]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[337, 338, 339, 340]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[358, 359]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[389, 390]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 407 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 407 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 407 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 21.88248634338379, \"passage_id\": \"idx_53\", \"query_id\": \"qid_53-1\", \"answer\": {\"value\": [\"10 W/kg\", \"2 W/kg\"], \"spans\": [[\"p\", 860, 861], [\"p\", 867, 874], [\"p\", 1163, 1169]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"2 W/kg\", \"10 W/kg\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 3:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 386 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 20, 13827, 3038, 9, 28562, 4895, 31, 5, 1849,\n",
            "\t\t5149, 13, 6698, 17051, 36, 534, 15153, 43, 58, 8069, 11, 24162, 6, 634, 10742, 38333, 13785, 23, 41,\n",
            "\t\t10603, 1122, 7, 1830, 1028, 5035, 4, 6208, 4467, 2849, 40474, 25170, 19899, 9, 181, 46473, 90,\n",
            "\t\t42194, 58, 172, 16556, 7, 5, 24162, 8, 41, 14073, 1421, 9, 18587, 12, 26404, 14186, 21, 1412, 31, 5,\n",
            "\t\t414, 4, 23670, 219, 12, 7109, 4194, 2943, 14933, 17558, 12, 495, 1584, 607, 24162, 12796, 13998,\n",
            "\t\t43941, 3044, 9, 4249, 45457, 911, 7, 2450, 26076, 9, 5, 740, 12, 506, 366, 46282, 17540, 71, 1814,\n",
            "\t\t4691, 8, 706, 298, 6, 8, 9, 5, 5921, 2617, 856, 11804, 31867, 41314, 8276, 36, 27150, 591, 43, 4801,\n",
            "\t\t298, 71, 13827, 4895, 7, 10, 10742, 38333, 38966, 882, 36, 5330, 597, 322, 20, 14073, 278, 12, 658,\n",
            "\t\t24624, 20104, 9, 22416, 476, 6, 31, 61, 5, 674, 2167, 33131, 731, 21, 9658, 634, 5, 40001, 12,\n",
            "\t\t32278, 24935, 86, 12, 46400, 36, 24667, 22615, 43, 132, 298, 71, 4895, 7, 14850, 597, 13785, 23,\n",
            "\t\t112, 4, 1898, 771, 73, 9043, 11, 181, 46473, 90, 42194, 12, 41104, 24162, 8, 112, 4, 3170, 771, 73,\n",
            "\t\t9043, 11, 30946, 24162, 4, 17450, 12637, 728, 71, 13785, 239, 1389, 9, 740, 12, 506, 366, 8151, 58,\n",
            "\t\t2673, 11, 5, 45016, 47419, 8, 18100, 1975, 47419, 552, 19, 614, 45107, 29997, 11, 181, 46473, 90,\n",
            "\t\t42194, 3032, 3122, 4, 1993, 2900, 911, 6, 4682, 5, 29654, 636, 47615, 976, 6, 969, 505, 3488, 11,\n",
            "\t\t46282, 29997, 706, 298, 71, 181, 46473, 90, 42194, 8, 13785, 4, 2873, 360, 71, 181, 46473, 90,\n",
            "\t\t42194, 1416, 6, 13785, 3038, 58, 202, 5890, 11, 5, 45016, 47419, 6, 14368, 877, 821, 44224, 8, 5267,\n",
            "\t\t246, 6, 53, 10, 1233, 7280, 11, 1940, 21, 1581, 11, 5, 36287, 38263, 8, 3838, 368, 298, 6204, 40715,\n",
            "\t\t4, 1590, 42, 86, 6, 5921, 2617, 9046, 9866, 1130, 19, 358, 18587, 11, 45708, 15253, 6, 181, 46473,\n",
            "\t\t90, 42194, 12, 41104, 2900, 3806, 4, 1541, 775, 4991, 14, 740, 12, 506, 366, 8, 5921, 2617, 22462,\n",
            "\t\t58, 7544, 30, 5, 2771, 3992, 9, 786, 12, 12968, 10417, 45708, 16546, 8, 5, 8422, 1683, 9, 181,\n",
            "\t\t46473, 90, 42194, 15, 30817, 25671, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 386 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 386 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 386 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 386 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, False, False, True, True, True, False, False, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, False, True, True, False, False, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tFalse, True, True, False, True, True, True, True, True, False, True, False, False, True, True, True,\n",
            "\t\tTrue, False, True, True, False, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, False, True, True, False, True, True, True, True, False, True, True, True, False, False,\n",
            "\t\tFalse, True, True, True, True, False, False, False, True, True, True, True, True, False, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, False, True, True, False, False, True, True,\n",
            "\t\tTrue, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tFalse, False, False, True, True, True, True, True, True, True, False, False, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, False, True, False, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tFalse, False, False, True, True, True, True, True, True, True, False, True, False, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, False, False, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, False, True, True, True, True, True, True, False, False, False,\n",
            "\t\tTrue, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 5 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[78, 79]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[81]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[213, 214]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[276]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (188, 211). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 51 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[25, 26]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[34, 35]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[46, 47]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[48, 49, 50]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[53, 54, 55, 56]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[70, 71]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[78, 79]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[84, 85]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[87, 88, 89]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[92, 93]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[106, 107]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[111, 112]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[114, 115]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[120, 121]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[122, 123, 124]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[128, 129]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[131, 132]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[138, 139]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[143, 144]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[170, 171]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[176, 177]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[179, 180]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[184, 185]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[188, 189, 190, 191]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[195, 196, 197, 198]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[203, 204, 205, 206]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[213, 214]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[223, 224]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[230, 231]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[233, 234, 235]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[242, 243, 244, 245]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[255, 256]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[266, 267]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[269, 270, 271, 272]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[279, 280, 281, 282]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[292, 293]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[295, 296]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[297, 298]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[300, 301]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[313, 314]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[316, 317, 318, 319]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[326, 327]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[328, 329]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[335, 336]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[338, 339, 340, 341]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[353, 354]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[356, 357]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[368, 369]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[370, 371]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[377, 378, 379, 380]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 386 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 386 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 386 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 21.807119369506836, \"passage_id\": \"idx_54\", \"query_id\": \"qid_54-1\", \"answer\": {\"value\": [\"1.45W/kg\", \"1.38W/kg\"], \"spans\": [[\"p\", 846, 854], [\"p\", 886, 894]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.45W/kg\", \"1.38W/kg\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 4:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 341 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2264, 16, 5, 6029, 13135, 116, 2, 2, 20, 2284, 304, 9,\n",
            "\t\t1830, 4247, 30, 408, 1693, 743, 59, 5, 3038, 9, 38966, 5447, 36, 5330, 597, 43, 15, 5, 39001, 1505,\n",
            "\t\t234, 8649, 1827, 5149, 36, 347, 6949, 322, 96, 5, 1455, 892, 6, 52, 24934, 3786, 3551, 3992, 8,\n",
            "\t\t5921, 2617, 8823, 11, 5, 2900, 9, 2623, 24162, 65, 183, 71, 10, 881, 4895, 9, 132, 1368, 7, 10, 272,\n",
            "\t\t15153, 112, 6, 3913, 41576, 6029, 23, 10, 2900, 674, 37699, 23709, 368, 24802, 14064, 36, 104, 2747,\n",
            "\t\t43, 11, 5, 1186, 9, 112, 4, 406, 7, 132, 4, 245, 305, 73, 9043, 4, 2880, 24162, 6, 4924, 7, 14850,\n",
            "\t\t597, 15, 618, 42135, 360, 36, 510, 43, 195, 36, 282, 5457, 231, 238, 379, 36, 282, 5457, 195, 43,\n",
            "\t\t50, 1718, 36, 282, 5457, 231, 238, 58, 1118, 7, 38283, 12, 18793, 7878, 18473, 10008, 24162, 36,\n",
            "\t\t282, 5457, 231, 23, 70, 4864, 322, 166, 341, 4669, 39144, 2577, 7, 10933, 2859, 4817, 17792, 36,\n",
            "\t\t725, 4186, 29, 43, 8, 44193, 366, 44869, 12, 50, 44755, 12478, 12, 3368, 17792, 11, 5, 2623, 12976,\n",
            "\t\t10191, 14190, 4, 20, 272, 15153, 6029, 56, 117, 1233, 1683, 15, 5, 18225, 9, 289, 4186, 2466, 6,\n",
            "\t\t289, 3632, 3083, 50, 289, 4186, 3248, 6, 9, 6821, 833, 13816, 991, 3175, 6, 47491, 6214, 12150,\n",
            "\t\t2696, 217, 12209, 565, 134, 8, 12209, 10388, 6, 50, 9, 5921, 2617, 856, 11804, 31867, 10395, 8276,\n",
            "\t\t36, 27150, 591, 43, 11, 1169, 746, 50, 45132, 11576, 36635, 4, 5902, 879, 2678, 661, 43941, 12673,\n",
            "\t\t9, 7522, 4671, 44368, 11, 2900, 9042, 31, 38283, 12, 18793, 7878, 8, 4924, 3122, 222, 45, 4991, 143,\n",
            "\t\t5550, 11, 5, 46930, 50, 3854, 9, 5177, 7210, 2617, 4590, 4, 1216, 775, 694, 117, 1283, 13, 13827,\n",
            "\t\t3551, 3992, 50, 5921, 2617, 11012, 22206, 9, 419, 26739, 3551, 1880, 6, 11, 2623, 15813, 4924, 7,\n",
            "\t\t112, 6, 3913, 41576, 8724, 11, 5, 1186, 9, 34565, 341, 11, 84, 892, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 341 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 341 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 341 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 341 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, False, False, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, True, False, False, True, True, True, True, True, True, True, True, False, False, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, False, False, True, True, False, False, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, False, False, True, True, True, False, False, True, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, False, False, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, False, True, True, False, False, True, True, False, False, True,\n",
            "\t\tTrue, True, False, True, False, False, True, True, True, False, False, True, True, False, False,\n",
            "\t\tTrue, True, False, True, True, True, True, False, True, False, False, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 14 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[69]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[76]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[82, 83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[104, 105, 106]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[108, 109, 110]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[129]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[133]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[135]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[139]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[142]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[146]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[161]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[325, 326, 327]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 14 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (104, 113). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 40 LabelsFields : \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[7, 8, 9]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[34, 35]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[41, 42, 43]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[46, 47]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[55, 56]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[60, 61]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[80, 81]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[82, 83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[92, 93, 94]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[97, 98]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[104, 105, 106]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[108, 109, 110]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[120, 121]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[123, 124]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[153, 154]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[155, 156]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[169, 170]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[177, 178, 179]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[182, 183, 184]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[187, 188]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[195, 196, 197]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[200, 201]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[211, 212, 213]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[215, 216, 217]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[219, 220, 221]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[224, 225]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[226, 227, 228]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[231, 232, 233]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[235, 236, 237]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[239, 240]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[244, 245]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[246, 247, 248]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[252, 253]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[263, 264, 265, 266, 267]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[270, 271]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[279, 280]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[295, 296, 297]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[310, 311]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[325, 326, 327]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 341 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 341 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 341 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 20.97553062438965, \"passage_id\": \"idx_56\", \"query_id\": \"qid_56-1\", \"answer\": {\"value\": [\"1.7\", \"2.5 W/kg\", \"postnatal days (P) 5 (n = 6), 15 (n = 5)\", \"35 (n = 6),\"], \"spans\": [[\"p\", 388, 391], [\"p\", 395, 403], [\"p\", 435, 475], [\"p\", 479, 490]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.7\", \"2.5 W/kg\"]}, \"em\": 0.0, \"f1\": 0.5, \"max_passage_length\": -1}\n",
            "\n",
            "input 5:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 313 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 33482, 35, 20, 6379, 709, 8, 2919, 9, 1830, 4372,\n",
            "\t\t17992, 7, 5, 937, 2625, 15, 5, 3038, 9, 38966, 5447, 37141, 30, 1830, 4247, 15, 5, 7464, 467, 4,\n",
            "\t\t152, 892, 5026, 23, 14978, 5, 5921, 2617, 856, 11804, 31867, 41314, 8276, 36, 27150, 591, 43, 8151,\n",
            "\t\t11, 2929, 12378, 15813, 7, 10516, 34729, 12976, 1001, 4469, 90, 13310, 6, 130, 8, 158, 360, 71, 251,\n",
            "\t\t12, 1279, 471, 12, 8338, 2849, 12, 611, 18731, 4895, 7, 10, 10742, 41576, 38966, 882, 36, 5330, 597,\n",
            "\t\t43, 6029, 6, 11, 2943, 24162, 4, 42879, 35, 14933, 17558, 12, 495, 1584, 607, 24162, 58, 4924, 13,\n",
            "\t\t2248, 5251, 73, 1208, 23, 10, 2900, 12, 9903, 4628, 2167, 33131, 731, 36, 104, 2747, 43, 5457, 112,\n",
            "\t\t4, 245, 305, 73, 9043, 50, 379, 5251, 73, 1208, 23, 10, 34565, 5457, 231, 305, 73, 9043, 13, 292,\n",
            "\t\t360, 228, 186, 148, 41, 799, 12, 3583, 675, 4, 32727, 591, 8151, 21, 9550, 30, 5, 13998, 30321, 90,\n",
            "\t\t39917, 5448, 11, 5, 511, 12378, 2900, 911, 35, 5048, 9289, 337, 40715, 6, 29012, 11312, 271, 40715,\n",
            "\t\t6, 14368, 877, 821, 44224, 9, 5, 45107, 6, 30972, 37544, 687, 26365, 808, 687, 9, 5, 28213, 15368,\n",
            "\t\t6, 8, 5, 6056, 1906, 877, 342, 21228, 4, 12499, 35, 23570, 7, 5, 31026, 12, 41104, 24162, 6, 167,\n",
            "\t\t4924, 7, 5, 2849, 12, 611, 18731, 272, 15153, 36, 18811, 5149, 13, 1830, 4372, 43, 6029, 23, 112, 4,\n",
            "\t\t245, 50, 231, 305, 73, 9043, 969, 41, 712, 11, 32727, 591, 1389, 11, 5, 430, 2900, 911, 6, 130, 8,\n",
            "\t\t2724, 360, 71, 1416, 4, 23518, 35, 1541, 775, 311, 14, 2849, 12, 611, 18731, 31548, 7, 10, 10742,\n",
            "\t\t41576, 14850, 597, 6029, 13, 80, 377, 115, 27112, 3327, 12378, 2900, 36, 13033, 9, 10, 801, 5921,\n",
            "\t\t38115, 322, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 313 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 313 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 313 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 313 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, False, False, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, False, True, True, False, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, False, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, False, False, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False,\n",
            "\t\tTrue, True, True, False, True, False, True, True, True, True, True, True, False, True, False, False,\n",
            "\t\tTrue, True, True, False, True, True, True, True, False, False, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 17 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[60]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[72]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[74]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[90]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[116]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[134, 135, 136]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[149]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[154]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[250, 251, 252]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[254]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[271]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[273]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[291]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[297]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 17 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (134, 152). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 30 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[47, 48]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[49, 50, 51]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[55, 56]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[66, 67, 68, 69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[85, 86]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[95, 96]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[106, 107]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[109, 110, 111]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[124, 125]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[130, 131]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[134, 135, 136]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[165, 166]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[172, 173, 174, 175]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[184, 185, 186]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[189, 190, 191]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[194, 195]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[196, 197]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[203, 204]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[205, 206, 207]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[210, 211]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[215, 216, 217]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[218, 219]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[237, 238]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[239, 240]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[250, 251, 252]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[262, 263]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[286, 287]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[293, 294]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[309, 310]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 313 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 313 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 313 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 20.882701873779297, \"passage_id\": \"idx_57\", \"query_id\": \"qid_57-1\", \"answer\": {\"value\": [\"1.5 W/kg\", \"6 W/kg\"], \"spans\": [[\"p\", 566, 574], [\"p\", 1027, 1030], [\"p\", 1034, 1040]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.5 W/kg\", \"6 W/kg\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 6:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 347 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 17104, 2919, 9, 1830, 4247, 8, 38966, 882, 36,\n",
            "\t\t5330, 597, 43, 4895, 34, 1179, 864, 9, 49, 678, 12243, 3038, 15, 5, 2900, 8, 7464, 467, 4, 4611,\n",
            "\t\t36274, 36, 30455, 43, 13785, 429, 11330, 19567, 4450, 45357, 22436, 25019, 149, 1022, 11, 28221, 36,\n",
            "\t\t38593, 1640, 176, 2744, 35122, 31582, 4484, 420, 3551, 42037, 4, 25065, 11, 5, 8151, 9, 28221,\n",
            "\t\t17014, 17792, 36, 38593, 21792, 43, 101, 13011, 41744, 179, 211, 2517, 12, 330, 36, 25392, 43, 8,\n",
            "\t\t13011, 4903, 179, 179, 36, 9822, 43, 115, 6364, 15241, 8316, 1640, 176, 42053, 8361, 2603, 17048,\n",
            "\t\t528, 7, 14850, 597, 4895, 4, 6933, 8, 4307, 8151, 58, 9550, 19, 13998, 2678, 661, 39917, 11, 5,\n",
            "\t\t45107, 9, 15540, 71, 14850, 597, 4895, 23, 290, 2022, 41576, 13, 430, 4895, 498, 8, 33131, 1162, 6,\n",
            "\t\t112, 1368, 73, 1208, 13, 195, 360, 23, 10, 2167, 33131, 731, 36, 104, 2747, 49143, 134, 4, 401, 305,\n",
            "\t\t73, 9043, 6, 112, 1368, 73, 1208, 13, 195, 360, 23, 34565, 5214, 306, 4, 288, 305, 73, 9043, 6, 195,\n",
            "\t\t1368, 73, 1208, 13, 112, 183, 23, 34565, 5214, 134, 4, 401, 305, 73, 9043, 6, 195, 1368, 73, 1208,\n",
            "\t\t13, 112, 183, 23, 34565, 5214, 306, 4, 288, 305, 73, 9043, 6, 1230, 4895, 13, 112, 353, 23, 34565,\n",
            "\t\t5214, 134, 4, 401, 305, 73, 9043, 4, 13048, 23341, 222, 45, 464, 3625, 4, 6933, 13998, 1688, 30280,\n",
            "\t\t36, 5216, 43, 7899, 7212, 1690, 8173, 9, 4590, 11, 5, 7636, 257, 44008, 354, 36, 4054, 43, 911, 8,\n",
            "\t\t26584, 31789, 17227, 7590, 4590, 4, 4307, 11594, 1487, 26584, 31789, 19290, 4040, 11934, 4590, 19,\n",
            "\t\t385, 1397, 39651, 878, 49413, 45555, 11, 5, 5267, 443, 4, 40032, 13, 112, 353, 2622, 818, 1498, 872,\n",
            "\t\t9, 19290, 4040, 11934, 4590, 11, 5, 5267, 134, 443, 4, 8316, 21792, 5550, 115, 1303, 1022, 11,\n",
            "\t\t19729, 8316, 1640, 176, 42053, 44280, 6, 61, 115, 33, 32169, 1334, 6514, 1683, 15, 2340, 48464, 337,\n",
            "\t\t8047, 2273, 19, 46282, 10335, 8, 7465, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 347 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 347 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 347 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 347 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tFalse, False, True, True, True, True, True, True, True, True, False, False, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tTrue, True, False, False, True, False, True, True, True, True, True, True, True, False, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, False, False, False, False, False, False, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, False, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, False, True, True, True, True, False, True, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, False, False, False, False, True, True, True, True, True, False, False,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 12 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[136, 137]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[147]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[152]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[170]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[175]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[187]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[192]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[204]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[209]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[224]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[296]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 12 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 34 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[20, 21]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[39, 40]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[47, 48, 49]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[57, 58, 59]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[62, 63]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[77, 78]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[81, 82, 83]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[84, 85]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[92, 93, 94, 95]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 7 with labels:\n",
            " \t\t[102, 103, 104, 105, 106, 107, 108]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[111, 112]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[122, 123, 124, 125]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[132, 133]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[136, 137]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 6 with labels:\n",
            " \t\t[160, 161, 162, 163, 164, 165]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[178, 179, 180, 181, 182]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[195, 196, 197, 198, 199]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[212, 213, 214, 215, 216]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[227, 228, 229, 230, 231]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[244, 245, 246]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[252, 253]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[258, 259]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[260, 261]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[269, 270]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[278, 279, 280]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[283, 284, 285]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[287, 288]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[303, 304, 305]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[309, 310]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[313, 314]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[321, 322, 323, 324, 325]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[330, 331, 332]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[336, 337]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 347 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 347 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 347 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 0 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 10000000.0, \"passage_id\": \"idx_58\", \"query_id\": \"qid_58-1\", \"answer\": {\"value\": [\"SAR=4.0 W/kg\", \"SAR=1.6 W/kg\"], \"spans\": [[\"p\", 713, 714], [\"p\", 741, 753], [\"p\", 776, 788], [\"p\", 811, 823], [\"p\", 855, 867]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.6 W/kg\", \"4.0 W/kg\"]}, \"em\": 0.0, \"f1\": 0.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 7:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 271 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 22537, 9, 5, 1830, 1028, 806, 7700, 2212, 59, 5,\n",
            "\t\t474, 3038, 9, 10742, 41576, 43698, 9419, 15, 5, 1353, 7464, 467, 36, 347, 6949, 322, 96, 42, 892,\n",
            "\t\t52, 9550, 32727, 591, 8151, 634, 13998, 30321, 90, 39917, 5448, 6, 7, 10516, 5921, 2617, 10795, 158,\n",
            "\t\t360, 71, 10, 7642, 4895, 36, 245, 360, 10, 186, 13, 706, 688, 43, 7, 272, 15153, 6029, 13, 2248,\n",
            "\t\t5251, 73, 1208, 23, 10, 2900, 12, 9903, 4628, 2167, 33131, 731, 36, 104, 2747, 49143, 134, 4, 245,\n",
            "\t\t305, 73, 9043, 8, 13, 379, 5251, 73, 1208, 23, 10, 34565, 5214, 401, 305, 73, 9043, 11, 5, 511,\n",
            "\t\t12378, 2900, 911, 35, 46695, 40715, 36, 510, 506, 347, 1178, 238, 6056, 1906, 877, 342, 21228, 36,\n",
            "\t\t347, 30738, 238, 30972, 37544, 687, 26365, 808, 687, 9, 28213, 15368, 36, 574, 12694, 238, 14368,\n",
            "\t\t877, 821, 44224, 9, 45107, 36, 495, 534, 43, 8, 29012, 11312, 783, 40715, 36, 3376, 1178, 322, 96,\n",
            "\t\t6676, 7, 31026, 50, 16051, 797, 3122, 6, 24162, 4924, 7, 7642, 272, 15153, 6029, 23, 231, 305, 73,\n",
            "\t\t9043, 33, 1130, 32727, 591, 31789, 4084, 911, 11, 5, 2900, 36, 642, 41552, 288, 4, 2546, 322, 125,\n",
            "\t\t5, 7642, 4895, 7, 272, 15153, 23, 112, 4, 245, 305, 73, 9043, 222, 45, 712, 32727, 591, 8151, 4,\n",
            "\t\t1541, 775, 4658, 14, 7642, 4895, 7, 272, 15153, 10742, 41576, 43698, 9419, 36, 104, 2747, 5214, 401,\n",
            "\t\t305, 73, 9043, 43, 189, 28944, 13109, 12976, 10191, 14190, 29997, 11, 5, 12378, 2900, 36, 13033, 9,\n",
            "\t\t10, 801, 5921, 38115, 322, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 271 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 271 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 271 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 271 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, False, True, True, True, False,\n",
            "\t\tFalse, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, False, False, False, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False,\n",
            "\t\tTrue, True, False, False, True, False, True, True, False, True, True, True, False, True, False,\n",
            "\t\tFalse, True, True, False, True, True, False, True, True, False, True, False, True, True, True, True,\n",
            "\t\tFalse, True, True, True, False, False, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, False, False, False, False,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tTrue, True, False, True, True, False, False, False, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 10 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[24]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[57]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[64]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[69]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[77]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[102]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[187]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[216, 217, 218]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[238]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 10 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 34 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[26, 27]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[34, 35]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[42, 43]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[46, 47, 48, 49]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[54, 55]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[73, 74]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[85, 86]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 6 with labels:\n",
            " \t\t[91, 92, 93, 94, 95, 96]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[108, 109, 110]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[124, 125, 126, 127]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[129, 130, 131]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[132, 133]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[135, 136]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[139, 140]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[141, 142, 143]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[145, 146]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[148, 149]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[151, 152]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[153, 154]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[158, 159]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[162, 163, 164]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[167, 168]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[183, 184]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[193, 194]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[202, 203, 204, 205, 206]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[213, 214]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[216, 217, 218]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[225, 226]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[236, 237]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[240, 241]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[243, 244, 245, 246]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[254, 255, 256]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[267, 268]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 271 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 271 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 271 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 0 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 10000000.0, \"passage_id\": \"idx_59\", \"query_id\": \"qid_59-1\", \"answer\": {\"value\": [\"SAR)=1.5 W/kg\", \"6 W/kg\", \"SAR=6 W/kg\"], \"spans\": [[\"p\", 381, 394], [\"p\", 704, 710], [\"p\", 815, 816], [\"p\", 925, 935]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.5 W/kg\", \"6 W/kg\"]}, \"em\": 0.0, \"f1\": 0.33, \"max_passage_length\": -1}\n",
            "\n",
            "input 8:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 353 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 20, 5859, 304, 9, 19729, 4247, 7700, 5, 936, 9,\n",
            "\t\t10405, 9, 38966, 5447, 19, 5, 1353, 7464, 467, 36, 347, 6949, 322, 96, 645, 7, 2450, 209, 3038, 15,\n",
            "\t\t44755, 44370, 1383, 11, 5, 41371, 6, 52, 2226, 10, 11883, 9, 44755, 44370, 12673, 716, 15, 13998,\n",
            "\t\t2678, 661, 39917, 8, 2274, 1966, 4, 43566, 12, 6320, 4360, 12, 4164, 3813, 36, 37838, 534, 238, 41,\n",
            "\t\t34496, 9, 5, 47644, 12, 9981, 13941, 3175, 21, 22993, 11, 24162, 7, 712, 47644, 11772, 11, 5, 41371,\n",
            "\t\t4, 20, 19729, 47644, 13654, 58, 172, 1487, 30, 13998, 2678, 661, 39917, 8, 4126, 12, 39064, 3786,\n",
            "\t\t30, 2274, 1966, 2446, 7, 130, 17294, 35, 17547, 16522, 36, 673, 4, 495, 12345, 1690, 8173, 443, 6,\n",
            "\t\t8, 346, 9, 1313, 4590, 4, 20, 712, 11, 29012, 11312, 271, 47644, 1383, 26914, 30, 272, 39997, 23777,\n",
            "\t\t17844, 73, 9043, 21, 7680, 11, 209, 130, 17294, 11, 5, 22481, 8, 5, 17227, 8244, 13171, 4, 9068, 6,\n",
            "\t\t797, 9, 13998, 2678, 661, 39917, 17294, 6, 561, 19, 3901, 2274, 1966, 6, 1220, 258, 5, 2259, 8, 5,\n",
            "\t\t12673, 9, 18746, 11, 19729, 44755, 44370, 1383, 4, 152, 11883, 21, 341, 7, 4830, 5, 3038, 9, 4895,\n",
            "\t\t7, 10742, 41576, 3188, 506, 42172, 14768, 15, 29012, 11312, 271, 47644, 1383, 4, 1868, 33463, 196,\n",
            "\t\t22679, 19, 10, 2167, 33131, 731, 36, 104, 2747, 43, 9, 204, 305, 73, 9043, 8, 11152, 22679, 19, 239,\n",
            "\t\t34565, 36, 2881, 305, 73, 9043, 43, 58, 4776, 4, 166, 6373, 10, 21921, 29063, 15175, 9, 5, 31789,\n",
            "\t\t5588, 443, 11, 5, 11834, 4245, 2359, 3551, 10490, 71, 4895, 7, 33463, 196, 3188, 36274, 8, 6, 11,\n",
            "\t\t1285, 6, 10, 7280, 11, 384, 4, 495, 4, 11, 5, 130, 3551, 13171, 71, 4895, 7, 11152, 6995, 4, 5994,\n",
            "\t\t42, 1683, 16, 6, 23, 513, 5647, 6, 528, 7, 10, 400, 11545, 9, 5, 25671, 16, 45, 684, 4, 7806, 6, 24,\n",
            "\t\t2092, 14, 239, 20425, 3188, 36274, 4895, 45645, 10, 29063, 15175, 11, 19729, 47644, 1383, 11, 5,\n",
            "\t\t29012, 11312, 783, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 353 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 353 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 353 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 353 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, False, False, False, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, False, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tFalse, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tFalse, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, False, True, True, True, True, True, True, False, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True,\n",
            "\t\tTrue]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 8 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[120]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[152]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[213]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[240]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[251]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[298]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 8 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 2 SpanFields : \n",
            " \t SpanField with spans: (240, 254). \n",
            " \t SpanField with spans: (240, 255). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 30 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[31, 32]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[41, 42]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[53, 54]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[58, 59, 60, 61]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[68, 69]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[71, 72]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[74, 75]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[83, 84, 85]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[106, 107, 108, 109]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[113, 114]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[126, 127, 128, 129]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[130, 131]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[143, 144, 145]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[150, 151]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[167, 168]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[175, 176, 177, 178]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[198, 199]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[215, 216, 217, 218]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[220, 221, 222]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[227, 228]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[236, 237]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[263, 264]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[272, 273, 274]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[280, 281]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[282, 283]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[292, 293, 294, 295]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[335, 336]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[340, 341]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[348, 349, 350]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 353 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 3 LabelsFields : \n",
            " \t LabelsField of length 353 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 353 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 353 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 353 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 20.46535873413086, \"passage_id\": \"idx_60\", \"query_id\": \"qid_60-1\", \"answer\": {\"value\": [\"4 W/kg\", \"32 W/kg\"], \"spans\": [[\"p\", 1167, 1173], [\"p\", 1213, 1220]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"4 W/kg\", \"32 W/kg\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 9:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 383 with labels:\n",
            " \t\t[0, 653, 16, 5, 6029, 13135, 116, 2, 2, 12806, 47782, 712, 11, 1830, 1028, 2939, 6, 576, 1430, 7,\n",
            "\t\t285, 2212, 2624, 5, 1697, 32169, 1334, 6514, 474, 21125, 25, 10, 15180, 9, 14308, 4895, 4, 96, 199,\n",
            "\t\t6, 5, 121, 4, 104, 4, 496, 8422, 4383, 586, 431, 6, 80, 76, 8422, 9779, 3218, 13, 801, 474, 21125,\n",
            "\t\t31, 4895, 7, 3551, 1028, 22750, 1635, 4, 14230, 8554, 15557, 11134, 16685, 310, 10, 2008, 4099, 774,\n",
            "\t\t11, 171, 19729, 8047, 8, 43758, 1274, 4, 96, 42, 892, 6, 52, 11852, 5, 12234, 12, 30231, 8, 13135,\n",
            "\t\t12, 30231, 44323, 15557, 46404, 36, 39287, 8, 31862, 1264, 39902, 1258, 43, 11, 5, 45107, 9, 305,\n",
            "\t\t31732, 24162, 4, 83, 5480, 9, 8971, 2943, 305, 31732, 24162, 58, 31522, 88, 316, 1134, 4924, 7,\n",
            "\t\t10742, 41576, 6, 18360, 41576, 8, 706, 1096, 41576, 18044, 12, 19454, 23, 10, 2167, 33131, 731, 36,\n",
            "\t\t104, 2747, 43, 9, 195, 4, 6232, 17935, 158, 12, 306, 305, 73, 9043, 6, 195, 4, 6405, 17935, 158, 12,\n",
            "\t\t306, 305, 73, 9043, 8, 231, 4, 306, 17935, 158, 12, 306, 305, 73, 9043, 4067, 13, 132, 1368, 228,\n",
            "\t\t183, 13, 112, 12, 2151, 6, 155, 12, 2151, 8, 231, 12, 2151, 5788, 4, 497, 5, 253, 9, 5, 4895, 13428,\n",
            "\t\t6, 3122, 58, 26936, 7, 5555, 5, 45107, 4, 1849, 48464, 337, 5708, 39902, 1258, 8, 33945, 1264,\n",
            "\t\t39902, 1258, 58, 2319, 30, 17678, 30483, 4, 635, 6, 5708, 39902, 1295, 35309, 6, 5708, 39902, 40095,\n",
            "\t\t3175, 134, 36, 40795, 11674, 134, 43, 8, 33945, 1264, 39902, 1295, 35309, 364, 4272, 5638, 5183,\n",
            "\t\t33945, 1264, 39902, 212, 28584, 6646, 3175, 134, 36, 38832, 11674, 134, 43, 8151, 21, 15423, 30,\n",
            "\t\t588, 12, 958, 45125, 6, 25, 157, 25, 617, 29548, 19, 2027, 39144, 4, 33971, 1258, 11, 44323, 15557,\n",
            "\t\t46404, 21, 6373, 11, 5, 45107, 4, 1849, 5708, 39902, 1258, 21, 8065, 8, 33945, 1264, 39902, 1258,\n",
            "\t\t21, 1130, 11, 5, 45107, 4, 166, 6373, 14, 28562, 4895, 669, 7, 1233, 44323, 15557, 11134, 16685, 11,\n",
            "\t\t5, 45107, 19, 2284, 13135, 8, 13428, 9, 4895, 4, 8900, 4610, 4097, 4895, 19, 2284, 13135, 8, 4895,\n",
            "\t\t13428, 3291, 1233, 36, 642, 28696, 321, 4, 2546, 43, 44323, 15557, 11134, 16685, 61, 43093, 10596,\n",
            "\t\t8151, 11, 5, 45107, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 383 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 383 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 383 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 383 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, False, False, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, True, False, True, False, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, True, False, False, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, False, True, True, False, True, False, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, False, False, False, True, True, False,\n",
            "\t\tFalse, True, True, True, False, True, False, True, True, False, False, False, True, False, True,\n",
            "\t\tFalse, False, False, False, False, True, True, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True,\n",
            "\t\tTrue, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, False, True, True, False, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 22 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[38]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[51]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[122]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[130]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[134]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[137]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[156, 157, 158]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[162]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[167, 168, 169]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[171]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[173]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[178, 179, 180]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[182]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[184]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[190]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[195]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[199]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[203]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[366, 367, 368]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 22 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (134, 142). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 44 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[9, 10]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[25, 26, 27]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[41, 42, 43, 44]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[46, 47]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[53, 54]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[65, 66]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[68, 69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[71, 72]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[100, 101]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[106, 107]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[108, 109]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[115, 116]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[124, 125]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[152, 153]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[156, 157, 158]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[167, 168, 169]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[178, 179, 180]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[225, 226]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[228, 229]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[231, 232]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[233, 234]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[238, 239]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[244, 245]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[249, 250, 251, 252]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[254, 255, 256]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[259, 260]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[261, 262]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[264, 265, 266, 267]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[268, 269]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 6 with labels:\n",
            " \t\t[270, 271, 272, 273, 274, 275]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[277, 278, 279]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[299, 300]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[302, 303]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[313, 314]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[318, 319]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[320, 321]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[336, 337]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[338, 339]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[351, 352, 353]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[366, 367, 368]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[370, 371]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[372, 373]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 383 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 383 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 383 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 19.665361404418945, \"passage_id\": \"idx_61\", \"query_id\": \"qid_61-1\", \"answer\": {\"value\": [\"900 MHz\", \"1800 MHz\", \"2450 MHz\"], \"spans\": [[\"p\", 658, 665], [\"p\", 667, 675], [\"p\", 680, 688]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"900 MHz\", \"1800 MHz\", \"2450 MHz\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 10:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 385 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 12806, 47782, 712, 11, 1830, 1028, 2939, 6, 576,\n",
            "\t\t1430, 7, 285, 2212, 2624, 5, 1697, 32169, 1334, 6514, 474, 21125, 25, 10, 15180, 9, 14308, 4895, 4,\n",
            "\t\t96, 199, 6, 5, 121, 4, 104, 4, 496, 8422, 4383, 586, 431, 6, 80, 76, 8422, 9779, 3218, 13, 801, 474,\n",
            "\t\t21125, 31, 4895, 7, 3551, 1028, 22750, 1635, 4, 14230, 8554, 15557, 11134, 16685, 310, 10, 2008,\n",
            "\t\t4099, 774, 11, 171, 19729, 8047, 8, 43758, 1274, 4, 96, 42, 892, 6, 52, 11852, 5, 12234, 12, 30231,\n",
            "\t\t8, 13135, 12, 30231, 44323, 15557, 46404, 36, 39287, 8, 31862, 1264, 39902, 1258, 43, 11, 5, 45107,\n",
            "\t\t9, 305, 31732, 24162, 4, 83, 5480, 9, 8971, 2943, 305, 31732, 24162, 58, 31522, 88, 316, 1134, 4924,\n",
            "\t\t7, 10742, 41576, 6, 18360, 41576, 8, 706, 1096, 41576, 18044, 12, 19454, 23, 10, 2167, 33131, 731,\n",
            "\t\t36, 104, 2747, 43, 9, 195, 4, 6232, 17935, 158, 12, 306, 305, 73, 9043, 6, 195, 4, 6405, 17935, 158,\n",
            "\t\t12, 306, 305, 73, 9043, 8, 231, 4, 306, 17935, 158, 12, 306, 305, 73, 9043, 4067, 13, 132, 1368,\n",
            "\t\t228, 183, 13, 112, 12, 2151, 6, 155, 12, 2151, 8, 231, 12, 2151, 5788, 4, 497, 5, 253, 9, 5, 4895,\n",
            "\t\t13428, 6, 3122, 58, 26936, 7, 5555, 5, 45107, 4, 1849, 48464, 337, 5708, 39902, 1258, 8, 33945,\n",
            "\t\t1264, 39902, 1258, 58, 2319, 30, 17678, 30483, 4, 635, 6, 5708, 39902, 1295, 35309, 6, 5708, 39902,\n",
            "\t\t40095, 3175, 134, 36, 40795, 11674, 134, 43, 8, 33945, 1264, 39902, 1295, 35309, 364, 4272, 5638,\n",
            "\t\t5183, 33945, 1264, 39902, 212, 28584, 6646, 3175, 134, 36, 38832, 11674, 134, 43, 8151, 21, 15423,\n",
            "\t\t30, 588, 12, 958, 45125, 6, 25, 157, 25, 617, 29548, 19, 2027, 39144, 4, 33971, 1258, 11, 44323,\n",
            "\t\t15557, 46404, 21, 6373, 11, 5, 45107, 4, 1849, 5708, 39902, 1258, 21, 8065, 8, 33945, 1264, 39902,\n",
            "\t\t1258, 21, 1130, 11, 5, 45107, 4, 166, 6373, 14, 28562, 4895, 669, 7, 1233, 44323, 15557, 11134,\n",
            "\t\t16685, 11, 5, 45107, 19, 2284, 13135, 8, 13428, 9, 4895, 4, 8900, 4610, 4097, 4895, 19, 2284, 13135,\n",
            "\t\t8, 4895, 13428, 3291, 1233, 36, 642, 28696, 321, 4, 2546, 43, 44323, 15557, 11134, 16685, 61, 43093,\n",
            "\t\t10596, 8151, 11, 5, 45107, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 385 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 385 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 385 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 385 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, False, False, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, False, True, False,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, False, True, True, False, True, False, True, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, False, True, True, True, True, False, False, False, True,\n",
            "\t\tTrue, False, False, True, True, True, False, True, False, True, True, False, False, False, True,\n",
            "\t\tFalse, True, False, False, False, False, False, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tTrue, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, False, True, True, False, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 22 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[40]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[53]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[124]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[132]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[136]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[139]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[142, 143]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[158, 159, 160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[162]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[164]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[169, 170, 171]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[173]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[175]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[180, 181, 182]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[184]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[186]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[192]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[197]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[201]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[205]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[368, 369, 370]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 22 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (158, 189). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 44 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[11, 12]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[27, 28, 29]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[43, 44, 45, 46]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[48, 49]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[55, 56]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[67, 68]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[70, 71, 72]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[73, 74]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[102, 103]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[108, 109]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[110, 111]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[117, 118]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[126, 127]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[142, 143]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[154, 155]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[158, 159, 160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[169, 170, 171]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[180, 181, 182]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[227, 228]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[230, 231]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[233, 234]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[235, 236]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[240, 241]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[246, 247]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[251, 252, 253, 254]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[256, 257, 258]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[261, 262]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[263, 264]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[266, 267, 268, 269]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[270, 271]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 6 with labels:\n",
            " \t\t[272, 273, 274, 275, 276, 277]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[279, 280, 281]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[301, 302]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[304, 305]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[315, 316]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[320, 321]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[322, 323]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[338, 339]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[340, 341]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[353, 354, 355]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[368, 369, 370]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[372, 373]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[374, 375]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 385 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 385 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 385 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 20.655698776245117, \"passage_id\": \"idx_62\", \"query_id\": \"qid_62-1\", \"answer\": {\"value\": [\"1800\", \"5.84 \\u00d7 10-4 W/kg\", \"5.94 \\u00d7 10-4 W/kg\", \"6.4 \\u00d7 10-4 W/kg\"], \"spans\": [[\"p\", 667, 671], [\"p\", 734, 750], [\"p\", 752, 768], [\"p\", 773, 788]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"5.84 \\u00d7 10-4 W/kg\", \"5.94 \\u00d7 10-4 W/kg\", \"6.4 \\u00d7 10-4 W/kg\"]}, \"em\": 0.0, \"f1\": 0.75, \"max_passage_length\": -1}\n",
            "\n",
            "input 11:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 180 with labels:\n",
            " \t\t[0, 1336, 171, 3122, 58, 341, 116, 2, 2, 32070, 35, 20, 5859, 304, 9, 6955, 2110, 148, 5, 94, 1724,\n",
            "\t\t16, 3282, 1379, 59, 12661, 474, 3038, 9, 5, 3188, 36274, 38966, 13785, 36, 30455, 12, 5330, 500, 43,\n",
            "\t\t37141, 31, 209, 2110, 4, 12845, 557, 16, 5650, 15, 21697, 154, 5, 7482, 14519, 9, 18044, 12, 5330,\n",
            "\t\t500, 8, 801, 19729, 3247, 4, 20, 128, 26382, 108, 239, 12, 11672, 9179, 8369, 32, 2247, 3270, 7,\n",
            "\t\t4830, 5, 720, 3038, 9, 18044, 12, 5330, 500, 15, 19729, 41966, 4, 42879, 35, 96, 42, 173, 6, 230,\n",
            "\t\t4390, 7976, 73, 401, 4194, 2943, 15540, 58, 1086, 12, 9773, 4924, 36, 282, 39891, 5457, 290, 43, 13,\n",
            "\t\t132, 42957, 7, 272, 15153, 18360, 41576, 1830, 1028, 13785, 23, 41, 674, 3459, 882, 10603, 1186, 9,\n",
            "\t\t204, 4, 246, 12, 1360, 4, 245, 468, 73, 119, 50, 31026, 12, 18793, 7878, 36, 282, 3388, 5457, 290,\n",
            "\t\t238, 8, 5, 18044, 12, 5330, 500, 3038, 15, 5, 48464, 337, 44278, 4399, 8, 12348, 4399, 11729, 58,\n",
            "\t\t11852, 231, 42957, 423, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 180 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 180 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 180 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 180 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, False, False, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, False, True, True, False, False, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, True, True, True, True, False, True, False, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 8 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[114]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[117]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[122]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[135, 136, 137]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[139, 140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[154]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[175]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 8 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (111, 114). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 18 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[30, 31]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[37, 38]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[50, 51]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[58, 59]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[71, 72]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[85, 86]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[97, 98, 99, 100, 101]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[111, 112]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[120, 121]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[135, 136, 137]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[139, 140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[148, 149]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[151, 152]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[160, 161]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[165, 166]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[167, 168]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[170, 171]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 180 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 180 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 180 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 14.037240982055664, \"passage_id\": \"idx_63\", \"query_id\": \"qid_63-1\", \"answer\": {\"value\": [\"=\"], \"spans\": [[\"p\", 522, 523]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"whole-body exposed (nExp = 8)\", \"sham-exposed (nSE = 8)\"]}, \"em\": 0.0, \"f1\": 0.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 12:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 364 with labels:\n",
            " \t\t[0, 653, 16, 5, 6029, 13135, 116, 2, 2, 35671, 3699, 35, 20, 2284, 731, 9, 81, 634, 3551, 4247, 34,\n",
            "\t\t57, 9712, 11, 10769, 8, 5283, 390, 4, 166, 10543, 5, 1683, 9, 1830, 4247, 13785, 15, 14819, 8151,\n",
            "\t\t21875, 15, 29012, 11312, 783, 9, 37914, 387, 73, 438, 15540, 137, 8, 71, 9, 5, 3113, 4, 13982, 8,\n",
            "\t\t6448, 35, 96, 42, 892, 6, 10, 1830, 1028, 11914, 2089, 6, 61, 16, 41, 10320, 7, 2097, 2806, 8724,\n",
            "\t\t227, 19729, 4247, 8, 1542, 6214, 44168, 4492, 36, 7109, 32407, 10742, 8, 18360, 41576, 43, 13, 4895,\n",
            "\t\t21, 341, 8, 11971, 5283, 15540, 36, 387, 2118, 387, 73, 438, 43, 6408, 88, 80, 1134, 36, 282, 5214,\n",
            "\t\t401, 238, 78, 333, 45708, 15253, 11, 6690, 675, 36, 1646, 212, 183, 238, 5, 200, 333, 222, 45,\n",
            "\t\t45708, 10599, 11, 6690, 675, 4, 572, 34884, 6, 28491, 58, 8967, 88, 237, 1134, 36, 282, 5214, 306,\n",
            "\t\t3256, 826, 134, 35, 797, 6, 826, 132, 35, 163, 134, 36, 34547, 7822, 15253, 71, 3113, 238, 826, 155,\n",
            "\t\t35, 163, 176, 36, 34547, 7822, 15253, 11, 6690, 675, 8, 71, 3113, 238, 826, 204, 35, 163, 246, 36,\n",
            "\t\t34547, 7822, 15253, 11, 6690, 675, 322, 520, 14207, 21, 2121, 36, 398, 12, 698, 688, 793, 238,\n",
            "\t\t15540, 58, 33562, 196, 8, 29012, 11312, 783, 21, 8067, 4, 20, 8151, 672, 9, 741, 3631, 6, 741, 3998,\n",
            "\t\t12, 176, 6, 181, 2146, 8, 181, 4540, 14819, 10543, 30, 588, 12, 958, 7213, 37118, 31260, 3175, 3206,\n",
            "\t\t4289, 36, 17105, 12, 14699, 10541, 12, 45125, 322, 12499, 35, 20, 414, 969, 14, 1830, 1028, 3188,\n",
            "\t\t6995, 58, 21223, 15, 5, 8151, 672, 9, 741, 3998, 12, 176, 8, 181, 4540, 14819, 43, 221, 15698, 288,\n",
            "\t\t4, 2546, 1640, 4, 1578, 10596, 8151, 672, 9, 741, 3631, 8065, 8, 10596, 8151, 672, 9, 181, 2146,\n",
            "\t\t1130, 12818, 7, 5, 797, 333, 36, 510, 41552, 288, 4, 2546, 322, 23518, 35, 1740, 5, 4756, 414, 24,\n",
            "\t\t115, 28, 4633, 14, 5, 1830, 1028, 22750, 1635, 222, 45, 28944, 47854, 13310, 11, 4590, 9, 5, 29012,\n",
            "\t\t11312, 783, 8, 5, 1710, 4590, 64, 28, 21298, 30, 3551, 4943, 2237, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 364 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 364 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 364 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 364 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, False, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, False, True, True, False, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, False, False, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, False, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, False, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, False, True, True, True, True, False, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True,\n",
            "\t\tTrue, False, False, False, False, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False,\n",
            "\t\tFalse, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, False, True, True, True, True, True, False, False, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 15 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[89]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[91]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[93]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[101]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[113]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[128, 129]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[150]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[163]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[175]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[191]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[208]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[210]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[235]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[282]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 15 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (91, 94). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 35 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[9, 10]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[42, 43, 44]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[46, 47]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[85, 86]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[105, 106, 107]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[116, 117, 118]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[122, 123]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[128, 129]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[137, 138]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[153, 154, 155]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[157, 158]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[165, 166]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[168, 169, 170]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[177, 178]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[180, 181, 182]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[193, 194]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[196, 197, 198]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[216, 217]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[219, 220, 221]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[229, 230]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[232, 233]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[237, 238]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[240, 241]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[250, 251]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[279, 280]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[284, 285]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[288, 289, 290, 291, 292]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[300, 301]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[308, 309]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[317, 318, 319, 320, 321]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[337, 338]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[342, 343]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[348, 349, 350]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 364 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 364 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 364 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 9.719344139099121, \"passage_id\": \"idx_64\", \"query_id\": \"qid_64-1\", \"answer\": {\"value\": [\"900\", \"1800 MHz\"], \"spans\": [[\"p\", 434, 437], [\"p\", 442, 450]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"900\", \"1800 MHz\"]}, \"em\": 1.0, \"f1\": 1.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 13:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 293 with labels:\n",
            " \t\t[0, 653, 16, 5, 6029, 13135, 116, 2, 2, 33482, 35, 598, 8085, 5, 22481, 3038, 9, 13827, 8, 7642,\n",
            "\t\t4895, 7, 258, 10742, 8, 32160, 41576, 3188, 36274, 38966, 13785, 36, 30455, 12, 5330, 500, 43, 15,\n",
            "\t\t5, 48464, 337, 672, 73, 30280, 9, 103, 9, 5, 35309, 111, 217, 221, 14559, 6, 8316, 24632, 11194,\n",
            "\t\t44721, 6, 28122, 387, 6, 8, 181, 3305, 73, 3714, 36890, 530, 111, 31, 234, 12, 46988, 12, 495, 12,\n",
            "\t\t281, 7755, 877, 33915, 36, 487, 12550, 2747, 19281, 3368, 22436, 25019, 4, 13982, 8, 6448, 35,\n",
            "\t\t44478, 58, 6408, 88, 5, 511, 1134, 35, 31026, 24162, 6, 8, 24162, 4924, 7, 10742, 8, 32160, 41576,\n",
            "\t\t18044, 12, 5330, 500, 13, 132, 1368, 73, 1208, 13, 13827, 36, 134, 186, 43, 50, 7642, 36, 698, 688,\n",
            "\t\t238, 4067, 4, 2027, 39144, 2577, 8, 1940, 20104, 8446, 4113, 58, 341, 7, 7118, 5, 672, 73, 30280, 9,\n",
            "\t\t5, 3919, 35309, 4, 12499, 35, 20, 4756, 775, 1487, 14, 5, 48464, 337, 672, 73, 30280, 9, 3919,\n",
            "\t\t35309, 21, 3625, 723, 11, 5, 7642, 1134, 25, 1118, 7, 5, 13827, 1134, 23, 258, 10742, 8, 32160,\n",
            "\t\t41576, 18044, 12, 5330, 500, 4895, 4, 96, 1285, 6, 48464, 337, 672, 73, 30280, 9, 3919, 35309, 21,\n",
            "\t\t3625, 723, 23, 32160, 41576, 18044, 12, 5330, 500, 87, 10742, 41576, 18044, 12, 5330, 500, 11, 258,\n",
            "\t\t13827, 8, 7642, 1134, 4, 2585, 41092, 35, 20, 1455, 892, 1639, 14073, 1283, 14, 258, 4895, 13428,\n",
            "\t\t36, 134, 186, 4411, 158, 688, 43, 8, 430, 6994, 32407, 36, 7784, 1954, 4, 32160, 41576, 43, 56, 430,\n",
            "\t\t3038, 15, 5, 8276, 8151, 9, 45107, 11, 305, 31732, 24162, 6, 61, 429, 3803, 617, 557, 15, 2591, 136,\n",
            "\t\t18044, 12, 5330, 500, 4895, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 293 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 293 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 293 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, False, False, False, True, True, False, True, True, True,\n",
            "\t\tFalse, False, False, True, False, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tFalse, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 16 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[23]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[25]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[109]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[111]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[118]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[125]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[131]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[188]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[190]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[213]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[220]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[247]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[250]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[258]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[261]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 16 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 3 SpanFields : \n",
            " \t SpanField with spans: (109, 112). \n",
            " \t SpanField with spans: (188, 191). \n",
            " \t SpanField with spans: (23, 26). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 22 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[27, 28]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[34, 35]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[39, 40]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[51, 52]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[54, 55, 56, 57]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[59, 60]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[63, 64, 65, 66]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[67, 68]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[77, 78, 79]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[82, 83, 84, 85]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[115, 116]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[137, 138]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[142, 143]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[165, 166]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[194, 195]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[201, 202]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[217, 218]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[224, 225]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[233, 234]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[274, 275]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[288, 289]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 7 LabelsFields : \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 19.842334747314453, \"passage_id\": \"idx_65\", \"query_id\": \"qid_65-1\", \"answer\": {\"value\": [\"900\", \"2100 MHz\"], \"spans\": [[\"p\", 428, 431], [\"p\", 436, 444], [\"p\", 815, 818], [\"p\", 823, 831], [\"p\", 937, 945], [\"p\", 1157, 1160], [\"p\", 1165, 1173]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"900 MHz\", \"2100 MHz\"]}, \"em\": 0.0, \"f1\": 0.83, \"max_passage_length\": -1}\n",
            "\n",
            "input 14:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 335 with labels:\n",
            " \t\t[0, 653, 16, 5, 6029, 13135, 116, 2, 2, 20, 4554, 9, 42, 892, 16, 7, 4830, 678, 12243, 3038, 9,\n",
            "\t\t3188, 36274, 38966, 5447, 36, 30455, 12, 5330, 597, 43, 25, 341, 11, 2297, 6955, 8327, 24741, 11,\n",
            "\t\t10, 157, 12, 9947, 14073, 1737, 634, 5884, 37961, 709, 25, 3477, 1421, 4, 18201, 7689, 58, 23125,\n",
            "\t\t1070, 223, 11152, 14073, 4895, 7, 272, 15153, 36, 134, 4, 398, 37037, 238, 211, 15004, 36, 134, 4,\n",
            "\t\t4652, 37037, 238, 22759, 2685, 36, 176, 4, 134, 37037, 238, 8, 305, 20606, 36, 245, 4, 401, 37037,\n",
            "\t\t43, 13785, 6, 19, 5, 3901, 46404, 11883, 6, 634, 10, 9486, 42019, 882, 3854, 23, 10, 882, 2707, 9,\n",
            "\t\t2219, 155, 468, 73, 119, 6, 4561, 5, 4532, 882, 672, 11, 10, 2340, 1207, 1737, 4, 43209, 12, 44656,\n",
            "\t\t196, 4895, 2833, 73, 38299, 23125, 3629, 58, 1633, 11, 12980, 13, 4924, 8, 797, 7689, 11, 10, 23377,\n",
            "\t\t415, 1538, 9486, 42019, 1737, 6, 634, 13411, 7689, 228, 1416, 11, 130, 12565, 5509, 228, 1416, 4,\n",
            "\t\t25840, 757, 21262, 9, 5, 4895, 36, 1399, 12720, 8, 2167, 33131, 731, 43, 58, 8069, 4, 33271, 17294,\n",
            "\t\t8069, 1165, 37961, 744, 148, 23125, 1258, 6, 1368, 20262, 3164, 6, 8, 1337, 38675, 9779, 8, 33945,\n",
            "\t\t9779, 17294, 9, 32293, 8, 38087, 8, 49, 16976, 6, 8, 10596, 8151, 11729, 9, 32293, 15, 183, 262, 8,\n",
            "\t\t183, 504, 9, 23125, 1258, 30, 5177, 30766, 8, 2231, 4794, 500, 4, 440, 37847, 1283, 21, 303, 13,\n",
            "\t\t26914, 43982, 15812, 50, 8196, 3899, 1635, 30, 4895, 7, 5, 341, 14850, 34417, 6, 50, 13, 3038, 15,\n",
            "\t\t5, 97, 9550, 17294, 4, 33991, 5550, 227, 1416, 1134, 58, 460, 650, 8, 5, 1683, 9, 1416, 21, 45,\n",
            "\t\t1233, 4, 96, 10, 17325, 1421, 14, 8266, 678, 10405, 227, 5509, 8, 4895, 2833, 6, 103, 9, 5, 171,\n",
            "\t\t1763, 10715, 17941, 9, 4924, 4411, 797, 56, 221, 12, 43994, 795, 87, 321, 4, 2546, 6, 53, 58, 45,\n",
            "\t\t1233, 71, 14921, 13, 1533, 3044, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 335 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 335 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 335 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 335 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tFalse, True, True, False, False, True, True, True, False, True, True, False, False, True, True,\n",
            "\t\tTrue, False, True, True, False, False, True, True, True, True, False, True, True, False, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True,\n",
            "\t\tFalse, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True,\n",
            "\t\tTrue, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tFalse, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 11 LabelsFields : \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[66, 67, 68]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[74, 75, 76]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[82, 83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[91, 92, 93]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[116]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[161]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[166]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[227]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[230]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[320, 321, 322]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 11 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 2 SpanFields : \n",
            " \t SpanField with spans: (63, 94). \n",
            " \t SpanField with spans: (63, 95). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 30 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[21, 22]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[28, 29]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[36, 37]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[56, 57]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[63, 64]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[66, 67, 68]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[71, 72]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[74, 75, 76]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[79, 80]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[82, 83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[88, 89]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[91, 92, 93]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[106, 107]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[134, 135]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[153, 154, 155]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[156, 157]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[172, 173, 174]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[196, 197]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[199, 200]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[205, 206]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[208, 209]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[232, 233]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[235, 236]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[238, 239, 240]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[252, 253, 254]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[260, 261]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[307, 308]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[320, 321, 322]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 335 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 3 LabelsFields : \n",
            " \t LabelsField of length 335 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 335 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 335 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 335 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 20.130401611328125, \"passage_id\": \"idx_66\", \"query_id\": \"qid_66-1\", \"answer\": {\"value\": [\"1.8 GHz\", \"DECT (1.88 GHz\", \"2.1 GHz\", \"5.6 GHz\"], \"spans\": [[\"p\", 340, 347], [\"p\", 350, 364], [\"p\", 373, 380], [\"p\", 393, 400]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.8 GHz\", \"1.88 GHz\", \"2.1 GHz\", \"5.6 GHz\"]}, \"em\": 0.0, \"f1\": 0.75, \"max_passage_length\": -1}\n",
            "\n",
            "input 15:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 408 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 20, 4554, 9, 42, 892, 21, 7, 4830, 5, 3038, 9, 80,\n",
            "\t\t1715, 9, 38966, 5447, 36, 5330, 34417, 43, 15, 5, 27067, 4399, 9, 29012, 11312, 783, 6, 45107, 6, 8,\n",
            "\t\t39102, 45776, 11, 4317, 428, 73, 438, 15540, 511, 251, 12, 1279, 1086, 809, 45708, 16546, 4, 2873,\n",
            "\t\t6681, 6408, 1134, 9, 3122, 36, 401, 3122, 73, 13839, 43, 58, 341, 131, 5, 78, 333, 21, 4924, 7, 10,\n",
            "\t\t6097, 1830, 1028, 6, 23, 10, 34565, 672, 1186, 9, 321, 4, 1360, 12, 288, 4, 3272, 305, 73, 9043, 13,\n",
            "\t\t155, 1368, 1230, 13, 290, 377, 6, 5, 200, 333, 21, 4924, 7, 10, 6955, 211, 15004, 1542, 36, 30219,\n",
            "\t\t37542, 11931, 1672, 31121, 73, 41854, 17283, 43, 23, 10, 34565, 672, 1186, 9, 321, 4, 37524, 12,\n",
            "\t\t288, 4, 40709, 305, 73, 9043, 13, 290, 1368, 73, 1208, 67, 13, 290, 377, 8, 5, 371, 333, 13822, 5,\n",
            "\t\t31026, 12, 18793, 7878, 3122, 4, 20492, 3693, 27067, 26382, 1966, 1487, 14, 251, 12, 1279, 45708,\n",
            "\t\t16546, 31, 258, 14850, 597, 1715, 15992, 3625, 36, 642, 28696, 321, 4, 2546, 43, 5, 8151, 9, 22726,\n",
            "\t\t17792, 11, 746, 36, 281, 614, 25, 321, 4, 33490, 14789, 159, 40757, 62, 7, 15900, 14789, 39919,\n",
            "\t\t44813, 21791, 322, 3646, 26739, 5043, 1330, 17792, 36, 118, 4, 242, 482, 4573, 2617, 274, 11804,\n",
            "\t\t31867, 33784, 636, 34786, 36, 27150, 591, 238, 7829, 12, 38972, 40143, 179, 6, 4573, 493, 256,\n",
            "\t\t41628, 19372, 6212, 36, 16972, 597, 238, 8, 6256, 1168, 42818, 45194, 381, 36, 24812, 717, 46934,\n",
            "\t\t2859, 4817, 17792, 6, 8, 44193, 366, 1071, 43669, 17792, 36, 118, 4, 242, 482, 28132, 18419, 26494,\n",
            "\t\t8, 37473, 1075, 1630, 27377, 43, 32, 1165, 11, 42, 889, 25, 157, 25, 17792, 9, 5, 2900, 30147, 36,\n",
            "\t\t118, 4, 242, 482, 287, 7755, 877, 524, 179, 1242, 28584, 6646, 3175, 6, 4573, 1182, 45530, 36410,\n",
            "\t\t26759, 3175, 43, 7, 823, 70, 2900, 3806, 8069, 4, 2027, 39144, 1966, 15, 3919, 17792, 1474, 5,\n",
            "\t\t27067, 26382, 414, 4, 20, 6373, 8276, 8151, 1022, 189, 28, 1330, 7, 2900, 4136, 1571, 35081, 6,\n",
            "\t\t22206, 9, 46099, 3992, 11, 5, 7464, 467, 50, 963, 11, 47854, 13310, 8, 429, 2905, 3922, 1050, 474,\n",
            "\t\t21125, 431, 98, 444, 6, 215, 25, 20816, 6, 3581, 20771, 6, 16069, 6, 3783, 16567, 6, 8, 2900, 16570,\n",
            "\t\t251, 12, 1279, 26076, 223, 1122, 4895, 1274, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 408 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 408 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 408 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 408 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, True, False, True, True, False, False, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True,\n",
            "\t\tTrue, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, False, False, True, True, False, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, True, False, True, False, True, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, False, True, True, True, True, True, True, True, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False,\n",
            "\t\tTrue, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, False, True, True, False, True, False, False, True, False, True, True, True,\n",
            "\t\tFalse, True, True, True, True, False, False, True, True, False, True, False, True, True, True, True,\n",
            "\t\tFalse, True, True, True, False, False, False, True, True, True, False, True, True, True, True, True,\n",
            "\t\tTrue, True, False, False, False, True, True, True, False, False, True, True, False, False, True,\n",
            "\t\tTrue, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, False, True, True, False, False, True, False, False, False, False,\n",
            "\t\tFalse, True, True, False, False, True, False, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 16 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[22]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[60]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[67]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[92, 93, 94]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[96, 97, 98]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[103]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[107]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[137, 138, 139]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[141, 142, 143]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[148]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[154]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[190, 191, 192]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[197]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[205, 206, 207]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[213]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 16 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (92, 101). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 45 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[28, 29]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[33, 34]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[36, 37, 38]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[46, 47]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[57, 58]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[92, 93, 94]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[96, 97, 98]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[118, 119]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[124, 125]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[128, 129]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[137, 138, 139]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[141, 142, 143]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[164, 165]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[168, 169]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[170, 171]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[178, 179]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[182, 183]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[190, 191, 192]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[205, 206, 207]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[209, 210]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[215, 216, 217]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[225, 226, 227]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[229, 230]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[231, 232, 233]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[234, 235]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[238, 239]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[243, 244, 245]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[247, 248]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[249, 250]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[254, 255]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[258, 259, 260, 261]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[264, 265]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[272, 273, 274, 275]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[278, 279, 280]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[282, 283, 284]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[286, 287, 288, 289]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[305, 306, 307]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[309, 310, 311]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 6 with labels:\n",
            " \t\t[312, 313, 314, 315, 316, 317]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[319, 320, 321]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[322, 323, 324]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[341, 342]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[355, 356]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[370, 371]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 408 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 408 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 408 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 21.695974349975586, \"passage_id\": \"idx_67\", \"query_id\": \"qid_67-1\", \"answer\": {\"value\": [\"0.17-0.37 W/kg\", \"0.012\", \"0.028 W/kg\"], \"spans\": [[\"p\", 375, 389], [\"p\", 552, 557], [\"p\", 558, 568]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"0.17-0.37 W/kg\", \"0.012-0.028 W/kg\"]}, \"em\": 0.0, \"f1\": 0.6, \"max_passage_length\": -1}\n",
            "\n",
            "input 16:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 293 with labels:\n",
            " \t\t[0, 1336, 171, 3122, 58, 341, 116, 2, 2, 44676, 35, 20, 3038, 9, 38966, 13785, 36, 5330, 500, 43,\n",
            "\t\t2622, 30, 10, 371, 12, 11092, 36, 246, 534, 43, 1830, 1028, 36, 7629, 43, 15, 12378, 2900, 25671,\n",
            "\t\t58, 6807, 11, 1110, 9, 17512, 35114, 19416, 39655, 16572, 36, 448, 8105, 238, 4003, 39917, 6, 8,\n",
            "\t\t33945, 43671, 9779, 30962, 4, 42879, 35, 20, 24162, 58, 22422, 5530, 7, 80, 1134, 35, 826, 112, 16,\n",
            "\t\t14092, 9, 155, 534, 12, 5330, 500, 12, 18793, 7878, 24162, 36, 282, 5457, 361, 43, 8, 826, 132, 16,\n",
            "\t\t5, 797, 333, 36, 282, 5457, 361, 322, 20, 78, 333, 21, 13849, 7, 381, 12642, 13, 291, 360, 4, 20,\n",
            "\t\t797, 333, 21, 45, 4924, 7, 381, 12642, 4, 732, 18675, 36, 43625, 238, 34113, 179, 179, 36, 29792,\n",
            "\t\t238, 8, 234, 12, 26799, 4360, 281, 7755, 877, 36, 487, 5596, 43, 1389, 58, 15423, 30, 256, 8105, 4,\n",
            "\t\t19963, 3175, 36, 347, 2571, 43, 8, 23457, 2681, 8525, 228, 4325, 808, 3175, 36, 534, 10237, 12, 510,\n",
            "\t\t1178, 43, 32834, 1713, 58, 9550, 30, 19416, 21130, 1242, 22356, 5448, 4, 31862, 43671, 9779, 20070,\n",
            "\t\t58, 2584, 66, 7, 10516, 47854, 13310, 11, 5, 2900, 25671, 9, 258, 1134, 4, 12499, 35, 96, 256, 8105,\n",
            "\t\t6, 234, 5596, 73, 29792, 6, 11501, 73, 29792, 6, 8, 234, 5596, 73, 43625, 17885, 58, 45, 3625, 430,\n",
            "\t\t227, 26599, 112, 8, 132, 4, 9081, 5, 46099, 3992, 17294, 6, 32295, 8, 272, 10237, 12, 510, 1178, 6,\n",
            "\t\t3486, 5, 346, 9, 47854, 13510, 4590, 58, 3625, 430, 227, 26599, 112, 8, 132, 4, 2585, 41092, 35,\n",
            "\t\t45131, 9, 765, 12, 1279, 155, 534, 3957, 473, 45, 2045, 7, 33, 10, 11190, 1683, 15, 12378, 2900,\n",
            "\t\t11576, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 293 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 293 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 293 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tFalse, True, True, False, True, True, False, True, True, True, False, False, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, False, True, True, False, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False,\n",
            "\t\tTrue, True, True, True, False, False, True, True, True, True, True, True, True, False, False, False,\n",
            "\t\tFalse, True, True, False, True, True, True, True, True, True, False, True, True, False, True, True,\n",
            "\t\tFalse, True, True, True, False, False, True, False, False, False, True, True, False, True, True,\n",
            "\t\tFalse, True, True, True, True, True, True, True, False, False, False, True, True, True, False,\n",
            "\t\tFalse, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True,\n",
            "\t\tTrue, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 13 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[27]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[74]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[90]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[94]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[102]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[113]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[234]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[236]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[264]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[266]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[276]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 13 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 2 SpanFields : \n",
            " \t SpanField with spans: (78, 103). \n",
            " \t SpanField with spans: (78, 102). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 32 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[17, 18]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[46, 47, 48]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[50, 51]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[53, 54]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[57, 58, 59]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[78, 79]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[81, 82]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[84, 85]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[110, 111]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[123, 124]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[126, 127]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[131, 132, 133]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 5 with labels:\n",
            " \t\t[140, 141, 142, 143, 144]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[146, 147]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[153, 154]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[156, 157]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[159, 160]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[163, 164, 165]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[166, 167, 168, 169]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[171, 172]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[174, 175]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 4 with labels:\n",
            " \t\t[182, 183, 184, 185]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[188, 189, 190]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[197, 198]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[210, 211]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[213, 214]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[223, 224]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[246, 247]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[249, 250]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[256, 257]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[268, 269]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 3 LabelsFields : \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 293 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 20.286521911621094, \"passage_id\": \"idx_68\", \"query_id\": \"qid_68-1\", \"answer\": {\"value\": [\"=\"], \"spans\": [[\"p\", 353, 354]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"3G-EMR-exposed rats (n = 9)\", \"control group (n = 9)\"]}, \"em\": 0.0, \"f1\": 0.0, \"max_passage_length\": -1}\n",
            "\n",
            "input 17:  Instance with fields:\n",
            " \t question_passage_tokens: LabelsField of length 209 with labels:\n",
            " \t\t[0, 1336, 203, 305, 73, 9043, 21, 341, 116, 2, 2, 598, 11526, 678, 3038, 9, 43698, 9419, 15, 10596,\n",
            "\t\t8151, 6, 15540, 58, 4924, 7, 720, 467, 13, 1830, 4358, 36, 534, 15153, 43, 18360, 41576, 6029, 13,\n",
            "\t\t112, 1368, 23, 10, 1086, 809, 34565, 9, 112, 4, 134, 305, 73, 9043, 4, 13120, 8151, 21, 8069, 11, 5,\n",
            "\t\t1086, 2900, 6, 147, 5, 674, 34565, 21, 321, 4, 176, 305, 73, 9043, 6, 30, 8151, 5177, 6166, 4113,\n",
            "\t\t8200, 81, 820, 6, 4697, 4513, 3880, 4, 37070, 9, 414, 31, 31026, 8, 4924, 3122, 969, 117, 1233,\n",
            "\t\t2249, 11, 10596, 8151, 46404, 4, 635, 6, 77, 540, 19940, 16311, 58, 5091, 7, 11526, 5177, 30766,\n",
            "\t\t775, 6, 3337, 14819, 58, 303, 7, 28, 11134, 12944, 511, 4895, 4, 23945, 12, 7109, 25067, 969, 14789,\n",
            "\t\t1022, 6272, 31, 112, 4, 245, 7, 132, 4, 398, 6, 9641, 2357, 58, 159, 12, 35908, 31, 321, 4, 4111,\n",
            "\t\t12, 7, 321, 4, 2890, 12, 12851, 1022, 6, 53, 209, 5550, 11, 10596, 8151, 58, 45, 1474, 30, 588, 12,\n",
            "\t\t958, 45125, 4, 2096, 209, 2167, 1804, 1274, 6, 117, 4292, 7335, 9, 10596, 8151, 46404, 11, 1086,\n",
            "\t\t18292, 2900, 21, 303, 3059, 7, 272, 15153, 18360, 41576, 4895, 4, 2]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_token_type_ids: LabelsField of length 209 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_special_tokens_mask: LabelsField of length 209 with labels:\n",
            " \t\t[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t question_passage_pad_mask: LabelsField of length 209 with labels:\n",
            " \t\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "\t\t1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t first_wordpiece_mask: LabelsField of length 209 with labels:\n",
            " \t\t[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tFalse, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, False, False, True, True, True, True, True, True, True, False, False,\n",
            "\t\tTrue, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True,\n",
            "\t\tFalse, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True,\n",
            "\t\tFalse, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "\t\tTrue, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True,\n",
            "\t\tTrue]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t number_indices: ListField of 15 LabelsFields : \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[35]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[39]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[47, 48, 49]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[68, 69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[82, 83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[119]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[130]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[132]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[139, 140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[143, 144, 145]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[148]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[154, 155, 156]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[159, 160, 161]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[204]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 15 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_expressions_extra: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_counts: ListField of 1 LabelFields : \n",
            " \t LabelField with label: -1 in namespace: 'labels'.' \n",
            " \n",
            " \t answer_as_passage_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (47, 52). \n",
            " \n",
            " \t answer_as_question_spans: ListField of 1 SpanFields : \n",
            " \t SpanField with spans: (-1, -1). \n",
            " \n",
            " \t wordpiece_indices: ListField of 14 LabelsFields : \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[16, 17]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[32, 33]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[47, 48, 49]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[68, 69, 70]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[77, 78, 79]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[82, 83, 84]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[115, 116]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[125, 126]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[139, 140, 141]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[143, 144, 145]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[154, 155, 156]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 3 with labels:\n",
            " \t\t[159, 160, 161]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 2 with labels:\n",
            " \t\t[202, 203]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t LabelsField of length 1 with labels:\n",
            " \t\t[-1]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t answer_as_text_to_disjoint_bios: ListField of 1 ListFields : \n",
            " \t ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 209 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \n",
            " \t answer_as_list_of_bios: ListField of 1 LabelsFields : \n",
            " \t LabelsField of length 209 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \n",
            " \t span_bio_labels: LabelsField of length 209 with labels:\n",
            " \t\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "\t\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \t\tin namespace: 'labels'. \n",
            " \t is_bio_mask: LabelField with label: 1 in namespace: 'labels'.' \n",
            " \t metadata: MetadataField (print field.metadata to see specific information). \n",
            "\n",
            "prediction:  {\"loss\": 19.98011016845703, \"passage_id\": \"idx_69\", \"query_id\": \"qid_69-1\", \"answer\": {\"value\": [\"0.2 W/kg\", \"1.5\", \"2.8\", \"0.67-\", \"0.29\"], \"spans\": [[\"p\", 259, 267], [\"p\", 634, 637], [\"p\", 641, 644], [\"p\", 682, 687], [\"p\", 691, 695]]}, \"predicted_ability\": \"multi_span\", \"maximizing_ground_truth\": {\"number\": \"\", \"date\": {\"day\": \"\", \"month\": \"\", \"year\": \"\"}, \"spans\": [\"1.1 W/kg\", \"0.2 W/kg\"]}, \"em\": 0.0, \"f1\": 0.2, \"max_passage_length\": -1}\n",
            "\n",
            "2022-04-23 03:14:20,964 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpj9i0optz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y9h9sWjfi56m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yNYZpiGMi6Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_BZ1SMxc43fF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}